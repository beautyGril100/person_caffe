I0228 10:24:26.865109 12900 caffe.cpp:217] Using GPUs 1
I0228 10:24:26.880409 12900 caffe.cpp:222] GPU 1: GeForce GTX 1080 Ti
I0228 10:24:27.404842 12900 solver.cpp:63] Initializing solver from parameters: 
train_net: "MobileNetSSD_train.prototxt"
test_net: "MobileNetSSD_test.prototxt"
test_iter: 673
test_interval: 10000
base_lr: 0.0005
display: 10
max_iter: 120000
lr_policy: "multistep"
gamma: 0.5
weight_decay: 5e-05
snapshot: 1000
snapshot_prefix: "snapshot/mobilenet"
solver_mode: GPU
device_id: 1
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 20000
stepvalue: 40000
iter_size: 1
type: "RMSProp"
eval_type: "detection"
ap_version: "11point"
I0228 10:24:27.405002 12900 solver.cpp:96] Creating training net from train_net file: MobileNetSSD_train.prototxt
I0228 10:24:27.406713 12900 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: MobileNetSSD_train.prototxt
I0228 10:24:27.406735 12900 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0228 10:24:27.408358 12900 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.007843
    mirror: true
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "trainval_lmdb/"
    batch_size: 24
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    or
I0228 10:24:27.409201 12900 layer_factory.hpp:77] Creating layer data
I0228 10:24:27.409749 12900 net.cpp:100] Creating Layer data
I0228 10:24:27.409772 12900 net.cpp:408] data -> data
I0228 10:24:27.409813 12900 net.cpp:408] data -> label
I0228 10:24:27.410897 12905 db_lmdb.cpp:35] Opened lmdb trainval_lmdb/
I0228 10:24:27.437222 12900 annotated_data_layer.cpp:62] output data size: 24,3,300,300
I0228 10:24:27.479002 12900 net.cpp:150] Setting up data
I0228 10:24:27.479032 12900 net.cpp:157] Top shape: 24 3 300 300 (6480000)
I0228 10:24:27.479040 12900 net.cpp:157] Top shape: 1 1 1 8 (8)
I0228 10:24:27.479044 12900 net.cpp:165] Memory required for data: 25920032
I0228 10:24:27.479058 12900 layer_factory.hpp:77] Creating layer data_data_0_split
I0228 10:24:27.479074 12900 net.cpp:100] Creating Layer data_data_0_split
I0228 10:24:27.479081 12900 net.cpp:434] data_data_0_split <- data
I0228 10:24:27.479099 12900 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0228 10:24:27.479112 12900 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0228 10:24:27.479125 12900 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0228 10:24:27.479135 12900 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0228 10:24:27.479143 12900 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0228 10:24:27.479157 12900 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0228 10:24:27.479166 12900 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0228 10:24:27.479321 12900 net.cpp:150] Setting up data_data_0_split
I0228 10:24:27.479331 12900 net.cpp:157] Top shape: 24 3 300 300 (6480000)
I0228 10:24:27.479337 12900 net.cpp:157] Top shape: 24 3 300 300 (6480000)
I0228 10:24:27.479343 12900 net.cpp:157] Top shape: 24 3 300 300 (6480000)
I0228 10:24:27.479369 12900 net.cpp:157] Top shape: 24 3 300 300 (6480000)
I0228 10:24:27.479375 12900 net.cpp:157] Top shape: 24 3 300 300 (6480000)
I0228 10:24:27.479382 12900 net.cpp:157] Top shape: 24 3 300 300 (6480000)
I0228 10:24:27.479388 12900 net.cpp:157] Top shape: 24 3 300 300 (6480000)
I0228 10:24:27.479393 12900 net.cpp:165] Memory required for data: 207360032
I0228 10:24:27.479398 12900 layer_factory.hpp:77] Creating layer conv0
I0228 10:24:27.479420 12900 net.cpp:100] Creating Layer conv0
I0228 10:24:27.479427 12900 net.cpp:434] conv0 <- data_data_0_split_0
I0228 10:24:27.479437 12900 net.cpp:408] conv0 -> conv0
I0228 10:24:28.160930 12900 net.cpp:150] Setting up conv0
I0228 10:24:28.160975 12900 net.cpp:157] Top shape: 24 32 150 150 (17280000)
I0228 10:24:28.160980 12900 net.cpp:165] Memory required for data: 276480032
I0228 10:24:28.160997 12900 layer_factory.hpp:77] Creating layer conv0/bn
I0228 10:24:28.161011 12900 net.cpp:100] Creating Layer conv0/bn
I0228 10:24:28.161017 12900 net.cpp:434] conv0/bn <- conv0
I0228 10:24:28.161039 12900 net.cpp:395] conv0/bn -> conv0 (in-place)
I0228 10:24:28.162433 12900 net.cpp:150] Setting up conv0/bn
I0228 10:24:28.162447 12900 net.cpp:157] Top shape: 24 32 150 150 (17280000)
I0228 10:24:28.162468 12900 net.cpp:165] Memory required for data: 345600032
I0228 10:24:28.162480 12900 layer_factory.hpp:77] Creating layer conv0/scale
I0228 10:24:28.162492 12900 net.cpp:100] Creating Layer conv0/scale
I0228 10:24:28.162497 12900 net.cpp:434] conv0/scale <- conv0
I0228 10:24:28.162521 12900 net.cpp:395] conv0/scale -> conv0 (in-place)
I0228 10:24:28.162588 12900 layer_factory.hpp:77] Creating layer conv0/scale
I0228 10:24:28.162750 12900 net.cpp:150] Setting up conv0/scale
I0228 10:24:28.162760 12900 net.cpp:157] Top shape: 24 32 150 150 (17280000)
I0228 10:24:28.162765 12900 net.cpp:165] Memory required for data: 414720032
I0228 10:24:28.162775 12900 layer_factory.hpp:77] Creating layer conv0/relu
I0228 10:24:28.162783 12900 net.cpp:100] Creating Layer conv0/relu
I0228 10:24:28.162787 12900 net.cpp:434] conv0/relu <- conv0
I0228 10:24:28.162796 12900 net.cpp:395] conv0/relu -> conv0 (in-place)
I0228 10:24:28.163305 12900 net.cpp:150] Setting up conv0/relu
I0228 10:24:28.163317 12900 net.cpp:157] Top shape: 24 32 150 150 (17280000)
I0228 10:24:28.163321 12900 net.cpp:165] Memory required for data: 483840032
I0228 10:24:28.163327 12900 layer_factory.hpp:77] Creating layer conv1/dw
I0228 10:24:28.163341 12900 net.cpp:100] Creating Layer conv1/dw
I0228 10:24:28.163347 12900 net.cpp:434] conv1/dw <- conv0
I0228 10:24:28.163355 12900 net.cpp:408] conv1/dw -> conv1/dw
I0228 10:24:28.163612 12900 net.cpp:150] Setting up conv1/dw
I0228 10:24:28.163622 12900 net.cpp:157] Top shape: 24 32 150 150 (17280000)
I0228 10:24:28.163627 12900 net.cpp:165] Memory required for data: 552960032
I0228 10:24:28.163633 12900 layer_factory.hpp:77] Creating layer conv1/dw/bn
I0228 10:24:28.163642 12900 net.cpp:100] Creating Layer conv1/dw/bn
I0228 10:24:28.163647 12900 net.cpp:434] conv1/dw/bn <- conv1/dw
I0228 10:24:28.163653 12900 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I0228 10:24:28.163874 12900 net.cpp:150] Setting up conv1/dw/bn
I0228 10:24:28.163884 12900 net.cpp:157] Top shape: 24 32 150 150 (17280000)
I0228 10:24:28.163888 12900 net.cpp:165] Memory required for data: 622080032
I0228 10:24:28.163898 12900 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0228 10:24:28.163906 12900 net.cpp:100] Creating Layer conv1/dw/scale
I0228 10:24:28.163911 12900 net.cpp:434] conv1/dw/scale <- conv1/dw
I0228 10:24:28.163920 12900 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I0228 10:24:28.163961 12900 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0228 10:24:28.164103 12900 net.cpp:150] Setting up conv1/dw/scale
I0228 10:24:28.164113 12900 net.cpp:157] Top shape: 24 32 150 150 (17280000)
I0228 10:24:28.164117 12900 net.cpp:165] Memory required for data: 691200032
I0228 10:24:28.164124 12900 layer_factory.hpp:77] Creating layer conv1/dw/relu
I0228 10:24:28.164149 12900 net.cpp:100] Creating Layer conv1/dw/relu
I0228 10:24:28.164155 12900 net.cpp:434] conv1/dw/relu <- conv1/dw
I0228 10:24:28.164160 12900 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I0228 10:24:28.164675 12900 net.cpp:150] Setting up conv1/dw/relu
I0228 10:24:28.164690 12900 net.cpp:157] Top shape: 24 32 150 150 (17280000)
I0228 10:24:28.164696 12900 net.cpp:165] Memory required for data: 760320032
I0228 10:24:28.164700 12900 layer_factory.hpp:77] Creating layer conv1
I0228 10:24:28.164726 12900 net.cpp:100] Creating Layer conv1
I0228 10:24:28.164731 12900 net.cpp:434] conv1 <- conv1/dw
I0228 10:24:28.164739 12900 net.cpp:408] conv1 -> conv1
I0228 10:24:28.167920 12900 net.cpp:150] Setting up conv1
I0228 10:24:28.167950 12900 net.cpp:157] Top shape: 24 64 150 150 (34560000)
I0228 10:24:28.167955 12900 net.cpp:165] Memory required for data: 898560032
I0228 10:24:28.167963 12900 layer_factory.hpp:77] Creating layer conv1/bn
I0228 10:24:28.167973 12900 net.cpp:100] Creating Layer conv1/bn
I0228 10:24:28.167978 12900 net.cpp:434] conv1/bn <- conv1
I0228 10:24:28.167984 12900 net.cpp:395] conv1/bn -> conv1 (in-place)
I0228 10:24:28.168190 12900 net.cpp:150] Setting up conv1/bn
I0228 10:24:28.168200 12900 net.cpp:157] Top shape: 24 64 150 150 (34560000)
I0228 10:24:28.168205 12900 net.cpp:165] Memory required for data: 1036800032
I0228 10:24:28.168212 12900 layer_factory.hpp:77] Creating layer conv1/scale
I0228 10:24:28.168220 12900 net.cpp:100] Creating Layer conv1/scale
I0228 10:24:28.168225 12900 net.cpp:434] conv1/scale <- conv1
I0228 10:24:28.168231 12900 net.cpp:395] conv1/scale -> conv1 (in-place)
I0228 10:24:28.168272 12900 layer_factory.hpp:77] Creating layer conv1/scale
I0228 10:24:28.168434 12900 net.cpp:150] Setting up conv1/scale
I0228 10:24:28.168444 12900 net.cpp:157] Top shape: 24 64 150 150 (34560000)
I0228 10:24:28.168448 12900 net.cpp:165] Memory required for data: 1175040032
I0228 10:24:28.168460 12900 layer_factory.hpp:77] Creating layer conv1/relu
I0228 10:24:28.168468 12900 net.cpp:100] Creating Layer conv1/relu
I0228 10:24:28.168474 12900 net.cpp:434] conv1/relu <- conv1
I0228 10:24:28.168480 12900 net.cpp:395] conv1/relu -> conv1 (in-place)
I0228 10:24:28.169442 12900 net.cpp:150] Setting up conv1/relu
I0228 10:24:28.169459 12900 net.cpp:157] Top shape: 24 64 150 150 (34560000)
I0228 10:24:28.169463 12900 net.cpp:165] Memory required for data: 1313280032
I0228 10:24:28.169468 12900 layer_factory.hpp:77] Creating layer conv2/dw
I0228 10:24:28.169479 12900 net.cpp:100] Creating Layer conv2/dw
I0228 10:24:28.169486 12900 net.cpp:434] conv2/dw <- conv1
I0228 10:24:28.169494 12900 net.cpp:408] conv2/dw -> conv2/dw
I0228 10:24:28.169716 12900 net.cpp:150] Setting up conv2/dw
I0228 10:24:28.169726 12900 net.cpp:157] Top shape: 24 64 75 75 (8640000)
I0228 10:24:28.169731 12900 net.cpp:165] Memory required for data: 1347840032
I0228 10:24:28.169739 12900 layer_factory.hpp:77] Creating layer conv2/dw/bn
I0228 10:24:28.169744 12900 net.cpp:100] Creating Layer conv2/dw/bn
I0228 10:24:28.169749 12900 net.cpp:434] conv2/dw/bn <- conv2/dw
I0228 10:24:28.169757 12900 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I0228 10:24:28.171010 12900 net.cpp:150] Setting up conv2/dw/bn
I0228 10:24:28.171025 12900 net.cpp:157] Top shape: 24 64 75 75 (8640000)
I0228 10:24:28.171030 12900 net.cpp:165] Memory required for data: 1382400032
I0228 10:24:28.171041 12900 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0228 10:24:28.171051 12900 net.cpp:100] Creating Layer conv2/dw/scale
I0228 10:24:28.171056 12900 net.cpp:434] conv2/dw/scale <- conv2/dw
I0228 10:24:28.171063 12900 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I0228 10:24:28.171108 12900 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0228 10:24:28.171231 12900 net.cpp:150] Setting up conv2/dw/scale
I0228 10:24:28.171241 12900 net.cpp:157] Top shape: 24 64 75 75 (8640000)
I0228 10:24:28.171244 12900 net.cpp:165] Memory required for data: 1416960032
I0228 10:24:28.171252 12900 layer_factory.hpp:77] Creating layer conv2/dw/relu
I0228 10:24:28.171273 12900 net.cpp:100] Creating Layer conv2/dw/relu
I0228 10:24:28.171278 12900 net.cpp:434] conv2/dw/relu <- conv2/dw
I0228 10:24:28.171284 12900 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I0228 10:24:28.171741 12900 net.cpp:150] Setting up conv2/dw/relu
I0228 10:24:28.171754 12900 net.cpp:157] Top shape: 24 64 75 75 (8640000)
I0228 10:24:28.171758 12900 net.cpp:165] Memory required for data: 1451520032
I0228 10:24:28.171763 12900 layer_factory.hpp:77] Creating layer conv2
I0228 10:24:28.171790 12900 net.cpp:100] Creating Layer conv2
I0228 10:24:28.171811 12900 net.cpp:434] conv2 <- conv2/dw
I0228 10:24:28.171820 12900 net.cpp:408] conv2 -> conv2
I0228 10:24:28.174561 12900 net.cpp:150] Setting up conv2
I0228 10:24:28.174577 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.174593 12900 net.cpp:165] Memory required for data: 1520640032
I0228 10:24:28.174600 12900 layer_factory.hpp:77] Creating layer conv2/bn
I0228 10:24:28.174607 12900 net.cpp:100] Creating Layer conv2/bn
I0228 10:24:28.174628 12900 net.cpp:434] conv2/bn <- conv2
I0228 10:24:28.174635 12900 net.cpp:395] conv2/bn -> conv2 (in-place)
I0228 10:24:28.174837 12900 net.cpp:150] Setting up conv2/bn
I0228 10:24:28.174846 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.174852 12900 net.cpp:165] Memory required for data: 1589760032
I0228 10:24:28.174860 12900 layer_factory.hpp:77] Creating layer conv2/scale
I0228 10:24:28.174868 12900 net.cpp:100] Creating Layer conv2/scale
I0228 10:24:28.174872 12900 net.cpp:434] conv2/scale <- conv2
I0228 10:24:28.174880 12900 net.cpp:395] conv2/scale -> conv2 (in-place)
I0228 10:24:28.174919 12900 layer_factory.hpp:77] Creating layer conv2/scale
I0228 10:24:28.175056 12900 net.cpp:150] Setting up conv2/scale
I0228 10:24:28.175065 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.175071 12900 net.cpp:165] Memory required for data: 1658880032
I0228 10:24:28.175078 12900 layer_factory.hpp:77] Creating layer conv2/relu
I0228 10:24:28.175084 12900 net.cpp:100] Creating Layer conv2/relu
I0228 10:24:28.175089 12900 net.cpp:434] conv2/relu <- conv2
I0228 10:24:28.175096 12900 net.cpp:395] conv2/relu -> conv2 (in-place)
I0228 10:24:28.175606 12900 net.cpp:150] Setting up conv2/relu
I0228 10:24:28.175616 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.175631 12900 net.cpp:165] Memory required for data: 1728000032
I0228 10:24:28.175635 12900 layer_factory.hpp:77] Creating layer conv3/dw
I0228 10:24:28.175647 12900 net.cpp:100] Creating Layer conv3/dw
I0228 10:24:28.175667 12900 net.cpp:434] conv3/dw <- conv2
I0228 10:24:28.175674 12900 net.cpp:408] conv3/dw -> conv3/dw
I0228 10:24:28.175879 12900 net.cpp:150] Setting up conv3/dw
I0228 10:24:28.175889 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.175894 12900 net.cpp:165] Memory required for data: 1797120032
I0228 10:24:28.175900 12900 layer_factory.hpp:77] Creating layer conv3/dw/bn
I0228 10:24:28.175907 12900 net.cpp:100] Creating Layer conv3/dw/bn
I0228 10:24:28.175912 12900 net.cpp:434] conv3/dw/bn <- conv3/dw
I0228 10:24:28.175918 12900 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I0228 10:24:28.176120 12900 net.cpp:150] Setting up conv3/dw/bn
I0228 10:24:28.176131 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.176134 12900 net.cpp:165] Memory required for data: 1866240032
I0228 10:24:28.176147 12900 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0228 10:24:28.176156 12900 net.cpp:100] Creating Layer conv3/dw/scale
I0228 10:24:28.176160 12900 net.cpp:434] conv3/dw/scale <- conv3/dw
I0228 10:24:28.176168 12900 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I0228 10:24:28.176220 12900 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0228 10:24:28.176336 12900 net.cpp:150] Setting up conv3/dw/scale
I0228 10:24:28.176359 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.176365 12900 net.cpp:165] Memory required for data: 1935360032
I0228 10:24:28.176373 12900 layer_factory.hpp:77] Creating layer conv3/dw/relu
I0228 10:24:28.176388 12900 net.cpp:100] Creating Layer conv3/dw/relu
I0228 10:24:28.176394 12900 net.cpp:434] conv3/dw/relu <- conv3/dw
I0228 10:24:28.176403 12900 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I0228 10:24:28.177357 12900 net.cpp:150] Setting up conv3/dw/relu
I0228 10:24:28.177372 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.177378 12900 net.cpp:165] Memory required for data: 2004480032
I0228 10:24:28.177383 12900 layer_factory.hpp:77] Creating layer conv3
I0228 10:24:28.177394 12900 net.cpp:100] Creating Layer conv3
I0228 10:24:28.177400 12900 net.cpp:434] conv3 <- conv3/dw
I0228 10:24:28.177409 12900 net.cpp:408] conv3 -> conv3
I0228 10:24:28.179703 12900 net.cpp:150] Setting up conv3
I0228 10:24:28.179718 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.179734 12900 net.cpp:165] Memory required for data: 2073600032
I0228 10:24:28.179742 12900 layer_factory.hpp:77] Creating layer conv3/bn
I0228 10:24:28.179752 12900 net.cpp:100] Creating Layer conv3/bn
I0228 10:24:28.179757 12900 net.cpp:434] conv3/bn <- conv3
I0228 10:24:28.179764 12900 net.cpp:395] conv3/bn -> conv3 (in-place)
I0228 10:24:28.179980 12900 net.cpp:150] Setting up conv3/bn
I0228 10:24:28.179989 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.179993 12900 net.cpp:165] Memory required for data: 2142720032
I0228 10:24:28.180001 12900 layer_factory.hpp:77] Creating layer conv3/scale
I0228 10:24:28.180011 12900 net.cpp:100] Creating Layer conv3/scale
I0228 10:24:28.180016 12900 net.cpp:434] conv3/scale <- conv3
I0228 10:24:28.180021 12900 net.cpp:395] conv3/scale -> conv3 (in-place)
I0228 10:24:28.180061 12900 layer_factory.hpp:77] Creating layer conv3/scale
I0228 10:24:28.180178 12900 net.cpp:150] Setting up conv3/scale
I0228 10:24:28.180187 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.180191 12900 net.cpp:165] Memory required for data: 2211840032
I0228 10:24:28.180198 12900 layer_factory.hpp:77] Creating layer conv3/relu
I0228 10:24:28.180207 12900 net.cpp:100] Creating Layer conv3/relu
I0228 10:24:28.180212 12900 net.cpp:434] conv3/relu <- conv3
I0228 10:24:28.180217 12900 net.cpp:395] conv3/relu -> conv3 (in-place)
I0228 10:24:28.180721 12900 net.cpp:150] Setting up conv3/relu
I0228 10:24:28.180734 12900 net.cpp:157] Top shape: 24 128 75 75 (17280000)
I0228 10:24:28.180739 12900 net.cpp:165] Memory required for data: 2280960032
I0228 10:24:28.180743 12900 layer_factory.hpp:77] Creating layer conv4/dw
I0228 10:24:28.180754 12900 net.cpp:100] Creating Layer conv4/dw
I0228 10:24:28.180763 12900 net.cpp:434] conv4/dw <- conv3
I0228 10:24:28.180769 12900 net.cpp:408] conv4/dw -> conv4/dw
I0228 10:24:28.180979 12900 net.cpp:150] Setting up conv4/dw
I0228 10:24:28.180989 12900 net.cpp:157] Top shape: 24 128 38 38 (4435968)
I0228 10:24:28.181008 12900 net.cpp:165] Memory required for data: 2298703904
I0228 10:24:28.181015 12900 layer_factory.hpp:77] Creating layer conv4/dw/bn
I0228 10:24:28.181021 12900 net.cpp:100] Creating Layer conv4/dw/bn
I0228 10:24:28.181026 12900 net.cpp:434] conv4/dw/bn <- conv4/dw
I0228 10:24:28.181033 12900 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I0228 10:24:28.181210 12900 net.cpp:150] Setting up conv4/dw/bn
I0228 10:24:28.181218 12900 net.cpp:157] Top shape: 24 128 38 38 (4435968)
I0228 10:24:28.181222 12900 net.cpp:165] Memory required for data: 2316447776
I0228 10:24:28.181231 12900 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0228 10:24:28.181241 12900 net.cpp:100] Creating Layer conv4/dw/scale
I0228 10:24:28.181246 12900 net.cpp:434] conv4/dw/scale <- conv4/dw
I0228 10:24:28.181252 12900 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I0228 10:24:28.181291 12900 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0228 10:24:28.181417 12900 net.cpp:150] Setting up conv4/dw/scale
I0228 10:24:28.181426 12900 net.cpp:157] Top shape: 24 128 38 38 (4435968)
I0228 10:24:28.181430 12900 net.cpp:165] Memory required for data: 2334191648
I0228 10:24:28.181437 12900 layer_factory.hpp:77] Creating layer conv4/dw/relu
I0228 10:24:28.181454 12900 net.cpp:100] Creating Layer conv4/dw/relu
I0228 10:24:28.181459 12900 net.cpp:434] conv4/dw/relu <- conv4/dw
I0228 10:24:28.181466 12900 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I0228 10:24:28.181915 12900 net.cpp:150] Setting up conv4/dw/relu
I0228 10:24:28.181927 12900 net.cpp:157] Top shape: 24 128 38 38 (4435968)
I0228 10:24:28.181931 12900 net.cpp:165] Memory required for data: 2351935520
I0228 10:24:28.181936 12900 layer_factory.hpp:77] Creating layer conv4
I0228 10:24:28.181947 12900 net.cpp:100] Creating Layer conv4
I0228 10:24:28.181952 12900 net.cpp:434] conv4 <- conv4/dw
I0228 10:24:28.181960 12900 net.cpp:408] conv4 -> conv4
I0228 10:24:28.184403 12900 net.cpp:150] Setting up conv4
I0228 10:24:28.184422 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.184427 12900 net.cpp:165] Memory required for data: 2387423264
I0228 10:24:28.184433 12900 layer_factory.hpp:77] Creating layer conv4/bn
I0228 10:24:28.184442 12900 net.cpp:100] Creating Layer conv4/bn
I0228 10:24:28.184448 12900 net.cpp:434] conv4/bn <- conv4
I0228 10:24:28.184455 12900 net.cpp:395] conv4/bn -> conv4 (in-place)
I0228 10:24:28.184667 12900 net.cpp:150] Setting up conv4/bn
I0228 10:24:28.184676 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.184682 12900 net.cpp:165] Memory required for data: 2422911008
I0228 10:24:28.184691 12900 layer_factory.hpp:77] Creating layer conv4/scale
I0228 10:24:28.184700 12900 net.cpp:100] Creating Layer conv4/scale
I0228 10:24:28.184705 12900 net.cpp:434] conv4/scale <- conv4
I0228 10:24:28.184710 12900 net.cpp:395] conv4/scale -> conv4 (in-place)
I0228 10:24:28.184753 12900 layer_factory.hpp:77] Creating layer conv4/scale
I0228 10:24:28.184870 12900 net.cpp:150] Setting up conv4/scale
I0228 10:24:28.184880 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.184885 12900 net.cpp:165] Memory required for data: 2458398752
I0228 10:24:28.184891 12900 layer_factory.hpp:77] Creating layer conv4/relu
I0228 10:24:28.184898 12900 net.cpp:100] Creating Layer conv4/relu
I0228 10:24:28.184902 12900 net.cpp:434] conv4/relu <- conv4
I0228 10:24:28.184911 12900 net.cpp:395] conv4/relu -> conv4 (in-place)
I0228 10:24:28.185395 12900 net.cpp:150] Setting up conv4/relu
I0228 10:24:28.185407 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.185411 12900 net.cpp:165] Memory required for data: 2493886496
I0228 10:24:28.185417 12900 layer_factory.hpp:77] Creating layer conv5/dw
I0228 10:24:28.185427 12900 net.cpp:100] Creating Layer conv5/dw
I0228 10:24:28.185432 12900 net.cpp:434] conv5/dw <- conv4
I0228 10:24:28.185441 12900 net.cpp:408] conv5/dw -> conv5/dw
I0228 10:24:28.185703 12900 net.cpp:150] Setting up conv5/dw
I0228 10:24:28.185714 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.185719 12900 net.cpp:165] Memory required for data: 2529374240
I0228 10:24:28.185725 12900 layer_factory.hpp:77] Creating layer conv5/dw/bn
I0228 10:24:28.185734 12900 net.cpp:100] Creating Layer conv5/dw/bn
I0228 10:24:28.185739 12900 net.cpp:434] conv5/dw/bn <- conv5/dw
I0228 10:24:28.185745 12900 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I0228 10:24:28.185953 12900 net.cpp:150] Setting up conv5/dw/bn
I0228 10:24:28.185963 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.185967 12900 net.cpp:165] Memory required for data: 2564861984
I0228 10:24:28.185974 12900 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0228 10:24:28.185983 12900 net.cpp:100] Creating Layer conv5/dw/scale
I0228 10:24:28.185989 12900 net.cpp:434] conv5/dw/scale <- conv5/dw
I0228 10:24:28.185994 12900 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I0228 10:24:28.186053 12900 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0228 10:24:28.186172 12900 net.cpp:150] Setting up conv5/dw/scale
I0228 10:24:28.186182 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.186185 12900 net.cpp:165] Memory required for data: 2600349728
I0228 10:24:28.186192 12900 layer_factory.hpp:77] Creating layer conv5/dw/relu
I0228 10:24:28.186208 12900 net.cpp:100] Creating Layer conv5/dw/relu
I0228 10:24:28.186213 12900 net.cpp:434] conv5/dw/relu <- conv5/dw
I0228 10:24:28.186220 12900 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I0228 10:24:28.187147 12900 net.cpp:150] Setting up conv5/dw/relu
I0228 10:24:28.187162 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.187167 12900 net.cpp:165] Memory required for data: 2635837472
I0228 10:24:28.187172 12900 layer_factory.hpp:77] Creating layer conv5
I0228 10:24:28.187183 12900 net.cpp:100] Creating Layer conv5
I0228 10:24:28.187188 12900 net.cpp:434] conv5 <- conv5/dw
I0228 10:24:28.187197 12900 net.cpp:408] conv5 -> conv5
I0228 10:24:28.190028 12900 net.cpp:150] Setting up conv5
I0228 10:24:28.190045 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.190050 12900 net.cpp:165] Memory required for data: 2671325216
I0228 10:24:28.190058 12900 layer_factory.hpp:77] Creating layer conv5/bn
I0228 10:24:28.190068 12900 net.cpp:100] Creating Layer conv5/bn
I0228 10:24:28.190073 12900 net.cpp:434] conv5/bn <- conv5
I0228 10:24:28.190079 12900 net.cpp:395] conv5/bn -> conv5 (in-place)
I0228 10:24:28.190299 12900 net.cpp:150] Setting up conv5/bn
I0228 10:24:28.190310 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.190315 12900 net.cpp:165] Memory required for data: 2706812960
I0228 10:24:28.190323 12900 layer_factory.hpp:77] Creating layer conv5/scale
I0228 10:24:28.190335 12900 net.cpp:100] Creating Layer conv5/scale
I0228 10:24:28.190340 12900 net.cpp:434] conv5/scale <- conv5
I0228 10:24:28.190346 12900 net.cpp:395] conv5/scale -> conv5 (in-place)
I0228 10:24:28.190403 12900 layer_factory.hpp:77] Creating layer conv5/scale
I0228 10:24:28.190523 12900 net.cpp:150] Setting up conv5/scale
I0228 10:24:28.190532 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.190536 12900 net.cpp:165] Memory required for data: 2742300704
I0228 10:24:28.190551 12900 layer_factory.hpp:77] Creating layer conv5/relu
I0228 10:24:28.190560 12900 net.cpp:100] Creating Layer conv5/relu
I0228 10:24:28.190564 12900 net.cpp:434] conv5/relu <- conv5
I0228 10:24:28.190570 12900 net.cpp:395] conv5/relu -> conv5 (in-place)
I0228 10:24:28.191058 12900 net.cpp:150] Setting up conv5/relu
I0228 10:24:28.191071 12900 net.cpp:157] Top shape: 24 256 38 38 (8871936)
I0228 10:24:28.191077 12900 net.cpp:165] Memory required for data: 2777788448
I0228 10:24:28.191082 12900 layer_factory.hpp:77] Creating layer conv6/dw
I0228 10:24:28.191092 12900 net.cpp:100] Creating Layer conv6/dw
I0228 10:24:28.191097 12900 net.cpp:434] conv6/dw <- conv5
I0228 10:24:28.191108 12900 net.cpp:408] conv6/dw -> conv6/dw
I0228 10:24:28.191365 12900 net.cpp:150] Setting up conv6/dw
I0228 10:24:28.191375 12900 net.cpp:157] Top shape: 24 256 19 19 (2217984)
I0228 10:24:28.191380 12900 net.cpp:165] Memory required for data: 2786660384
I0228 10:24:28.191385 12900 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0228 10:24:28.191391 12900 net.cpp:100] Creating Layer conv6/dw/bn
I0228 10:24:28.191396 12900 net.cpp:434] conv6/dw/bn <- conv6/dw
I0228 10:24:28.191403 12900 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I0228 10:24:28.191638 12900 net.cpp:150] Setting up conv6/dw/bn
I0228 10:24:28.191648 12900 net.cpp:157] Top shape: 24 256 19 19 (2217984)
I0228 10:24:28.191651 12900 net.cpp:165] Memory required for data: 2795532320
I0228 10:24:28.191660 12900 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0228 10:24:28.191668 12900 net.cpp:100] Creating Layer conv6/dw/scale
I0228 10:24:28.191673 12900 net.cpp:434] conv6/dw/scale <- conv6/dw
I0228 10:24:28.191679 12900 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I0228 10:24:28.191721 12900 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0228 10:24:28.191849 12900 net.cpp:150] Setting up conv6/dw/scale
I0228 10:24:28.191859 12900 net.cpp:157] Top shape: 24 256 19 19 (2217984)
I0228 10:24:28.191862 12900 net.cpp:165] Memory required for data: 2804404256
I0228 10:24:28.191869 12900 layer_factory.hpp:77] Creating layer conv6/dw/relu
I0228 10:24:28.191905 12900 net.cpp:100] Creating Layer conv6/dw/relu
I0228 10:24:28.191910 12900 net.cpp:434] conv6/dw/relu <- conv6/dw
I0228 10:24:28.191916 12900 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I0228 10:24:28.192418 12900 net.cpp:150] Setting up conv6/dw/relu
I0228 10:24:28.192432 12900 net.cpp:157] Top shape: 24 256 19 19 (2217984)
I0228 10:24:28.192437 12900 net.cpp:165] Memory required for data: 2813276192
I0228 10:24:28.192441 12900 layer_factory.hpp:77] Creating layer conv6
I0228 10:24:28.192466 12900 net.cpp:100] Creating Layer conv6
I0228 10:24:28.192473 12900 net.cpp:434] conv6 <- conv6/dw
I0228 10:24:28.192482 12900 net.cpp:408] conv6 -> conv6
I0228 10:24:28.197180 12900 net.cpp:150] Setting up conv6
I0228 10:24:28.197197 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.197202 12900 net.cpp:165] Memory required for data: 2831020064
I0228 10:24:28.197209 12900 layer_factory.hpp:77] Creating layer conv6/bn
I0228 10:24:28.197218 12900 net.cpp:100] Creating Layer conv6/bn
I0228 10:24:28.197224 12900 net.cpp:434] conv6/bn <- conv6
I0228 10:24:28.197230 12900 net.cpp:395] conv6/bn -> conv6 (in-place)
I0228 10:24:28.197470 12900 net.cpp:150] Setting up conv6/bn
I0228 10:24:28.197480 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.197486 12900 net.cpp:165] Memory required for data: 2848763936
I0228 10:24:28.197496 12900 layer_factory.hpp:77] Creating layer conv6/scale
I0228 10:24:28.197505 12900 net.cpp:100] Creating Layer conv6/scale
I0228 10:24:28.197511 12900 net.cpp:434] conv6/scale <- conv6
I0228 10:24:28.197518 12900 net.cpp:395] conv6/scale -> conv6 (in-place)
I0228 10:24:28.197566 12900 layer_factory.hpp:77] Creating layer conv6/scale
I0228 10:24:28.197684 12900 net.cpp:150] Setting up conv6/scale
I0228 10:24:28.197692 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.197697 12900 net.cpp:165] Memory required for data: 2866507808
I0228 10:24:28.197705 12900 layer_factory.hpp:77] Creating layer conv6/relu
I0228 10:24:28.197713 12900 net.cpp:100] Creating Layer conv6/relu
I0228 10:24:28.197717 12900 net.cpp:434] conv6/relu <- conv6
I0228 10:24:28.197724 12900 net.cpp:395] conv6/relu -> conv6 (in-place)
I0228 10:24:28.198657 12900 net.cpp:150] Setting up conv6/relu
I0228 10:24:28.198684 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.198689 12900 net.cpp:165] Memory required for data: 2884251680
I0228 10:24:28.198695 12900 layer_factory.hpp:77] Creating layer conv7/dw
I0228 10:24:28.198720 12900 net.cpp:100] Creating Layer conv7/dw
I0228 10:24:28.198725 12900 net.cpp:434] conv7/dw <- conv6
I0228 10:24:28.198732 12900 net.cpp:408] conv7/dw -> conv7/dw
I0228 10:24:28.199002 12900 net.cpp:150] Setting up conv7/dw
I0228 10:24:28.199012 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.199015 12900 net.cpp:165] Memory required for data: 2901995552
I0228 10:24:28.199035 12900 layer_factory.hpp:77] Creating layer conv7/dw/bn
I0228 10:24:28.199043 12900 net.cpp:100] Creating Layer conv7/dw/bn
I0228 10:24:28.199062 12900 net.cpp:434] conv7/dw/bn <- conv7/dw
I0228 10:24:28.199069 12900 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I0228 10:24:28.199295 12900 net.cpp:150] Setting up conv7/dw/bn
I0228 10:24:28.199304 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.199309 12900 net.cpp:165] Memory required for data: 2919739424
I0228 10:24:28.199317 12900 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0228 10:24:28.199324 12900 net.cpp:100] Creating Layer conv7/dw/scale
I0228 10:24:28.199331 12900 net.cpp:434] conv7/dw/scale <- conv7/dw
I0228 10:24:28.199337 12900 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I0228 10:24:28.199393 12900 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0228 10:24:28.199525 12900 net.cpp:150] Setting up conv7/dw/scale
I0228 10:24:28.199537 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.199542 12900 net.cpp:165] Memory required for data: 2937483296
I0228 10:24:28.199548 12900 layer_factory.hpp:77] Creating layer conv7/dw/relu
I0228 10:24:28.199568 12900 net.cpp:100] Creating Layer conv7/dw/relu
I0228 10:24:28.199574 12900 net.cpp:434] conv7/dw/relu <- conv7/dw
I0228 10:24:28.199580 12900 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I0228 10:24:28.200047 12900 net.cpp:150] Setting up conv7/dw/relu
I0228 10:24:28.200059 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.200075 12900 net.cpp:165] Memory required for data: 2955227168
I0228 10:24:28.200080 12900 layer_factory.hpp:77] Creating layer conv7
I0228 10:24:28.200090 12900 net.cpp:100] Creating Layer conv7
I0228 10:24:28.200094 12900 net.cpp:434] conv7 <- conv7/dw
I0228 10:24:28.200103 12900 net.cpp:408] conv7 -> conv7
I0228 10:24:28.204969 12900 net.cpp:150] Setting up conv7
I0228 10:24:28.205000 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.205005 12900 net.cpp:165] Memory required for data: 2972971040
I0228 10:24:28.205013 12900 layer_factory.hpp:77] Creating layer conv7/bn
I0228 10:24:28.205021 12900 net.cpp:100] Creating Layer conv7/bn
I0228 10:24:28.205026 12900 net.cpp:434] conv7/bn <- conv7
I0228 10:24:28.205032 12900 net.cpp:395] conv7/bn -> conv7 (in-place)
I0228 10:24:28.205263 12900 net.cpp:150] Setting up conv7/bn
I0228 10:24:28.205273 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.205277 12900 net.cpp:165] Memory required for data: 2990714912
I0228 10:24:28.205286 12900 layer_factory.hpp:77] Creating layer conv7/scale
I0228 10:24:28.205296 12900 net.cpp:100] Creating Layer conv7/scale
I0228 10:24:28.205301 12900 net.cpp:434] conv7/scale <- conv7
I0228 10:24:28.205307 12900 net.cpp:395] conv7/scale -> conv7 (in-place)
I0228 10:24:28.205353 12900 layer_factory.hpp:77] Creating layer conv7/scale
I0228 10:24:28.205490 12900 net.cpp:150] Setting up conv7/scale
I0228 10:24:28.205502 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.205507 12900 net.cpp:165] Memory required for data: 3008458784
I0228 10:24:28.205513 12900 layer_factory.hpp:77] Creating layer conv7/relu
I0228 10:24:28.205520 12900 net.cpp:100] Creating Layer conv7/relu
I0228 10:24:28.205525 12900 net.cpp:434] conv7/relu <- conv7
I0228 10:24:28.205530 12900 net.cpp:395] conv7/relu -> conv7 (in-place)
I0228 10:24:28.206053 12900 net.cpp:150] Setting up conv7/relu
I0228 10:24:28.206066 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.206085 12900 net.cpp:165] Memory required for data: 3026202656
I0228 10:24:28.206090 12900 layer_factory.hpp:77] Creating layer conv8/dw
I0228 10:24:28.206101 12900 net.cpp:100] Creating Layer conv8/dw
I0228 10:24:28.206107 12900 net.cpp:434] conv8/dw <- conv7
I0228 10:24:28.206115 12900 net.cpp:408] conv8/dw -> conv8/dw
I0228 10:24:28.206379 12900 net.cpp:150] Setting up conv8/dw
I0228 10:24:28.206388 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.206393 12900 net.cpp:165] Memory required for data: 3043946528
I0228 10:24:28.206400 12900 layer_factory.hpp:77] Creating layer conv8/dw/bn
I0228 10:24:28.206423 12900 net.cpp:100] Creating Layer conv8/dw/bn
I0228 10:24:28.206444 12900 net.cpp:434] conv8/dw/bn <- conv8/dw
I0228 10:24:28.206451 12900 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I0228 10:24:28.206667 12900 net.cpp:150] Setting up conv8/dw/bn
I0228 10:24:28.206676 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.206681 12900 net.cpp:165] Memory required for data: 3061690400
I0228 10:24:28.206689 12900 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0228 10:24:28.206704 12900 net.cpp:100] Creating Layer conv8/dw/scale
I0228 10:24:28.206725 12900 net.cpp:434] conv8/dw/scale <- conv8/dw
I0228 10:24:28.206732 12900 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I0228 10:24:28.206779 12900 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0228 10:24:28.206917 12900 net.cpp:150] Setting up conv8/dw/scale
I0228 10:24:28.206924 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.206928 12900 net.cpp:165] Memory required for data: 3079434272
I0228 10:24:28.206936 12900 layer_factory.hpp:77] Creating layer conv8/dw/relu
I0228 10:24:28.206955 12900 net.cpp:100] Creating Layer conv8/dw/relu
I0228 10:24:28.206960 12900 net.cpp:434] conv8/dw/relu <- conv8/dw
I0228 10:24:28.206969 12900 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I0228 10:24:28.207926 12900 net.cpp:150] Setting up conv8/dw/relu
I0228 10:24:28.207940 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.207945 12900 net.cpp:165] Memory required for data: 3097178144
I0228 10:24:28.207949 12900 layer_factory.hpp:77] Creating layer conv8
I0228 10:24:28.207978 12900 net.cpp:100] Creating Layer conv8
I0228 10:24:28.207983 12900 net.cpp:434] conv8 <- conv8/dw
I0228 10:24:28.207991 12900 net.cpp:408] conv8 -> conv8
I0228 10:24:28.213856 12900 net.cpp:150] Setting up conv8
I0228 10:24:28.213891 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.213896 12900 net.cpp:165] Memory required for data: 3114922016
I0228 10:24:28.213902 12900 layer_factory.hpp:77] Creating layer conv8/bn
I0228 10:24:28.213910 12900 net.cpp:100] Creating Layer conv8/bn
I0228 10:24:28.213917 12900 net.cpp:434] conv8/bn <- conv8
I0228 10:24:28.213924 12900 net.cpp:395] conv8/bn -> conv8 (in-place)
I0228 10:24:28.214148 12900 net.cpp:150] Setting up conv8/bn
I0228 10:24:28.214159 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.214164 12900 net.cpp:165] Memory required for data: 3132665888
I0228 10:24:28.214171 12900 layer_factory.hpp:77] Creating layer conv8/scale
I0228 10:24:28.214179 12900 net.cpp:100] Creating Layer conv8/scale
I0228 10:24:28.214184 12900 net.cpp:434] conv8/scale <- conv8
I0228 10:24:28.214192 12900 net.cpp:395] conv8/scale -> conv8 (in-place)
I0228 10:24:28.214239 12900 layer_factory.hpp:77] Creating layer conv8/scale
I0228 10:24:28.214375 12900 net.cpp:150] Setting up conv8/scale
I0228 10:24:28.214385 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.214390 12900 net.cpp:165] Memory required for data: 3150409760
I0228 10:24:28.214397 12900 layer_factory.hpp:77] Creating layer conv8/relu
I0228 10:24:28.214403 12900 net.cpp:100] Creating Layer conv8/relu
I0228 10:24:28.214408 12900 net.cpp:434] conv8/relu <- conv8
I0228 10:24:28.214417 12900 net.cpp:395] conv8/relu -> conv8 (in-place)
I0228 10:24:28.214941 12900 net.cpp:150] Setting up conv8/relu
I0228 10:24:28.214952 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.214972 12900 net.cpp:165] Memory required for data: 3168153632
I0228 10:24:28.214978 12900 layer_factory.hpp:77] Creating layer conv9/dw
I0228 10:24:28.214989 12900 net.cpp:100] Creating Layer conv9/dw
I0228 10:24:28.214994 12900 net.cpp:434] conv9/dw <- conv8
I0228 10:24:28.215003 12900 net.cpp:408] conv9/dw -> conv9/dw
I0228 10:24:28.215276 12900 net.cpp:150] Setting up conv9/dw
I0228 10:24:28.215286 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.215291 12900 net.cpp:165] Memory required for data: 3185897504
I0228 10:24:28.215311 12900 layer_factory.hpp:77] Creating layer conv9/dw/bn
I0228 10:24:28.215318 12900 net.cpp:100] Creating Layer conv9/dw/bn
I0228 10:24:28.215337 12900 net.cpp:434] conv9/dw/bn <- conv9/dw
I0228 10:24:28.215344 12900 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I0228 10:24:28.215560 12900 net.cpp:150] Setting up conv9/dw/bn
I0228 10:24:28.215570 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.215574 12900 net.cpp:165] Memory required for data: 3203641376
I0228 10:24:28.215582 12900 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0228 10:24:28.215589 12900 net.cpp:100] Creating Layer conv9/dw/scale
I0228 10:24:28.215595 12900 net.cpp:434] conv9/dw/scale <- conv9/dw
I0228 10:24:28.215601 12900 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I0228 10:24:28.215643 12900 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0228 10:24:28.215760 12900 net.cpp:150] Setting up conv9/dw/scale
I0228 10:24:28.215770 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.215773 12900 net.cpp:165] Memory required for data: 3221385248
I0228 10:24:28.215780 12900 layer_factory.hpp:77] Creating layer conv9/dw/relu
I0228 10:24:28.215801 12900 net.cpp:100] Creating Layer conv9/dw/relu
I0228 10:24:28.215822 12900 net.cpp:434] conv9/dw/relu <- conv9/dw
I0228 10:24:28.215829 12900 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I0228 10:24:28.216300 12900 net.cpp:150] Setting up conv9/dw/relu
I0228 10:24:28.216311 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.216327 12900 net.cpp:165] Memory required for data: 3239129120
I0228 10:24:28.216331 12900 layer_factory.hpp:77] Creating layer conv9
I0228 10:24:28.216341 12900 net.cpp:100] Creating Layer conv9
I0228 10:24:28.216361 12900 net.cpp:434] conv9 <- conv9/dw
I0228 10:24:28.216372 12900 net.cpp:408] conv9 -> conv9
I0228 10:24:28.221246 12900 net.cpp:150] Setting up conv9
I0228 10:24:28.221262 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.221266 12900 net.cpp:165] Memory required for data: 3256872992
I0228 10:24:28.221274 12900 layer_factory.hpp:77] Creating layer conv9/bn
I0228 10:24:28.221283 12900 net.cpp:100] Creating Layer conv9/bn
I0228 10:24:28.221288 12900 net.cpp:434] conv9/bn <- conv9
I0228 10:24:28.221295 12900 net.cpp:395] conv9/bn -> conv9 (in-place)
I0228 10:24:28.221536 12900 net.cpp:150] Setting up conv9/bn
I0228 10:24:28.221546 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.221550 12900 net.cpp:165] Memory required for data: 3274616864
I0228 10:24:28.221560 12900 layer_factory.hpp:77] Creating layer conv9/scale
I0228 10:24:28.221585 12900 net.cpp:100] Creating Layer conv9/scale
I0228 10:24:28.221588 12900 net.cpp:434] conv9/scale <- conv9
I0228 10:24:28.221596 12900 net.cpp:395] conv9/scale -> conv9 (in-place)
I0228 10:24:28.221642 12900 layer_factory.hpp:77] Creating layer conv9/scale
I0228 10:24:28.221765 12900 net.cpp:150] Setting up conv9/scale
I0228 10:24:28.221773 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.221777 12900 net.cpp:165] Memory required for data: 3292360736
I0228 10:24:28.221784 12900 layer_factory.hpp:77] Creating layer conv9/relu
I0228 10:24:28.221792 12900 net.cpp:100] Creating Layer conv9/relu
I0228 10:24:28.221797 12900 net.cpp:434] conv9/relu <- conv9
I0228 10:24:28.221802 12900 net.cpp:395] conv9/relu -> conv9 (in-place)
I0228 10:24:28.222304 12900 net.cpp:150] Setting up conv9/relu
I0228 10:24:28.222316 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.222321 12900 net.cpp:165] Memory required for data: 3310104608
I0228 10:24:28.222326 12900 layer_factory.hpp:77] Creating layer conv10/dw
I0228 10:24:28.222337 12900 net.cpp:100] Creating Layer conv10/dw
I0228 10:24:28.222342 12900 net.cpp:434] conv10/dw <- conv9
I0228 10:24:28.222349 12900 net.cpp:408] conv10/dw -> conv10/dw
I0228 10:24:28.222621 12900 net.cpp:150] Setting up conv10/dw
I0228 10:24:28.222631 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.222636 12900 net.cpp:165] Memory required for data: 3327848480
I0228 10:24:28.222642 12900 layer_factory.hpp:77] Creating layer conv10/dw/bn
I0228 10:24:28.222648 12900 net.cpp:100] Creating Layer conv10/dw/bn
I0228 10:24:28.222653 12900 net.cpp:434] conv10/dw/bn <- conv10/dw
I0228 10:24:28.222659 12900 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I0228 10:24:28.222870 12900 net.cpp:150] Setting up conv10/dw/bn
I0228 10:24:28.222879 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.222883 12900 net.cpp:165] Memory required for data: 3345592352
I0228 10:24:28.222892 12900 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0228 10:24:28.222898 12900 net.cpp:100] Creating Layer conv10/dw/scale
I0228 10:24:28.222903 12900 net.cpp:434] conv10/dw/scale <- conv10/dw
I0228 10:24:28.222908 12900 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I0228 10:24:28.222951 12900 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0228 10:24:28.223080 12900 net.cpp:150] Setting up conv10/dw/scale
I0228 10:24:28.223089 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.223094 12900 net.cpp:165] Memory required for data: 3363336224
I0228 10:24:28.223101 12900 layer_factory.hpp:77] Creating layer conv10/dw/relu
I0228 10:24:28.223119 12900 net.cpp:100] Creating Layer conv10/dw/relu
I0228 10:24:28.223124 12900 net.cpp:434] conv10/dw/relu <- conv10/dw
I0228 10:24:28.223129 12900 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I0228 10:24:28.224066 12900 net.cpp:150] Setting up conv10/dw/relu
I0228 10:24:28.224081 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.224086 12900 net.cpp:165] Memory required for data: 3381080096
I0228 10:24:28.224090 12900 layer_factory.hpp:77] Creating layer conv10
I0228 10:24:28.224119 12900 net.cpp:100] Creating Layer conv10
I0228 10:24:28.224143 12900 net.cpp:434] conv10 <- conv10/dw
I0228 10:24:28.224151 12900 net.cpp:408] conv10 -> conv10
I0228 10:24:28.229892 12900 net.cpp:150] Setting up conv10
I0228 10:24:28.229925 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.229930 12900 net.cpp:165] Memory required for data: 3398823968
I0228 10:24:28.229938 12900 layer_factory.hpp:77] Creating layer conv10/bn
I0228 10:24:28.229946 12900 net.cpp:100] Creating Layer conv10/bn
I0228 10:24:28.229952 12900 net.cpp:434] conv10/bn <- conv10
I0228 10:24:28.229959 12900 net.cpp:395] conv10/bn -> conv10 (in-place)
I0228 10:24:28.230170 12900 net.cpp:150] Setting up conv10/bn
I0228 10:24:28.230178 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.230183 12900 net.cpp:165] Memory required for data: 3416567840
I0228 10:24:28.230192 12900 layer_factory.hpp:77] Creating layer conv10/scale
I0228 10:24:28.230199 12900 net.cpp:100] Creating Layer conv10/scale
I0228 10:24:28.230204 12900 net.cpp:434] conv10/scale <- conv10
I0228 10:24:28.230211 12900 net.cpp:395] conv10/scale -> conv10 (in-place)
I0228 10:24:28.230257 12900 layer_factory.hpp:77] Creating layer conv10/scale
I0228 10:24:28.230396 12900 net.cpp:150] Setting up conv10/scale
I0228 10:24:28.230406 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.230412 12900 net.cpp:165] Memory required for data: 3434311712
I0228 10:24:28.230418 12900 layer_factory.hpp:77] Creating layer conv10/relu
I0228 10:24:28.230425 12900 net.cpp:100] Creating Layer conv10/relu
I0228 10:24:28.230430 12900 net.cpp:434] conv10/relu <- conv10
I0228 10:24:28.230437 12900 net.cpp:395] conv10/relu -> conv10 (in-place)
I0228 10:24:28.230902 12900 net.cpp:150] Setting up conv10/relu
I0228 10:24:28.230916 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.230921 12900 net.cpp:165] Memory required for data: 3452055584
I0228 10:24:28.230926 12900 layer_factory.hpp:77] Creating layer conv11/dw
I0228 10:24:28.230937 12900 net.cpp:100] Creating Layer conv11/dw
I0228 10:24:28.230943 12900 net.cpp:434] conv11/dw <- conv10
I0228 10:24:28.230950 12900 net.cpp:408] conv11/dw -> conv11/dw
I0228 10:24:28.231221 12900 net.cpp:150] Setting up conv11/dw
I0228 10:24:28.231231 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.231235 12900 net.cpp:165] Memory required for data: 3469799456
I0228 10:24:28.231241 12900 layer_factory.hpp:77] Creating layer conv11/dw/bn
I0228 10:24:28.231248 12900 net.cpp:100] Creating Layer conv11/dw/bn
I0228 10:24:28.231253 12900 net.cpp:434] conv11/dw/bn <- conv11/dw
I0228 10:24:28.231259 12900 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I0228 10:24:28.231505 12900 net.cpp:150] Setting up conv11/dw/bn
I0228 10:24:28.231515 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.231519 12900 net.cpp:165] Memory required for data: 3487543328
I0228 10:24:28.231544 12900 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0228 10:24:28.231556 12900 net.cpp:100] Creating Layer conv11/dw/scale
I0228 10:24:28.231561 12900 net.cpp:434] conv11/dw/scale <- conv11/dw
I0228 10:24:28.231568 12900 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I0228 10:24:28.231631 12900 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0228 10:24:28.231750 12900 net.cpp:150] Setting up conv11/dw/scale
I0228 10:24:28.231760 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.231763 12900 net.cpp:165] Memory required for data: 3505287200
I0228 10:24:28.231797 12900 layer_factory.hpp:77] Creating layer conv11/dw/relu
I0228 10:24:28.231803 12900 net.cpp:100] Creating Layer conv11/dw/relu
I0228 10:24:28.231809 12900 net.cpp:434] conv11/dw/relu <- conv11/dw
I0228 10:24:28.231815 12900 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I0228 10:24:28.232288 12900 net.cpp:150] Setting up conv11/dw/relu
I0228 10:24:28.232300 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.232306 12900 net.cpp:165] Memory required for data: 3523031072
I0228 10:24:28.232311 12900 layer_factory.hpp:77] Creating layer conv11
I0228 10:24:28.232321 12900 net.cpp:100] Creating Layer conv11
I0228 10:24:28.232326 12900 net.cpp:434] conv11 <- conv11/dw
I0228 10:24:28.232334 12900 net.cpp:408] conv11 -> conv11
I0228 10:24:28.237272 12900 net.cpp:150] Setting up conv11
I0228 10:24:28.237289 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.237309 12900 net.cpp:165] Memory required for data: 3540774944
I0228 10:24:28.237318 12900 layer_factory.hpp:77] Creating layer conv11/bn
I0228 10:24:28.237325 12900 net.cpp:100] Creating Layer conv11/bn
I0228 10:24:28.237330 12900 net.cpp:434] conv11/bn <- conv11
I0228 10:24:28.237339 12900 net.cpp:395] conv11/bn -> conv11 (in-place)
I0228 10:24:28.237557 12900 net.cpp:150] Setting up conv11/bn
I0228 10:24:28.237567 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.237583 12900 net.cpp:165] Memory required for data: 3558518816
I0228 10:24:28.237591 12900 layer_factory.hpp:77] Creating layer conv11/scale
I0228 10:24:28.237601 12900 net.cpp:100] Creating Layer conv11/scale
I0228 10:24:28.237606 12900 net.cpp:434] conv11/scale <- conv11
I0228 10:24:28.237617 12900 net.cpp:395] conv11/scale -> conv11 (in-place)
I0228 10:24:28.237663 12900 layer_factory.hpp:77] Creating layer conv11/scale
I0228 10:24:28.237792 12900 net.cpp:150] Setting up conv11/scale
I0228 10:24:28.237800 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.237805 12900 net.cpp:165] Memory required for data: 3576262688
I0228 10:24:28.237812 12900 layer_factory.hpp:77] Creating layer conv11/relu
I0228 10:24:28.237820 12900 net.cpp:100] Creating Layer conv11/relu
I0228 10:24:28.237824 12900 net.cpp:434] conv11/relu <- conv11
I0228 10:24:28.237833 12900 net.cpp:395] conv11/relu -> conv11 (in-place)
I0228 10:24:28.238909 12900 net.cpp:150] Setting up conv11/relu
I0228 10:24:28.238929 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.238932 12900 net.cpp:165] Memory required for data: 3594006560
I0228 10:24:28.238939 12900 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I0228 10:24:28.238946 12900 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I0228 10:24:28.238952 12900 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I0228 10:24:28.238961 12900 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I0228 10:24:28.238977 12900 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I0228 10:24:28.238987 12900 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I0228 10:24:28.238996 12900 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I0228 10:24:28.239074 12900 net.cpp:150] Setting up conv11_conv11/relu_0_split
I0228 10:24:28.239084 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.239090 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.239096 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.239102 12900 net.cpp:157] Top shape: 24 512 19 19 (4435968)
I0228 10:24:28.239106 12900 net.cpp:165] Memory required for data: 3664982048
I0228 10:24:28.239110 12900 layer_factory.hpp:77] Creating layer conv12/dw
I0228 10:24:28.239122 12900 net.cpp:100] Creating Layer conv12/dw
I0228 10:24:28.239131 12900 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I0228 10:24:28.239140 12900 net.cpp:408] conv12/dw -> conv12/dw
I0228 10:24:28.239401 12900 net.cpp:150] Setting up conv12/dw
I0228 10:24:28.239413 12900 net.cpp:157] Top shape: 24 512 10 10 (1228800)
I0228 10:24:28.239426 12900 net.cpp:165] Memory required for data: 3669897248
I0228 10:24:28.239435 12900 layer_factory.hpp:77] Creating layer conv12/dw/bn
I0228 10:24:28.239444 12900 net.cpp:100] Creating Layer conv12/dw/bn
I0228 10:24:28.239450 12900 net.cpp:434] conv12/dw/bn <- conv12/dw
I0228 10:24:28.239456 12900 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I0228 10:24:28.239701 12900 net.cpp:150] Setting up conv12/dw/bn
I0228 10:24:28.239711 12900 net.cpp:157] Top shape: 24 512 10 10 (1228800)
I0228 10:24:28.239717 12900 net.cpp:165] Memory required for data: 3674812448
I0228 10:24:28.239725 12900 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0228 10:24:28.239733 12900 net.cpp:100] Creating Layer conv12/dw/scale
I0228 10:24:28.239738 12900 net.cpp:434] conv12/dw/scale <- conv12/dw
I0228 10:24:28.239747 12900 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I0228 10:24:28.239802 12900 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0228 10:24:28.239936 12900 net.cpp:150] Setting up conv12/dw/scale
I0228 10:24:28.239945 12900 net.cpp:157] Top shape: 24 512 10 10 (1228800)
I0228 10:24:28.239950 12900 net.cpp:165] Memory required for data: 3679727648
I0228 10:24:28.239958 12900 layer_factory.hpp:77] Creating layer conv12/dw/relu
I0228 10:24:28.239964 12900 net.cpp:100] Creating Layer conv12/dw/relu
I0228 10:24:28.239967 12900 net.cpp:434] conv12/dw/relu <- conv12/dw
I0228 10:24:28.239976 12900 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I0228 10:24:28.240949 12900 net.cpp:150] Setting up conv12/dw/relu
I0228 10:24:28.240975 12900 net.cpp:157] Top shape: 24 512 10 10 (1228800)
I0228 10:24:28.240980 12900 net.cpp:165] Memory required for data: 3684642848
I0228 10:24:28.240988 12900 layer_factory.hpp:77] Creating layer conv12
I0228 10:24:28.240999 12900 net.cpp:100] Creating Layer conv12
I0228 10:24:28.241004 12900 net.cpp:434] conv12 <- conv12/dw
I0228 10:24:28.241014 12900 net.cpp:408] conv12 -> conv12
I0228 10:24:28.250298 12900 net.cpp:150] Setting up conv12
I0228 10:24:28.250331 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.250336 12900 net.cpp:165] Memory required for data: 3694473248
I0228 10:24:28.250344 12900 layer_factory.hpp:77] Creating layer conv12/bn
I0228 10:24:28.250351 12900 net.cpp:100] Creating Layer conv12/bn
I0228 10:24:28.250356 12900 net.cpp:434] conv12/bn <- conv12
I0228 10:24:28.250365 12900 net.cpp:395] conv12/bn -> conv12 (in-place)
I0228 10:24:28.250599 12900 net.cpp:150] Setting up conv12/bn
I0228 10:24:28.250612 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.250617 12900 net.cpp:165] Memory required for data: 3704303648
I0228 10:24:28.250624 12900 layer_factory.hpp:77] Creating layer conv12/scale
I0228 10:24:28.250633 12900 net.cpp:100] Creating Layer conv12/scale
I0228 10:24:28.250638 12900 net.cpp:434] conv12/scale <- conv12
I0228 10:24:28.250643 12900 net.cpp:395] conv12/scale -> conv12 (in-place)
I0228 10:24:28.250700 12900 layer_factory.hpp:77] Creating layer conv12/scale
I0228 10:24:28.250833 12900 net.cpp:150] Setting up conv12/scale
I0228 10:24:28.250844 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.250849 12900 net.cpp:165] Memory required for data: 3714134048
I0228 10:24:28.250871 12900 layer_factory.hpp:77] Creating layer conv12/relu
I0228 10:24:28.250880 12900 net.cpp:100] Creating Layer conv12/relu
I0228 10:24:28.250886 12900 net.cpp:434] conv12/relu <- conv12
I0228 10:24:28.250892 12900 net.cpp:395] conv12/relu -> conv12 (in-place)
I0228 10:24:28.251405 12900 net.cpp:150] Setting up conv12/relu
I0228 10:24:28.251416 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.251421 12900 net.cpp:165] Memory required for data: 3723964448
I0228 10:24:28.251426 12900 layer_factory.hpp:77] Creating layer conv13/dw
I0228 10:24:28.251436 12900 net.cpp:100] Creating Layer conv13/dw
I0228 10:24:28.251441 12900 net.cpp:434] conv13/dw <- conv12
I0228 10:24:28.251449 12900 net.cpp:408] conv13/dw -> conv13/dw
I0228 10:24:28.251817 12900 net.cpp:150] Setting up conv13/dw
I0228 10:24:28.251827 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.251840 12900 net.cpp:165] Memory required for data: 3733794848
I0228 10:24:28.251847 12900 layer_factory.hpp:77] Creating layer conv13/dw/bn
I0228 10:24:28.251855 12900 net.cpp:100] Creating Layer conv13/dw/bn
I0228 10:24:28.251860 12900 net.cpp:434] conv13/dw/bn <- conv13/dw
I0228 10:24:28.251865 12900 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I0228 10:24:28.252099 12900 net.cpp:150] Setting up conv13/dw/bn
I0228 10:24:28.252108 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.252112 12900 net.cpp:165] Memory required for data: 3743625248
I0228 10:24:28.252120 12900 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0228 10:24:28.252130 12900 net.cpp:100] Creating Layer conv13/dw/scale
I0228 10:24:28.252135 12900 net.cpp:434] conv13/dw/scale <- conv13/dw
I0228 10:24:28.252140 12900 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I0228 10:24:28.252182 12900 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0228 10:24:28.252315 12900 net.cpp:150] Setting up conv13/dw/scale
I0228 10:24:28.252324 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.252328 12900 net.cpp:165] Memory required for data: 3753455648
I0228 10:24:28.252336 12900 layer_factory.hpp:77] Creating layer conv13/dw/relu
I0228 10:24:28.252343 12900 net.cpp:100] Creating Layer conv13/dw/relu
I0228 10:24:28.252362 12900 net.cpp:434] conv13/dw/relu <- conv13/dw
I0228 10:24:28.252369 12900 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I0228 10:24:28.253415 12900 net.cpp:150] Setting up conv13/dw/relu
I0228 10:24:28.253443 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.253446 12900 net.cpp:165] Memory required for data: 3763286048
I0228 10:24:28.253451 12900 layer_factory.hpp:77] Creating layer conv13
I0228 10:24:28.253461 12900 net.cpp:100] Creating Layer conv13
I0228 10:24:28.253468 12900 net.cpp:434] conv13 <- conv13/dw
I0228 10:24:28.253476 12900 net.cpp:408] conv13 -> conv13
I0228 10:24:28.267256 12900 net.cpp:150] Setting up conv13
I0228 10:24:28.267272 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.267278 12900 net.cpp:165] Memory required for data: 3773116448
I0228 10:24:28.267284 12900 layer_factory.hpp:77] Creating layer conv13/bn
I0228 10:24:28.267293 12900 net.cpp:100] Creating Layer conv13/bn
I0228 10:24:28.267298 12900 net.cpp:434] conv13/bn <- conv13
I0228 10:24:28.267307 12900 net.cpp:395] conv13/bn -> conv13 (in-place)
I0228 10:24:28.267540 12900 net.cpp:150] Setting up conv13/bn
I0228 10:24:28.267550 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.267554 12900 net.cpp:165] Memory required for data: 3782946848
I0228 10:24:28.267563 12900 layer_factory.hpp:77] Creating layer conv13/scale
I0228 10:24:28.267573 12900 net.cpp:100] Creating Layer conv13/scale
I0228 10:24:28.267577 12900 net.cpp:434] conv13/scale <- conv13
I0228 10:24:28.267583 12900 net.cpp:395] conv13/scale -> conv13 (in-place)
I0228 10:24:28.267627 12900 layer_factory.hpp:77] Creating layer conv13/scale
I0228 10:24:28.267755 12900 net.cpp:150] Setting up conv13/scale
I0228 10:24:28.267763 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.267767 12900 net.cpp:165] Memory required for data: 3792777248
I0228 10:24:28.267776 12900 layer_factory.hpp:77] Creating layer conv13/relu
I0228 10:24:28.267783 12900 net.cpp:100] Creating Layer conv13/relu
I0228 10:24:28.267789 12900 net.cpp:434] conv13/relu <- conv13
I0228 10:24:28.267796 12900 net.cpp:395] conv13/relu -> conv13 (in-place)
I0228 10:24:28.268302 12900 net.cpp:150] Setting up conv13/relu
I0228 10:24:28.268316 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.268332 12900 net.cpp:165] Memory required for data: 3802607648
I0228 10:24:28.268335 12900 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I0228 10:24:28.268359 12900 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I0228 10:24:28.268365 12900 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I0228 10:24:28.268374 12900 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I0228 10:24:28.268393 12900 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I0228 10:24:28.268402 12900 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I0228 10:24:28.268410 12900 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I0228 10:24:28.268487 12900 net.cpp:150] Setting up conv13_conv13/relu_0_split
I0228 10:24:28.268496 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.268503 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.268508 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.268513 12900 net.cpp:157] Top shape: 24 1024 10 10 (2457600)
I0228 10:24:28.268517 12900 net.cpp:165] Memory required for data: 3841929248
I0228 10:24:28.268523 12900 layer_factory.hpp:77] Creating layer conv14_1
I0228 10:24:28.268534 12900 net.cpp:100] Creating Layer conv14_1
I0228 10:24:28.268539 12900 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I0228 10:24:28.268548 12900 net.cpp:408] conv14_1 -> conv14_1
I0228 10:24:28.274464 12900 net.cpp:150] Setting up conv14_1
I0228 10:24:28.274482 12900 net.cpp:157] Top shape: 24 256 10 10 (614400)
I0228 10:24:28.274502 12900 net.cpp:165] Memory required for data: 3844386848
I0228 10:24:28.274508 12900 layer_factory.hpp:77] Creating layer conv14_1/bn
I0228 10:24:28.274519 12900 net.cpp:100] Creating Layer conv14_1/bn
I0228 10:24:28.274538 12900 net.cpp:434] conv14_1/bn <- conv14_1
I0228 10:24:28.274560 12900 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I0228 10:24:28.274775 12900 net.cpp:150] Setting up conv14_1/bn
I0228 10:24:28.274786 12900 net.cpp:157] Top shape: 24 256 10 10 (614400)
I0228 10:24:28.274791 12900 net.cpp:165] Memory required for data: 3846844448
I0228 10:24:28.274798 12900 layer_factory.hpp:77] Creating layer conv14_1/scale
I0228 10:24:28.274806 12900 net.cpp:100] Creating Layer conv14_1/scale
I0228 10:24:28.274811 12900 net.cpp:434] conv14_1/scale <- conv14_1
I0228 10:24:28.274817 12900 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I0228 10:24:28.274863 12900 layer_factory.hpp:77] Creating layer conv14_1/scale
I0228 10:24:28.274983 12900 net.cpp:150] Setting up conv14_1/scale
I0228 10:24:28.274993 12900 net.cpp:157] Top shape: 24 256 10 10 (614400)
I0228 10:24:28.274997 12900 net.cpp:165] Memory required for data: 3849302048
I0228 10:24:28.275003 12900 layer_factory.hpp:77] Creating layer conv14_1/relu
I0228 10:24:28.275012 12900 net.cpp:100] Creating Layer conv14_1/relu
I0228 10:24:28.275017 12900 net.cpp:434] conv14_1/relu <- conv14_1
I0228 10:24:28.275022 12900 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I0228 10:24:28.275532 12900 net.cpp:150] Setting up conv14_1/relu
I0228 10:24:28.275543 12900 net.cpp:157] Top shape: 24 256 10 10 (614400)
I0228 10:24:28.275564 12900 net.cpp:165] Memory required for data: 3851759648
I0228 10:24:28.275569 12900 layer_factory.hpp:77] Creating layer conv14_2
I0228 10:24:28.275580 12900 net.cpp:100] Creating Layer conv14_2
I0228 10:24:28.275585 12900 net.cpp:434] conv14_2 <- conv14_1
I0228 10:24:28.275594 12900 net.cpp:408] conv14_2 -> conv14_2
I0228 10:24:28.291455 12900 net.cpp:150] Setting up conv14_2
I0228 10:24:28.291473 12900 net.cpp:157] Top shape: 24 512 5 5 (307200)
I0228 10:24:28.291478 12900 net.cpp:165] Memory required for data: 3852988448
I0228 10:24:28.291486 12900 layer_factory.hpp:77] Creating layer conv14_2/bn
I0228 10:24:28.291494 12900 net.cpp:100] Creating Layer conv14_2/bn
I0228 10:24:28.291499 12900 net.cpp:434] conv14_2/bn <- conv14_2
I0228 10:24:28.291505 12900 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I0228 10:24:28.291749 12900 net.cpp:150] Setting up conv14_2/bn
I0228 10:24:28.291759 12900 net.cpp:157] Top shape: 24 512 5 5 (307200)
I0228 10:24:28.291764 12900 net.cpp:165] Memory required for data: 3854217248
I0228 10:24:28.291771 12900 layer_factory.hpp:77] Creating layer conv14_2/scale
I0228 10:24:28.291780 12900 net.cpp:100] Creating Layer conv14_2/scale
I0228 10:24:28.291785 12900 net.cpp:434] conv14_2/scale <- conv14_2
I0228 10:24:28.291803 12900 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I0228 10:24:28.291849 12900 layer_factory.hpp:77] Creating layer conv14_2/scale
I0228 10:24:28.291978 12900 net.cpp:150] Setting up conv14_2/scale
I0228 10:24:28.291988 12900 net.cpp:157] Top shape: 24 512 5 5 (307200)
I0228 10:24:28.291992 12900 net.cpp:165] Memory required for data: 3855446048
I0228 10:24:28.291999 12900 layer_factory.hpp:77] Creating layer conv14_2/relu
I0228 10:24:28.292008 12900 net.cpp:100] Creating Layer conv14_2/relu
I0228 10:24:28.292012 12900 net.cpp:434] conv14_2/relu <- conv14_2
I0228 10:24:28.292017 12900 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I0228 10:24:28.292526 12900 net.cpp:150] Setting up conv14_2/relu
I0228 10:24:28.292554 12900 net.cpp:157] Top shape: 24 512 5 5 (307200)
I0228 10:24:28.292574 12900 net.cpp:165] Memory required for data: 3856674848
I0228 10:24:28.292579 12900 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I0228 10:24:28.292587 12900 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I0228 10:24:28.292593 12900 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I0228 10:24:28.292601 12900 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I0228 10:24:28.292609 12900 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I0228 10:24:28.292616 12900 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I0228 10:24:28.292624 12900 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I0228 10:24:28.292699 12900 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I0228 10:24:28.292707 12900 net.cpp:157] Top shape: 24 512 5 5 (307200)
I0228 10:24:28.292712 12900 net.cpp:157] Top shape: 24 512 5 5 (307200)
I0228 10:24:28.292718 12900 net.cpp:157] Top shape: 24 512 5 5 (307200)
I0228 10:24:28.292723 12900 net.cpp:157] Top shape: 24 512 5 5 (307200)
I0228 10:24:28.292727 12900 net.cpp:165] Memory required for data: 3861590048
I0228 10:24:28.292732 12900 layer_factory.hpp:77] Creating layer conv15_1
I0228 10:24:28.292743 12900 net.cpp:100] Creating Layer conv15_1
I0228 10:24:28.292748 12900 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I0228 10:24:28.292757 12900 net.cpp:408] conv15_1 -> conv15_1
I0228 10:24:28.295621 12900 net.cpp:150] Setting up conv15_1
I0228 10:24:28.295653 12900 net.cpp:157] Top shape: 24 128 5 5 (76800)
I0228 10:24:28.295661 12900 net.cpp:165] Memory required for data: 3861897248
I0228 10:24:28.295668 12900 layer_factory.hpp:77] Creating layer conv15_1/bn
I0228 10:24:28.295675 12900 net.cpp:100] Creating Layer conv15_1/bn
I0228 10:24:28.295681 12900 net.cpp:434] conv15_1/bn <- conv15_1
I0228 10:24:28.295687 12900 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I0228 10:24:28.295923 12900 net.cpp:150] Setting up conv15_1/bn
I0228 10:24:28.295933 12900 net.cpp:157] Top shape: 24 128 5 5 (76800)
I0228 10:24:28.295938 12900 net.cpp:165] Memory required for data: 3862204448
I0228 10:24:28.295946 12900 layer_factory.hpp:77] Creating layer conv15_1/scale
I0228 10:24:28.295954 12900 net.cpp:100] Creating Layer conv15_1/scale
I0228 10:24:28.295974 12900 net.cpp:434] conv15_1/scale <- conv15_1
I0228 10:24:28.295984 12900 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I0228 10:24:28.296032 12900 layer_factory.hpp:77] Creating layer conv15_1/scale
I0228 10:24:28.296162 12900 net.cpp:150] Setting up conv15_1/scale
I0228 10:24:28.296172 12900 net.cpp:157] Top shape: 24 128 5 5 (76800)
I0228 10:24:28.296178 12900 net.cpp:165] Memory required for data: 3862511648
I0228 10:24:28.296185 12900 layer_factory.hpp:77] Creating layer conv15_1/relu
I0228 10:24:28.296193 12900 net.cpp:100] Creating Layer conv15_1/relu
I0228 10:24:28.296198 12900 net.cpp:434] conv15_1/relu <- conv15_1
I0228 10:24:28.296205 12900 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I0228 10:24:28.297289 12900 net.cpp:150] Setting up conv15_1/relu
I0228 10:24:28.297304 12900 net.cpp:157] Top shape: 24 128 5 5 (76800)
I0228 10:24:28.297318 12900 net.cpp:165] Memory required for data: 3862818848
I0228 10:24:28.297324 12900 layer_factory.hpp:77] Creating layer conv15_2
I0228 10:24:28.297335 12900 net.cpp:100] Creating Layer conv15_2
I0228 10:24:28.297340 12900 net.cpp:434] conv15_2 <- conv15_1
I0228 10:24:28.297348 12900 net.cpp:408] conv15_2 -> conv15_2
I0228 10:24:28.303418 12900 net.cpp:150] Setting up conv15_2
I0228 10:24:28.303436 12900 net.cpp:157] Top shape: 24 256 3 3 (55296)
I0228 10:24:28.303457 12900 net.cpp:165] Memory required for data: 3863040032
I0228 10:24:28.303463 12900 layer_factory.hpp:77] Creating layer conv15_2/bn
I0228 10:24:28.303472 12900 net.cpp:100] Creating Layer conv15_2/bn
I0228 10:24:28.303478 12900 net.cpp:434] conv15_2/bn <- conv15_2
I0228 10:24:28.303485 12900 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I0228 10:24:28.303733 12900 net.cpp:150] Setting up conv15_2/bn
I0228 10:24:28.303745 12900 net.cpp:157] Top shape: 24 256 3 3 (55296)
I0228 10:24:28.303750 12900 net.cpp:165] Memory required for data: 3863261216
I0228 10:24:28.303757 12900 layer_factory.hpp:77] Creating layer conv15_2/scale
I0228 10:24:28.303766 12900 net.cpp:100] Creating Layer conv15_2/scale
I0228 10:24:28.303771 12900 net.cpp:434] conv15_2/scale <- conv15_2
I0228 10:24:28.303779 12900 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I0228 10:24:28.303824 12900 layer_factory.hpp:77] Creating layer conv15_2/scale
I0228 10:24:28.303951 12900 net.cpp:150] Setting up conv15_2/scale
I0228 10:24:28.303961 12900 net.cpp:157] Top shape: 24 256 3 3 (55296)
I0228 10:24:28.303966 12900 net.cpp:165] Memory required for data: 3863482400
I0228 10:24:28.303973 12900 layer_factory.hpp:77] Creating layer conv15_2/relu
I0228 10:24:28.303997 12900 net.cpp:100] Creating Layer conv15_2/relu
I0228 10:24:28.304005 12900 net.cpp:434] conv15_2/relu <- conv15_2
I0228 10:24:28.304010 12900 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I0228 10:24:28.304504 12900 net.cpp:150] Setting up conv15_2/relu
I0228 10:24:28.304517 12900 net.cpp:157] Top shape: 24 256 3 3 (55296)
I0228 10:24:28.304538 12900 net.cpp:165] Memory required for data: 3863703584
I0228 10:24:28.304543 12900 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I0228 10:24:28.304551 12900 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I0228 10:24:28.304556 12900 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I0228 10:24:28.304564 12900 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I0228 10:24:28.304572 12900 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I0228 10:24:28.304582 12900 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I0228 10:24:28.304589 12900 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I0228 10:24:28.304671 12900 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I0228 10:24:28.304678 12900 net.cpp:157] Top shape: 24 256 3 3 (55296)
I0228 10:24:28.304684 12900 net.cpp:157] Top shape: 24 256 3 3 (55296)
I0228 10:24:28.304689 12900 net.cpp:157] Top shape: 24 256 3 3 (55296)
I0228 10:24:28.304695 12900 net.cpp:157] Top shape: 24 256 3 3 (55296)
I0228 10:24:28.304699 12900 net.cpp:165] Memory required for data: 3864588320
I0228 10:24:28.304704 12900 layer_factory.hpp:77] Creating layer conv16_1
I0228 10:24:28.304718 12900 net.cpp:100] Creating Layer conv16_1
I0228 10:24:28.304725 12900 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I0228 10:24:28.304733 12900 net.cpp:408] conv16_1 -> conv16_1
I0228 10:24:28.307371 12900 net.cpp:150] Setting up conv16_1
I0228 10:24:28.307402 12900 net.cpp:157] Top shape: 24 128 3 3 (27648)
I0228 10:24:28.307409 12900 net.cpp:165] Memory required for data: 3864698912
I0228 10:24:28.307415 12900 layer_factory.hpp:77] Creating layer conv16_1/bn
I0228 10:24:28.307425 12900 net.cpp:100] Creating Layer conv16_1/bn
I0228 10:24:28.307446 12900 net.cpp:434] conv16_1/bn <- conv16_1
I0228 10:24:28.307453 12900 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I0228 10:24:28.307714 12900 net.cpp:150] Setting up conv16_1/bn
I0228 10:24:28.307735 12900 net.cpp:157] Top shape: 24 128 3 3 (27648)
I0228 10:24:28.307739 12900 net.cpp:165] Memory required for data: 3864809504
I0228 10:24:28.307749 12900 layer_factory.hpp:77] Creating layer conv16_1/scale
I0228 10:24:28.307757 12900 net.cpp:100] Creating Layer conv16_1/scale
I0228 10:24:28.307762 12900 net.cpp:434] conv16_1/scale <- conv16_1
I0228 10:24:28.307770 12900 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I0228 10:24:28.307821 12900 layer_factory.hpp:77] Creating layer conv16_1/scale
I0228 10:24:28.307946 12900 net.cpp:150] Setting up conv16_1/scale
I0228 10:24:28.307956 12900 net.cpp:157] Top shape: 24 128 3 3 (27648)
I0228 10:24:28.307960 12900 net.cpp:165] Memory required for data: 3864920096
I0228 10:24:28.307968 12900 layer_factory.hpp:77] Creating layer conv16_1/relu
I0228 10:24:28.307977 12900 net.cpp:100] Creating Layer conv16_1/relu
I0228 10:24:28.307982 12900 net.cpp:434] conv16_1/relu <- conv16_1
I0228 10:24:28.307988 12900 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I0228 10:24:28.308476 12900 net.cpp:150] Setting up conv16_1/relu
I0228 10:24:28.308506 12900 net.cpp:157] Top shape: 24 128 3 3 (27648)
I0228 10:24:28.308511 12900 net.cpp:165] Memory required for data: 3865030688
I0228 10:24:28.308516 12900 layer_factory.hpp:77] Creating layer conv16_2
I0228 10:24:28.308526 12900 net.cpp:100] Creating Layer conv16_2
I0228 10:24:28.308547 12900 net.cpp:434] conv16_2 <- conv16_1
I0228 10:24:28.308555 12900 net.cpp:408] conv16_2 -> conv16_2
I0228 10:24:28.314589 12900 net.cpp:150] Setting up conv16_2
I0228 10:24:28.314605 12900 net.cpp:157] Top shape: 24 256 2 2 (24576)
I0228 10:24:28.314610 12900 net.cpp:165] Memory required for data: 3865128992
I0228 10:24:28.314616 12900 layer_factory.hpp:77] Creating layer conv16_2/bn
I0228 10:24:28.314625 12900 net.cpp:100] Creating Layer conv16_2/bn
I0228 10:24:28.314630 12900 net.cpp:434] conv16_2/bn <- conv16_2
I0228 10:24:28.314636 12900 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I0228 10:24:28.314867 12900 net.cpp:150] Setting up conv16_2/bn
I0228 10:24:28.314877 12900 net.cpp:157] Top shape: 24 256 2 2 (24576)
I0228 10:24:28.314882 12900 net.cpp:165] Memory required for data: 3865227296
I0228 10:24:28.314890 12900 layer_factory.hpp:77] Creating layer conv16_2/scale
I0228 10:24:28.314898 12900 net.cpp:100] Creating Layer conv16_2/scale
I0228 10:24:28.314903 12900 net.cpp:434] conv16_2/scale <- conv16_2
I0228 10:24:28.314910 12900 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I0228 10:24:28.314971 12900 layer_factory.hpp:77] Creating layer conv16_2/scale
I0228 10:24:28.315095 12900 net.cpp:150] Setting up conv16_2/scale
I0228 10:24:28.315104 12900 net.cpp:157] Top shape: 24 256 2 2 (24576)
I0228 10:24:28.315109 12900 net.cpp:165] Memory required for data: 3865325600
I0228 10:24:28.315116 12900 layer_factory.hpp:77] Creating layer conv16_2/relu
I0228 10:24:28.315124 12900 net.cpp:100] Creating Layer conv16_2/relu
I0228 10:24:28.315130 12900 net.cpp:434] conv16_2/relu <- conv16_2
I0228 10:24:28.315136 12900 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I0228 10:24:28.316165 12900 net.cpp:150] Setting up conv16_2/relu
I0228 10:24:28.316181 12900 net.cpp:157] Top shape: 24 256 2 2 (24576)
I0228 10:24:28.316185 12900 net.cpp:165] Memory required for data: 3865423904
I0228 10:24:28.316191 12900 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I0228 10:24:28.316198 12900 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I0228 10:24:28.316203 12900 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I0228 10:24:28.316211 12900 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I0228 10:24:28.316220 12900 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I0228 10:24:28.316227 12900 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I0228 10:24:28.316236 12900 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I0228 10:24:28.316311 12900 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I0228 10:24:28.316361 12900 net.cpp:157] Top shape: 24 256 2 2 (24576)
I0228 10:24:28.316368 12900 net.cpp:157] Top shape: 24 256 2 2 (24576)
I0228 10:24:28.316375 12900 net.cpp:157] Top shape: 24 256 2 2 (24576)
I0228 10:24:28.316380 12900 net.cpp:157] Top shape: 24 256 2 2 (24576)
I0228 10:24:28.316385 12900 net.cpp:165] Memory required for data: 3865817120
I0228 10:24:28.316390 12900 layer_factory.hpp:77] Creating layer conv17_1
I0228 10:24:28.316401 12900 net.cpp:100] Creating Layer conv17_1
I0228 10:24:28.316406 12900 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I0228 10:24:28.316416 12900 net.cpp:408] conv17_1 -> conv17_1
I0228 10:24:28.318827 12900 net.cpp:150] Setting up conv17_1
I0228 10:24:28.318842 12900 net.cpp:157] Top shape: 24 64 2 2 (6144)
I0228 10:24:28.318862 12900 net.cpp:165] Memory required for data: 3865841696
I0228 10:24:28.318871 12900 layer_factory.hpp:77] Creating layer conv17_1/bn
I0228 10:24:28.318878 12900 net.cpp:100] Creating Layer conv17_1/bn
I0228 10:24:28.318883 12900 net.cpp:434] conv17_1/bn <- conv17_1
I0228 10:24:28.318907 12900 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I0228 10:24:28.319144 12900 net.cpp:150] Setting up conv17_1/bn
I0228 10:24:28.319154 12900 net.cpp:157] Top shape: 24 64 2 2 (6144)
I0228 10:24:28.319159 12900 net.cpp:165] Memory required for data: 3865866272
I0228 10:24:28.319167 12900 layer_factory.hpp:77] Creating layer conv17_1/scale
I0228 10:24:28.319177 12900 net.cpp:100] Creating Layer conv17_1/scale
I0228 10:24:28.319182 12900 net.cpp:434] conv17_1/scale <- conv17_1
I0228 10:24:28.319190 12900 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I0228 10:24:28.319237 12900 layer_factory.hpp:77] Creating layer conv17_1/scale
I0228 10:24:28.319389 12900 net.cpp:150] Setting up conv17_1/scale
I0228 10:24:28.319399 12900 net.cpp:157] Top shape: 24 64 2 2 (6144)
I0228 10:24:28.319403 12900 net.cpp:165] Memory required for data: 3865890848
I0228 10:24:28.319411 12900 layer_factory.hpp:77] Creating layer conv17_1/relu
I0228 10:24:28.319418 12900 net.cpp:100] Creating Layer conv17_1/relu
I0228 10:24:28.319423 12900 net.cpp:434] conv17_1/relu <- conv17_1
I0228 10:24:28.319432 12900 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I0228 10:24:28.319929 12900 net.cpp:150] Setting up conv17_1/relu
I0228 10:24:28.319957 12900 net.cpp:157] Top shape: 24 64 2 2 (6144)
I0228 10:24:28.319960 12900 net.cpp:165] Memory required for data: 3865915424
I0228 10:24:28.319980 12900 layer_factory.hpp:77] Creating layer conv17_2
I0228 10:24:28.319991 12900 net.cpp:100] Creating Layer conv17_2
I0228 10:24:28.319996 12900 net.cpp:434] conv17_2 <- conv17_1
I0228 10:24:28.320005 12900 net.cpp:408] conv17_2 -> conv17_2
I0228 10:24:28.323498 12900 net.cpp:150] Setting up conv17_2
I0228 10:24:28.323514 12900 net.cpp:157] Top shape: 24 128 1 1 (3072)
I0228 10:24:28.323519 12900 net.cpp:165] Memory required for data: 3865927712
I0228 10:24:28.323526 12900 layer_factory.hpp:77] Creating layer conv17_2/bn
I0228 10:24:28.323534 12900 net.cpp:100] Creating Layer conv17_2/bn
I0228 10:24:28.323539 12900 net.cpp:434] conv17_2/bn <- conv17_2
I0228 10:24:28.323546 12900 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I0228 10:24:28.323781 12900 net.cpp:150] Setting up conv17_2/bn
I0228 10:24:28.323791 12900 net.cpp:157] Top shape: 24 128 1 1 (3072)
I0228 10:24:28.323796 12900 net.cpp:165] Memory required for data: 3865940000
I0228 10:24:28.323804 12900 layer_factory.hpp:77] Creating layer conv17_2/scale
I0228 10:24:28.323813 12900 net.cpp:100] Creating Layer conv17_2/scale
I0228 10:24:28.323818 12900 net.cpp:434] conv17_2/scale <- conv17_2
I0228 10:24:28.323824 12900 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I0228 10:24:28.323878 12900 layer_factory.hpp:77] Creating layer conv17_2/scale
I0228 10:24:28.324002 12900 net.cpp:150] Setting up conv17_2/scale
I0228 10:24:28.324010 12900 net.cpp:157] Top shape: 24 128 1 1 (3072)
I0228 10:24:28.324015 12900 net.cpp:165] Memory required for data: 3865952288
I0228 10:24:28.324023 12900 layer_factory.hpp:77] Creating layer conv17_2/relu
I0228 10:24:28.324039 12900 net.cpp:100] Creating Layer conv17_2/relu
I0228 10:24:28.324044 12900 net.cpp:434] conv17_2/relu <- conv17_2
I0228 10:24:28.324053 12900 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I0228 10:24:28.324585 12900 net.cpp:150] Setting up conv17_2/relu
I0228 10:24:28.324597 12900 net.cpp:157] Top shape: 24 128 1 1 (3072)
I0228 10:24:28.324614 12900 net.cpp:165] Memory required for data: 3865964576
I0228 10:24:28.324618 12900 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I0228 10:24:28.324627 12900 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I0228 10:24:28.324632 12900 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I0228 10:24:28.324640 12900 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I0228 10:24:28.324658 12900 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I0228 10:24:28.324669 12900 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I0228 10:24:28.324746 12900 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I0228 10:24:28.324755 12900 net.cpp:157] Top shape: 24 128 1 1 (3072)
I0228 10:24:28.324761 12900 net.cpp:157] Top shape: 24 128 1 1 (3072)
I0228 10:24:28.324767 12900 net.cpp:157] Top shape: 24 128 1 1 (3072)
I0228 10:24:28.324771 12900 net.cpp:165] Memory required for data: 3866001440
I0228 10:24:28.324775 12900 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I0228 10:24:28.324786 12900 net.cpp:100] Creating Layer conv11_mbox_loc
I0228 10:24:28.324791 12900 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I0228 10:24:28.324800 12900 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I0228 10:24:28.327173 12900 net.cpp:150] Setting up conv11_mbox_loc
I0228 10:24:28.327189 12900 net.cpp:157] Top shape: 24 12 19 19 (103968)
I0228 10:24:28.327196 12900 net.cpp:165] Memory required for data: 3866417312
I0228 10:24:28.327205 12900 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I0228 10:24:28.327214 12900 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I0228 10:24:28.327221 12900 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I0228 10:24:28.327230 12900 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I0228 10:24:28.327359 12900 net.cpp:150] Setting up conv11_mbox_loc_perm
I0228 10:24:28.327368 12900 net.cpp:157] Top shape: 24 19 19 12 (103968)
I0228 10:24:28.327373 12900 net.cpp:165] Memory required for data: 3866833184
I0228 10:24:28.327378 12900 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I0228 10:24:28.327386 12900 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I0228 10:24:28.327391 12900 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I0228 10:24:28.327399 12900 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I0228 10:24:28.327430 12900 net.cpp:150] Setting up conv11_mbox_loc_flat
I0228 10:24:28.327438 12900 net.cpp:157] Top shape: 24 4332 (103968)
I0228 10:24:28.327442 12900 net.cpp:165] Memory required for data: 3867249056
I0228 10:24:28.327447 12900 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I0228 10:24:28.327461 12900 net.cpp:100] Creating Layer conv11_mbox_conf_new
I0228 10:24:28.327467 12900 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I0228 10:24:28.327476 12900 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I0228 10:24:28.329828 12900 net.cpp:150] Setting up conv11_mbox_conf_new
I0228 10:24:28.329844 12900 net.cpp:157] Top shape: 24 12 19 19 (103968)
I0228 10:24:28.329865 12900 net.cpp:165] Memory required for data: 3867664928
I0228 10:24:28.329874 12900 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I0228 10:24:28.329882 12900 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I0228 10:24:28.329888 12900 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I0228 10:24:28.329897 12900 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I0228 10:24:28.330016 12900 net.cpp:150] Setting up conv11_mbox_conf_perm
I0228 10:24:28.330024 12900 net.cpp:157] Top shape: 24 19 19 12 (103968)
I0228 10:24:28.330040 12900 net.cpp:165] Memory required for data: 3868080800
I0228 10:24:28.330045 12900 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I0228 10:24:28.330054 12900 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I0228 10:24:28.330073 12900 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I0228 10:24:28.330099 12900 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I0228 10:24:28.330132 12900 net.cpp:150] Setting up conv11_mbox_conf_flat
I0228 10:24:28.330140 12900 net.cpp:157] Top shape: 24 4332 (103968)
I0228 10:24:28.330144 12900 net.cpp:165] Memory required for data: 3868496672
I0228 10:24:28.330150 12900 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I0228 10:24:28.330159 12900 net.cpp:100] Creating Layer conv11_mbox_priorbox
I0228 10:24:28.330164 12900 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I0228 10:24:28.330171 12900 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I0228 10:24:28.330180 12900 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I0228 10:24:28.330216 12900 net.cpp:150] Setting up conv11_mbox_priorbox
I0228 10:24:28.330224 12900 net.cpp:157] Top shape: 1 2 4332 (8664)
I0228 10:24:28.330229 12900 net.cpp:165] Memory required for data: 3868531328
I0228 10:24:28.330235 12900 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I0228 10:24:28.330245 12900 net.cpp:100] Creating Layer conv13_mbox_loc
I0228 10:24:28.330252 12900 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I0228 10:24:28.330261 12900 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I0228 10:24:28.332883 12900 net.cpp:150] Setting up conv13_mbox_loc
I0228 10:24:28.332898 12900 net.cpp:157] Top shape: 24 24 10 10 (57600)
I0228 10:24:28.332919 12900 net.cpp:165] Memory required for data: 3868761728
I0228 10:24:28.332927 12900 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I0228 10:24:28.332937 12900 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I0228 10:24:28.332942 12900 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I0228 10:24:28.332949 12900 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I0228 10:24:28.333070 12900 net.cpp:150] Setting up conv13_mbox_loc_perm
I0228 10:24:28.333081 12900 net.cpp:157] Top shape: 24 10 10 24 (57600)
I0228 10:24:28.333084 12900 net.cpp:165] Memory required for data: 3868992128
I0228 10:24:28.333088 12900 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I0228 10:24:28.333096 12900 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I0228 10:24:28.333101 12900 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I0228 10:24:28.333108 12900 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I0228 10:24:28.333137 12900 net.cpp:150] Setting up conv13_mbox_loc_flat
I0228 10:24:28.333144 12900 net.cpp:157] Top shape: 24 2400 (57600)
I0228 10:24:28.333149 12900 net.cpp:165] Memory required for data: 3869222528
I0228 10:24:28.333154 12900 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I0228 10:24:28.333165 12900 net.cpp:100] Creating Layer conv13_mbox_conf_new
I0228 10:24:28.333170 12900 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I0228 10:24:28.333179 12900 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I0228 10:24:28.335667 12900 net.cpp:150] Setting up conv13_mbox_conf_new
I0228 10:24:28.335683 12900 net.cpp:157] Top shape: 24 24 10 10 (57600)
I0228 10:24:28.335687 12900 net.cpp:165] Memory required for data: 3869452928
I0228 10:24:28.335696 12900 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I0228 10:24:28.335706 12900 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I0228 10:24:28.335712 12900 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I0228 10:24:28.335719 12900 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I0228 10:24:28.335845 12900 net.cpp:150] Setting up conv13_mbox_conf_perm
I0228 10:24:28.335855 12900 net.cpp:157] Top shape: 24 10 10 24 (57600)
I0228 10:24:28.335860 12900 net.cpp:165] Memory required for data: 3869683328
I0228 10:24:28.335876 12900 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I0228 10:24:28.335886 12900 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I0228 10:24:28.335891 12900 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I0228 10:24:28.335897 12900 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I0228 10:24:28.335928 12900 net.cpp:150] Setting up conv13_mbox_conf_flat
I0228 10:24:28.335937 12900 net.cpp:157] Top shape: 24 2400 (57600)
I0228 10:24:28.335942 12900 net.cpp:165] Memory required for data: 3869913728
I0228 10:24:28.335947 12900 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I0228 10:24:28.335955 12900 net.cpp:100] Creating Layer conv13_mbox_priorbox
I0228 10:24:28.335961 12900 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I0228 10:24:28.335968 12900 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I0228 10:24:28.335974 12900 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I0228 10:24:28.336007 12900 net.cpp:150] Setting up conv13_mbox_priorbox
I0228 10:24:28.336016 12900 net.cpp:157] Top shape: 1 2 2400 (4800)
I0228 10:24:28.336020 12900 net.cpp:165] Memory required for data: 3869932928
I0228 10:24:28.336024 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I0228 10:24:28.336035 12900 net.cpp:100] Creating Layer conv14_2_mbox_loc
I0228 10:24:28.336042 12900 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I0228 10:24:28.336052 12900 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I0228 10:24:28.338697 12900 net.cpp:150] Setting up conv14_2_mbox_loc
I0228 10:24:28.338714 12900 net.cpp:157] Top shape: 24 24 5 5 (14400)
I0228 10:24:28.338719 12900 net.cpp:165] Memory required for data: 3869990528
I0228 10:24:28.338727 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I0228 10:24:28.338737 12900 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I0228 10:24:28.338743 12900 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I0228 10:24:28.338752 12900 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I0228 10:24:28.338873 12900 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I0228 10:24:28.338882 12900 net.cpp:157] Top shape: 24 5 5 24 (14400)
I0228 10:24:28.338886 12900 net.cpp:165] Memory required for data: 3870048128
I0228 10:24:28.338892 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I0228 10:24:28.338901 12900 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I0228 10:24:28.338907 12900 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I0228 10:24:28.338912 12900 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I0228 10:24:28.338943 12900 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I0228 10:24:28.338950 12900 net.cpp:157] Top shape: 24 600 (14400)
I0228 10:24:28.338954 12900 net.cpp:165] Memory required for data: 3870105728
I0228 10:24:28.338958 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I0228 10:24:28.338970 12900 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I0228 10:24:28.338977 12900 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I0228 10:24:28.338985 12900 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I0228 10:24:28.341521 12900 net.cpp:150] Setting up conv14_2_mbox_conf_new
I0228 10:24:28.341552 12900 net.cpp:157] Top shape: 24 24 5 5 (14400)
I0228 10:24:28.341557 12900 net.cpp:165] Memory required for data: 3870163328
I0228 10:24:28.341565 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I0228 10:24:28.341575 12900 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I0228 10:24:28.341581 12900 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I0228 10:24:28.341589 12900 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I0228 10:24:28.341735 12900 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I0228 10:24:28.341747 12900 net.cpp:157] Top shape: 24 5 5 24 (14400)
I0228 10:24:28.341751 12900 net.cpp:165] Memory required for data: 3870220928
I0228 10:24:28.341756 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I0228 10:24:28.341773 12900 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I0228 10:24:28.341778 12900 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I0228 10:24:28.341785 12900 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I0228 10:24:28.341815 12900 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I0228 10:24:28.341825 12900 net.cpp:157] Top shape: 24 600 (14400)
I0228 10:24:28.341830 12900 net.cpp:165] Memory required for data: 3870278528
I0228 10:24:28.341835 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I0228 10:24:28.341842 12900 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I0228 10:24:28.341847 12900 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I0228 10:24:28.341853 12900 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I0228 10:24:28.341862 12900 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I0228 10:24:28.341892 12900 net.cpp:150] Setting up conv14_2_mbox_priorbox
I0228 10:24:28.341902 12900 net.cpp:157] Top shape: 1 2 600 (1200)
I0228 10:24:28.341905 12900 net.cpp:165] Memory required for data: 3870283328
I0228 10:24:28.341910 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I0228 10:24:28.341922 12900 net.cpp:100] Creating Layer conv15_2_mbox_loc
I0228 10:24:28.341928 12900 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I0228 10:24:28.341934 12900 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I0228 10:24:28.344379 12900 net.cpp:150] Setting up conv15_2_mbox_loc
I0228 10:24:28.344395 12900 net.cpp:157] Top shape: 24 24 3 3 (5184)
I0228 10:24:28.344400 12900 net.cpp:165] Memory required for data: 3870304064
I0228 10:24:28.344408 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I0228 10:24:28.344416 12900 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I0228 10:24:28.344421 12900 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I0228 10:24:28.344429 12900 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I0228 10:24:28.344563 12900 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I0228 10:24:28.344573 12900 net.cpp:157] Top shape: 24 3 3 24 (5184)
I0228 10:24:28.344578 12900 net.cpp:165] Memory required for data: 3870324800
I0228 10:24:28.344581 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I0228 10:24:28.344588 12900 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I0228 10:24:28.344594 12900 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I0228 10:24:28.344602 12900 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I0228 10:24:28.344630 12900 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I0228 10:24:28.344640 12900 net.cpp:157] Top shape: 24 216 (5184)
I0228 10:24:28.344645 12900 net.cpp:165] Memory required for data: 3870345536
I0228 10:24:28.344648 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I0228 10:24:28.344660 12900 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I0228 10:24:28.344666 12900 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I0228 10:24:28.344676 12900 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I0228 10:24:28.347530 12900 net.cpp:150] Setting up conv15_2_mbox_conf_new
I0228 10:24:28.347545 12900 net.cpp:157] Top shape: 24 24 3 3 (5184)
I0228 10:24:28.347565 12900 net.cpp:165] Memory required for data: 3870366272
I0228 10:24:28.347574 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I0228 10:24:28.347582 12900 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I0228 10:24:28.347587 12900 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I0228 10:24:28.347594 12900 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I0228 10:24:28.347738 12900 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I0228 10:24:28.347746 12900 net.cpp:157] Top shape: 24 3 3 24 (5184)
I0228 10:24:28.347750 12900 net.cpp:165] Memory required for data: 3870387008
I0228 10:24:28.347754 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I0228 10:24:28.347776 12900 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I0228 10:24:28.347782 12900 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I0228 10:24:28.347790 12900 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I0228 10:24:28.347820 12900 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I0228 10:24:28.347828 12900 net.cpp:157] Top shape: 24 216 (5184)
I0228 10:24:28.347832 12900 net.cpp:165] Memory required for data: 3870407744
I0228 10:24:28.347836 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I0228 10:24:28.347846 12900 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I0228 10:24:28.347851 12900 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I0228 10:24:28.347857 12900 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I0228 10:24:28.347864 12900 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I0228 10:24:28.347896 12900 net.cpp:150] Setting up conv15_2_mbox_priorbox
I0228 10:24:28.347904 12900 net.cpp:157] Top shape: 1 2 216 (432)
I0228 10:24:28.347908 12900 net.cpp:165] Memory required for data: 3870409472
I0228 10:24:28.347913 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I0228 10:24:28.347923 12900 net.cpp:100] Creating Layer conv16_2_mbox_loc
I0228 10:24:28.347929 12900 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I0228 10:24:28.347939 12900 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I0228 10:24:28.350319 12900 net.cpp:150] Setting up conv16_2_mbox_loc
I0228 10:24:28.350337 12900 net.cpp:157] Top shape: 24 24 2 2 (2304)
I0228 10:24:28.350342 12900 net.cpp:165] Memory required for data: 3870418688
I0228 10:24:28.350350 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I0228 10:24:28.350359 12900 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I0228 10:24:28.350364 12900 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I0228 10:24:28.350373 12900 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I0228 10:24:28.350505 12900 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I0228 10:24:28.350514 12900 net.cpp:157] Top shape: 24 2 2 24 (2304)
I0228 10:24:28.350518 12900 net.cpp:165] Memory required for data: 3870427904
I0228 10:24:28.350524 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I0228 10:24:28.350531 12900 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I0228 10:24:28.350535 12900 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I0228 10:24:28.350543 12900 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I0228 10:24:28.350574 12900 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I0228 10:24:28.350582 12900 net.cpp:157] Top shape: 24 96 (2304)
I0228 10:24:28.350586 12900 net.cpp:165] Memory required for data: 3870437120
I0228 10:24:28.350591 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I0228 10:24:28.350603 12900 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I0228 10:24:28.350610 12900 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I0228 10:24:28.350618 12900 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I0228 10:24:28.353199 12900 net.cpp:150] Setting up conv16_2_mbox_conf_new
I0228 10:24:28.353219 12900 net.cpp:157] Top shape: 24 24 2 2 (2304)
I0228 10:24:28.353224 12900 net.cpp:165] Memory required for data: 3870446336
I0228 10:24:28.353232 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I0228 10:24:28.353242 12900 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I0228 10:24:28.353255 12900 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I0228 10:24:28.353262 12900 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I0228 10:24:28.353400 12900 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I0228 10:24:28.353410 12900 net.cpp:157] Top shape: 24 2 2 24 (2304)
I0228 10:24:28.353415 12900 net.cpp:165] Memory required for data: 3870455552
I0228 10:24:28.353421 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I0228 10:24:28.353430 12900 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I0228 10:24:28.353454 12900 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I0228 10:24:28.353463 12900 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I0228 10:24:28.353502 12900 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I0228 10:24:28.353512 12900 net.cpp:157] Top shape: 24 96 (2304)
I0228 10:24:28.353515 12900 net.cpp:165] Memory required for data: 3870464768
I0228 10:24:28.353521 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I0228 10:24:28.353531 12900 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I0228 10:24:28.353536 12900 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I0228 10:24:28.353544 12900 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I0228 10:24:28.353552 12900 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I0228 10:24:28.353590 12900 net.cpp:150] Setting up conv16_2_mbox_priorbox
I0228 10:24:28.353597 12900 net.cpp:157] Top shape: 1 2 96 (192)
I0228 10:24:28.353602 12900 net.cpp:165] Memory required for data: 3870465536
I0228 10:24:28.353607 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I0228 10:24:28.353621 12900 net.cpp:100] Creating Layer conv17_2_mbox_loc
I0228 10:24:28.353628 12900 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I0228 10:24:28.353637 12900 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I0228 10:24:28.356452 12900 net.cpp:150] Setting up conv17_2_mbox_loc
I0228 10:24:28.356470 12900 net.cpp:157] Top shape: 24 24 1 1 (576)
I0228 10:24:28.356475 12900 net.cpp:165] Memory required for data: 3870467840
I0228 10:24:28.356485 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I0228 10:24:28.356498 12900 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I0228 10:24:28.356508 12900 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I0228 10:24:28.356516 12900 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I0228 10:24:28.356653 12900 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I0228 10:24:28.356665 12900 net.cpp:157] Top shape: 24 1 1 24 (576)
I0228 10:24:28.356669 12900 net.cpp:165] Memory required for data: 3870470144
I0228 10:24:28.356674 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I0228 10:24:28.356681 12900 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I0228 10:24:28.356688 12900 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I0228 10:24:28.356696 12900 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I0228 10:24:28.356729 12900 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I0228 10:24:28.356737 12900 net.cpp:157] Top shape: 24 24 (576)
I0228 10:24:28.356743 12900 net.cpp:165] Memory required for data: 3870472448
I0228 10:24:28.356748 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I0228 10:24:28.356760 12900 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I0228 10:24:28.356765 12900 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I0228 10:24:28.356775 12900 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I0228 10:24:28.359205 12900 net.cpp:150] Setting up conv17_2_mbox_conf_new
I0228 10:24:28.359220 12900 net.cpp:157] Top shape: 24 24 1 1 (576)
I0228 10:24:28.359239 12900 net.cpp:165] Memory required for data: 3870474752
I0228 10:24:28.359248 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I0228 10:24:28.359257 12900 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I0228 10:24:28.359263 12900 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I0228 10:24:28.359271 12900 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I0228 10:24:28.359388 12900 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I0228 10:24:28.359397 12900 net.cpp:157] Top shape: 24 1 1 24 (576)
I0228 10:24:28.359401 12900 net.cpp:165] Memory required for data: 3870477056
I0228 10:24:28.359406 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I0228 10:24:28.359414 12900 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I0228 10:24:28.359432 12900 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I0228 10:24:28.359439 12900 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I0228 10:24:28.359472 12900 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I0228 10:24:28.359480 12900 net.cpp:157] Top shape: 24 24 (576)
I0228 10:24:28.359485 12900 net.cpp:165] Memory required for data: 3870479360
I0228 10:24:28.359490 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I0228 10:24:28.359499 12900 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I0228 10:24:28.359504 12900 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I0228 10:24:28.359510 12900 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I0228 10:24:28.359516 12900 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I0228 10:24:28.359549 12900 net.cpp:150] Setting up conv17_2_mbox_priorbox
I0228 10:24:28.359557 12900 net.cpp:157] Top shape: 1 2 24 (48)
I0228 10:24:28.359560 12900 net.cpp:165] Memory required for data: 3870479552
I0228 10:24:28.359565 12900 layer_factory.hpp:77] Creating layer mbox_loc
I0228 10:24:28.359573 12900 net.cpp:100] Creating Layer mbox_loc
I0228 10:24:28.359580 12900 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I0228 10:24:28.359586 12900 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I0228 10:24:28.359591 12900 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I0228 10:24:28.359596 12900 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I0228 10:24:28.359601 12900 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I0228 10:24:28.359606 12900 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I0228 10:24:28.359612 12900 net.cpp:408] mbox_loc -> mbox_loc
I0228 10:24:28.359645 12900 net.cpp:150] Setting up mbox_loc
I0228 10:24:28.359654 12900 net.cpp:157] Top shape: 24 7668 (184032)
I0228 10:24:28.359658 12900 net.cpp:165] Memory required for data: 3871215680
I0228 10:24:28.359674 12900 layer_factory.hpp:77] Creating layer mbox_conf
I0228 10:24:28.359681 12900 net.cpp:100] Creating Layer mbox_conf
I0228 10:24:28.359688 12900 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I0228 10:24:28.359694 12900 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I0228 10:24:28.359699 12900 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I0228 10:24:28.359704 12900 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I0228 10:24:28.359710 12900 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I0228 10:24:28.359716 12900 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I0228 10:24:28.359724 12900 net.cpp:408] mbox_conf -> mbox_conf
I0228 10:24:28.359755 12900 net.cpp:150] Setting up mbox_conf
I0228 10:24:28.359763 12900 net.cpp:157] Top shape: 24 7668 (184032)
I0228 10:24:28.359768 12900 net.cpp:165] Memory required for data: 3871951808
I0228 10:24:28.359773 12900 layer_factory.hpp:77] Creating layer mbox_priorbox
I0228 10:24:28.359779 12900 net.cpp:100] Creating Layer mbox_priorbox
I0228 10:24:28.359786 12900 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I0228 10:24:28.359791 12900 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I0228 10:24:28.359797 12900 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I0228 10:24:28.359817 12900 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I0228 10:24:28.359824 12900 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I0228 10:24:28.359830 12900 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I0228 10:24:28.359838 12900 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0228 10:24:28.359866 12900 net.cpp:150] Setting up mbox_priorbox
I0228 10:24:28.359876 12900 net.cpp:157] Top shape: 1 2 7668 (15336)
I0228 10:24:28.359881 12900 net.cpp:165] Memory required for data: 3872013152
I0228 10:24:28.359885 12900 layer_factory.hpp:77] Creating layer mbox_loss
I0228 10:24:28.359897 12900 net.cpp:100] Creating Layer mbox_loss
I0228 10:24:28.359905 12900 net.cpp:434] mbox_loss <- mbox_loc
I0228 10:24:28.359910 12900 net.cpp:434] mbox_loss <- mbox_conf
I0228 10:24:28.359916 12900 net.cpp:434] mbox_loss <- mbox_priorbox
I0228 10:24:28.359921 12900 net.cpp:434] mbox_loss <- label
I0228 10:24:28.359941 12900 net.cpp:408] mbox_loss -> mbox_loss
I0228 10:24:28.360014 12900 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0228 10:24:28.360131 12900 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0228 10:24:28.360143 12900 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0228 10:24:28.361423 12900 net.cpp:150] Setting up mbox_loss
I0228 10:24:28.361438 12900 net.cpp:157] Top shape: (1)
I0228 10:24:28.361443 12900 net.cpp:160]     with loss weight 1
I0228 10:24:28.361464 12900 net.cpp:165] Memory required for data: 3872013156
I0228 10:24:28.361469 12900 net.cpp:226] mbox_loss needs backward computation.
I0228 10:24:28.361479 12900 net.cpp:228] mbox_priorbox does not need backward computation.
I0228 10:24:28.361486 12900 net.cpp:226] mbox_conf needs backward computation.
I0228 10:24:28.361493 12900 net.cpp:226] mbox_loc needs backward computation.
I0228 10:24:28.361501 12900 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I0228 10:24:28.361508 12900 net.cpp:226] conv17_2_mbox_conf_flat needs backward computation.
I0228 10:24:28.361513 12900 net.cpp:226] conv17_2_mbox_conf_perm needs backward computation.
I0228 10:24:28.361518 12900 net.cpp:226] conv17_2_mbox_conf_new needs backward computation.
I0228 10:24:28.361524 12900 net.cpp:226] conv17_2_mbox_loc_flat needs backward computation.
I0228 10:24:28.361529 12900 net.cpp:226] conv17_2_mbox_loc_perm needs backward computation.
I0228 10:24:28.361534 12900 net.cpp:226] conv17_2_mbox_loc needs backward computation.
I0228 10:24:28.361541 12900 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I0228 10:24:28.361549 12900 net.cpp:226] conv16_2_mbox_conf_flat needs backward computation.
I0228 10:24:28.361554 12900 net.cpp:226] conv16_2_mbox_conf_perm needs backward computation.
I0228 10:24:28.361559 12900 net.cpp:226] conv16_2_mbox_conf_new needs backward computation.
I0228 10:24:28.361564 12900 net.cpp:226] conv16_2_mbox_loc_flat needs backward computation.
I0228 10:24:28.361570 12900 net.cpp:226] conv16_2_mbox_loc_perm needs backward computation.
I0228 10:24:28.361575 12900 net.cpp:226] conv16_2_mbox_loc needs backward computation.
I0228 10:24:28.361580 12900 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I0228 10:24:28.361587 12900 net.cpp:226] conv15_2_mbox_conf_flat needs backward computation.
I0228 10:24:28.361593 12900 net.cpp:226] conv15_2_mbox_conf_perm needs backward computation.
I0228 10:24:28.361598 12900 net.cpp:226] conv15_2_mbox_conf_new needs backward computation.
I0228 10:24:28.361603 12900 net.cpp:226] conv15_2_mbox_loc_flat needs backward computation.
I0228 10:24:28.361608 12900 net.cpp:226] conv15_2_mbox_loc_perm needs backward computation.
I0228 10:24:28.361613 12900 net.cpp:226] conv15_2_mbox_loc needs backward computation.
I0228 10:24:28.361619 12900 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I0228 10:24:28.361626 12900 net.cpp:226] conv14_2_mbox_conf_flat needs backward computation.
I0228 10:24:28.361631 12900 net.cpp:226] conv14_2_mbox_conf_perm needs backward computation.
I0228 10:24:28.361637 12900 net.cpp:226] conv14_2_mbox_conf_new needs backward computation.
I0228 10:24:28.361644 12900 net.cpp:226] conv14_2_mbox_loc_flat needs backward computation.
I0228 10:24:28.361649 12900 net.cpp:226] conv14_2_mbox_loc_perm needs backward computation.
I0228 10:24:28.361654 12900 net.cpp:226] conv14_2_mbox_loc needs backward computation.
I0228 10:24:28.361660 12900 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I0228 10:24:28.361666 12900 net.cpp:226] conv13_mbox_conf_flat needs backward computation.
I0228 10:24:28.361671 12900 net.cpp:226] conv13_mbox_conf_perm needs backward computation.
I0228 10:24:28.361677 12900 net.cpp:226] conv13_mbox_conf_new needs backward computation.
I0228 10:24:28.361683 12900 net.cpp:226] conv13_mbox_loc_flat needs backward computation.
I0228 10:24:28.361688 12900 net.cpp:226] conv13_mbox_loc_perm needs backward computation.
I0228 10:24:28.361693 12900 net.cpp:226] conv13_mbox_loc needs backward computation.
I0228 10:24:28.361707 12900 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I0228 10:24:28.361716 12900 net.cpp:226] conv11_mbox_conf_flat needs backward computation.
I0228 10:24:28.361721 12900 net.cpp:226] conv11_mbox_conf_perm needs backward computation.
I0228 10:24:28.361726 12900 net.cpp:226] conv11_mbox_conf_new needs backward computation.
I0228 10:24:28.361730 12900 net.cpp:226] conv11_mbox_loc_flat needs backward computation.
I0228 10:24:28.361737 12900 net.cpp:226] conv11_mbox_loc_perm needs backward computation.
I0228 10:24:28.361742 12900 net.cpp:226] conv11_mbox_loc needs backward computation.
I0228 10:24:28.361747 12900 net.cpp:226] conv17_2_conv17_2/relu_0_split needs backward computation.
I0228 10:24:28.361752 12900 net.cpp:226] conv17_2/relu needs backward computation.
I0228 10:24:28.361758 12900 net.cpp:226] conv17_2/scale needs backward computation.
I0228 10:24:28.361763 12900 net.cpp:226] conv17_2/bn needs backward computation.
I0228 10:24:28.361768 12900 net.cpp:226] conv17_2 needs backward computation.
I0228 10:24:28.361773 12900 net.cpp:226] conv17_1/relu needs backward computation.
I0228 10:24:28.361778 12900 net.cpp:226] conv17_1/scale needs backward computation.
I0228 10:24:28.361783 12900 net.cpp:226] conv17_1/bn needs backward computation.
I0228 10:24:28.361788 12900 net.cpp:226] conv17_1 needs backward computation.
I0228 10:24:28.361791 12900 net.cpp:226] conv16_2_conv16_2/relu_0_split needs backward computation.
I0228 10:24:28.361798 12900 net.cpp:226] conv16_2/relu needs backward computation.
I0228 10:24:28.361802 12900 net.cpp:226] conv16_2/scale needs backward computation.
I0228 10:24:28.361806 12900 net.cpp:226] conv16_2/bn needs backward computation.
I0228 10:24:28.361811 12900 net.cpp:226] conv16_2 needs backward computation.
I0228 10:24:28.361816 12900 net.cpp:226] conv16_1/relu needs backward computation.
I0228 10:24:28.361821 12900 net.cpp:226] conv16_1/scale needs backward computation.
I0228 10:24:28.361825 12900 net.cpp:226] conv16_1/bn needs backward computation.
I0228 10:24:28.361830 12900 net.cpp:226] conv16_1 needs backward computation.
I0228 10:24:28.361836 12900 net.cpp:226] conv15_2_conv15_2/relu_0_split needs backward computation.
I0228 10:24:28.361843 12900 net.cpp:226] conv15_2/relu needs backward computation.
I0228 10:24:28.361847 12900 net.cpp:226] conv15_2/scale needs backward computation.
I0228 10:24:28.361852 12900 net.cpp:226] conv15_2/bn needs backward computation.
I0228 10:24:28.361857 12900 net.cpp:226] conv15_2 needs backward computation.
I0228 10:24:28.361862 12900 net.cpp:226] conv15_1/relu needs backward computation.
I0228 10:24:28.361866 12900 net.cpp:226] conv15_1/scale needs backward computation.
I0228 10:24:28.361871 12900 net.cpp:226] conv15_1/bn needs backward computation.
I0228 10:24:28.361877 12900 net.cpp:226] conv15_1 needs backward computation.
I0228 10:24:28.361882 12900 net.cpp:226] conv14_2_conv14_2/relu_0_split needs backward computation.
I0228 10:24:28.361887 12900 net.cpp:226] conv14_2/relu needs backward computation.
I0228 10:24:28.361907 12900 net.cpp:226] conv14_2/scale needs backward computation.
I0228 10:24:28.361913 12900 net.cpp:226] conv14_2/bn needs backward computation.
I0228 10:24:28.361919 12900 net.cpp:226] conv14_2 needs backward computation.
I0228 10:24:28.361924 12900 net.cpp:226] conv14_1/relu needs backward computation.
I0228 10:24:28.361929 12900 net.cpp:226] conv14_1/scale needs backward computation.
I0228 10:24:28.361934 12900 net.cpp:226] conv14_1/bn needs backward computation.
I0228 10:24:28.361938 12900 net.cpp:226] conv14_1 needs backward computation.
I0228 10:24:28.361944 12900 net.cpp:226] conv13_conv13/relu_0_split needs backward computation.
I0228 10:24:28.361949 12900 net.cpp:226] conv13/relu needs backward computation.
I0228 10:24:28.361955 12900 net.cpp:226] conv13/scale needs backward computation.
I0228 10:24:28.361960 12900 net.cpp:226] conv13/bn needs backward computation.
I0228 10:24:28.361964 12900 net.cpp:226] conv13 needs backward computation.
I0228 10:24:28.361976 12900 net.cpp:226] conv13/dw/relu needs backward computation.
I0228 10:24:28.361982 12900 net.cpp:226] conv13/dw/scale needs backward computation.
I0228 10:24:28.361987 12900 net.cpp:226] conv13/dw/bn needs backward computation.
I0228 10:24:28.361991 12900 net.cpp:226] conv13/dw needs backward computation.
I0228 10:24:28.361997 12900 net.cpp:226] conv12/relu needs backward computation.
I0228 10:24:28.362004 12900 net.cpp:226] conv12/scale needs backward computation.
I0228 10:24:28.362007 12900 net.cpp:226] conv12/bn needs backward computation.
I0228 10:24:28.362012 12900 net.cpp:226] conv12 needs backward computation.
I0228 10:24:28.362017 12900 net.cpp:226] conv12/dw/relu needs backward computation.
I0228 10:24:28.362022 12900 net.cpp:226] conv12/dw/scale needs backward computation.
I0228 10:24:28.362027 12900 net.cpp:226] conv12/dw/bn needs backward computation.
I0228 10:24:28.362032 12900 net.cpp:226] conv12/dw needs backward computation.
I0228 10:24:28.362037 12900 net.cpp:226] conv11_conv11/relu_0_split needs backward computation.
I0228 10:24:28.362043 12900 net.cpp:226] conv11/relu needs backward computation.
I0228 10:24:28.362048 12900 net.cpp:226] conv11/scale needs backward computation.
I0228 10:24:28.362053 12900 net.cpp:226] conv11/bn needs backward computation.
I0228 10:24:28.362057 12900 net.cpp:226] conv11 needs backward computation.
I0228 10:24:28.362063 12900 net.cpp:226] conv11/dw/relu needs backward computation.
I0228 10:24:28.362068 12900 net.cpp:226] conv11/dw/scale needs backward computation.
I0228 10:24:28.362073 12900 net.cpp:226] conv11/dw/bn needs backward computation.
I0228 10:24:28.362078 12900 net.cpp:226] conv11/dw needs backward computation.
I0228 10:24:28.362084 12900 net.cpp:226] conv10/relu needs backward computation.
I0228 10:24:28.362089 12900 net.cpp:226] conv10/scale needs backward computation.
I0228 10:24:28.362094 12900 net.cpp:226] conv10/bn needs backward computation.
I0228 10:24:28.362099 12900 net.cpp:226] conv10 needs backward computation.
I0228 10:24:28.362104 12900 net.cpp:226] conv10/dw/relu needs backward computation.
I0228 10:24:28.362109 12900 net.cpp:226] conv10/dw/scale needs backward computation.
I0228 10:24:28.362114 12900 net.cpp:226] conv10/dw/bn needs backward computation.
I0228 10:24:28.362119 12900 net.cpp:226] conv10/dw needs backward computation.
I0228 10:24:28.362125 12900 net.cpp:226] conv9/relu needs backward computation.
I0228 10:24:28.362130 12900 net.cpp:226] conv9/scale needs backward computation.
I0228 10:24:28.362136 12900 net.cpp:226] conv9/bn needs backward computation.
I0228 10:24:28.362141 12900 net.cpp:226] conv9 needs backward computation.
I0228 10:24:28.362149 12900 net.cpp:226] conv9/dw/relu needs backward computation.
I0228 10:24:28.362152 12900 net.cpp:226] conv9/dw/scale needs backward computation.
I0228 10:24:28.362157 12900 net.cpp:226] conv9/dw/bn needs backward computation.
I0228 10:24:28.362162 12900 net.cpp:226] conv9/dw needs backward computation.
I0228 10:24:28.362169 12900 net.cpp:226] conv8/relu needs backward computation.
I0228 10:24:28.362172 12900 net.cpp:226] conv8/scale needs backward computation.
I0228 10:24:28.362177 12900 net.cpp:226] conv8/bn needs backward computation.
I0228 10:24:28.362182 12900 net.cpp:226] conv8 needs backward computation.
I0228 10:24:28.362187 12900 net.cpp:226] conv8/dw/relu needs backward computation.
I0228 10:24:28.362192 12900 net.cpp:226] conv8/dw/scale needs backward computation.
I0228 10:24:28.362197 12900 net.cpp:226] conv8/dw/bn needs backward computation.
I0228 10:24:28.362201 12900 net.cpp:226] conv8/dw needs backward computation.
I0228 10:24:28.362207 12900 net.cpp:226] conv7/relu needs backward computation.
I0228 10:24:28.362212 12900 net.cpp:226] conv7/scale needs backward computation.
I0228 10:24:28.362216 12900 net.cpp:226] conv7/bn needs backward computation.
I0228 10:24:28.362221 12900 net.cpp:226] conv7 needs backward computation.
I0228 10:24:28.362227 12900 net.cpp:226] conv7/dw/relu needs backward computation.
I0228 10:24:28.362233 12900 net.cpp:226] conv7/dw/scale needs backward computation.
I0228 10:24:28.362242 12900 net.cpp:226] conv7/dw/bn needs backward computation.
I0228 10:24:28.362247 12900 net.cpp:226] conv7/dw needs backward computation.
I0228 10:24:28.362253 12900 net.cpp:226] conv6/relu needs backward computation.
I0228 10:24:28.362258 12900 net.cpp:226] conv6/scale needs backward computation.
I0228 10:24:28.362263 12900 net.cpp:226] conv6/bn needs backward computation.
I0228 10:24:28.362268 12900 net.cpp:226] conv6 needs backward computation.
I0228 10:24:28.362273 12900 net.cpp:226] conv6/dw/relu needs backward computation.
I0228 10:24:28.362278 12900 net.cpp:226] conv6/dw/scale needs backward computation.
I0228 10:24:28.362283 12900 net.cpp:226] conv6/dw/bn needs backward computation.
I0228 10:24:28.362287 12900 net.cpp:226] conv6/dw needs backward computation.
I0228 10:24:28.362293 12900 net.cpp:226] conv5/relu needs backward computation.
I0228 10:24:28.362299 12900 net.cpp:226] conv5/scale needs backward computation.
I0228 10:24:28.362304 12900 net.cpp:226] conv5/bn needs backward computation.
I0228 10:24:28.362308 12900 net.cpp:226] conv5 needs backward computation.
I0228 10:24:28.362314 12900 net.cpp:226] conv5/dw/relu needs backward computation.
I0228 10:24:28.362318 12900 net.cpp:226] conv5/dw/scale needs backward computation.
I0228 10:24:28.362323 12900 net.cpp:226] conv5/dw/bn needs backward computation.
I0228 10:24:28.362327 12900 net.cpp:226] conv5/dw needs backward computation.
I0228 10:24:28.362334 12900 net.cpp:226] conv4/relu needs backward computation.
I0228 10:24:28.362339 12900 net.cpp:226] conv4/scale needs backward computation.
I0228 10:24:28.362342 12900 net.cpp:226] conv4/bn needs backward computation.
I0228 10:24:28.362347 12900 net.cpp:226] conv4 needs backward computation.
I0228 10:24:28.362352 12900 net.cpp:226] conv4/dw/relu needs backward computation.
I0228 10:24:28.362357 12900 net.cpp:226] conv4/dw/scale needs backward computation.
I0228 10:24:28.362361 12900 net.cpp:226] conv4/dw/bn needs backward computation.
I0228 10:24:28.362366 12900 net.cpp:226] conv4/dw needs backward computation.
I0228 10:24:28.362372 12900 net.cpp:226] conv3/relu needs backward computation.
I0228 10:24:28.362377 12900 net.cpp:226] conv3/scale needs backward computation.
I0228 10:24:28.362381 12900 net.cpp:226] conv3/bn needs backward computation.
I0228 10:24:28.362385 12900 net.cpp:226] conv3 needs backward computation.
I0228 10:24:28.362391 12900 net.cpp:226] conv3/dw/relu needs backward computation.
I0228 10:24:28.362396 12900 net.cpp:226] conv3/dw/scale needs backward computation.
I0228 10:24:28.362399 12900 net.cpp:226] conv3/dw/bn needs backward computation.
I0228 10:24:28.362404 12900 net.cpp:226] conv3/dw needs backward computation.
I0228 10:24:28.362409 12900 net.cpp:226] conv2/relu needs backward computation.
I0228 10:24:28.362413 12900 net.cpp:226] conv2/scale needs backward computation.
I0228 10:24:28.362418 12900 net.cpp:226] conv2/bn needs backward computation.
I0228 10:24:28.362422 12900 net.cpp:226] conv2 needs backward computation.
I0228 10:24:28.362427 12900 net.cpp:226] conv2/dw/relu needs backward computation.
I0228 10:24:28.362432 12900 net.cpp:226] conv2/dw/scale needs backward computation.
I0228 10:24:28.362437 12900 net.cpp:226] conv2/dw/bn needs backward computation.
I0228 10:24:28.362442 12900 net.cpp:226] conv2/dw needs backward computation.
I0228 10:24:28.362447 12900 net.cpp:226] conv1/relu needs backward computation.
I0228 10:24:28.362452 12900 net.cpp:226] conv1/scale needs backward computation.
I0228 10:24:28.362455 12900 net.cpp:226] conv1/bn needs backward computation.
I0228 10:24:28.362460 12900 net.cpp:226] conv1 needs backward computation.
I0228 10:24:28.362465 12900 net.cpp:226] conv1/dw/relu needs backward computation.
I0228 10:24:28.362470 12900 net.cpp:226] conv1/dw/scale needs backward computation.
I0228 10:24:28.362474 12900 net.cpp:226] conv1/dw/bn needs backward computation.
I0228 10:24:28.362479 12900 net.cpp:226] conv1/dw needs backward computation.
I0228 10:24:28.362484 12900 net.cpp:226] conv0/relu needs backward computation.
I0228 10:24:28.362495 12900 net.cpp:226] conv0/scale needs backward computation.
I0228 10:24:28.362499 12900 net.cpp:226] conv0/bn needs backward computation.
I0228 10:24:28.362504 12900 net.cpp:226] conv0 needs backward computation.
I0228 10:24:28.362511 12900 net.cpp:228] data_data_0_split does not need backward computation.
I0228 10:24:28.362517 12900 net.cpp:228] data does not need backward computation.
I0228 10:24:28.362521 12900 net.cpp:270] This network produces output mbox_loss
I0228 10:24:28.362648 12900 net.cpp:283] Network initialization done.
I0228 10:24:28.364305 12900 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: MobileNetSSD_test.prototxt
I0228 10:24:28.364320 12900 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0228 10:24:28.364326 12900 solver.cpp:196] Creating test net (#0) specified by test_net file: MobileNetSSD_test.prototxt
I0228 10:24:28.365469 12900 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "test_lmdb"
    batch_size: 8
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_mbox_loc_perm"
  top: "conv11_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_conf_new"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_mbox_conf"
  top: "conv11_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_mbox_conf_perm"
  top: "conv11_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11"
  bottom: "data"
  top: "conv11_mbox_priorbox"
  prior_box_param {
    min_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "conv13_mbox_loc"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_loc_perm"
  type: "Permute"
  bottom: "conv13_mbox_loc"
  top: "conv13_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv13_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv13_mbox_loc_perm"
  top: "conv13_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv13_mbox_conf_new"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_conf_perm"
  type: "Permute"
  bottom: "conv13_mbox_conf"
  top: "conv13_mbox_conf_perm"
  permute_param {
    order: 0
I0228 10:24:28.366048 12900 layer_factory.hpp:77] Creating layer data
I0228 10:24:28.366107 12900 net.cpp:100] Creating Layer data
I0228 10:24:28.366130 12900 net.cpp:408] data -> data
I0228 10:24:28.366140 12900 net.cpp:408] data -> label
I0228 10:24:28.367768 12930 db_lmdb.cpp:35] Opened lmdb test_lmdb
I0228 10:24:28.463420 12900 annotated_data_layer.cpp:62] output data size: 8,3,300,300
I0228 10:24:28.476680 12900 net.cpp:150] Setting up data
I0228 10:24:28.476737 12900 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0228 10:24:28.476744 12900 net.cpp:157] Top shape: 1 1 1 8 (8)
I0228 10:24:28.476748 12900 net.cpp:165] Memory required for data: 8640032
I0228 10:24:28.476759 12900 layer_factory.hpp:77] Creating layer data_data_0_split
I0228 10:24:28.476775 12900 net.cpp:100] Creating Layer data_data_0_split
I0228 10:24:28.476783 12900 net.cpp:434] data_data_0_split <- data
I0228 10:24:28.476790 12900 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0228 10:24:28.476817 12900 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0228 10:24:28.476826 12900 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0228 10:24:28.476835 12900 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0228 10:24:28.476842 12900 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0228 10:24:28.476850 12900 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0228 10:24:28.476857 12900 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0228 10:24:28.477139 12900 net.cpp:150] Setting up data_data_0_split
I0228 10:24:28.477149 12900 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0228 10:24:28.477155 12900 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0228 10:24:28.477160 12900 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0228 10:24:28.477166 12900 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0228 10:24:28.477188 12900 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0228 10:24:28.477195 12900 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0228 10:24:28.477200 12900 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0228 10:24:28.477205 12900 net.cpp:165] Memory required for data: 69120032
I0228 10:24:28.477210 12900 layer_factory.hpp:77] Creating layer conv0
I0228 10:24:28.477224 12900 net.cpp:100] Creating Layer conv0
I0228 10:24:28.477232 12900 net.cpp:434] conv0 <- data_data_0_split_0
I0228 10:24:28.477239 12900 net.cpp:408] conv0 -> conv0
I0228 10:24:28.479817 12900 net.cpp:150] Setting up conv0
I0228 10:24:28.479851 12900 net.cpp:157] Top shape: 8 32 150 150 (5760000)
I0228 10:24:28.479856 12900 net.cpp:165] Memory required for data: 92160032
I0228 10:24:28.479867 12900 layer_factory.hpp:77] Creating layer conv0/bn
I0228 10:24:28.479877 12900 net.cpp:100] Creating Layer conv0/bn
I0228 10:24:28.479882 12900 net.cpp:434] conv0/bn <- conv0
I0228 10:24:28.479889 12900 net.cpp:395] conv0/bn -> conv0 (in-place)
I0228 10:24:28.480203 12900 net.cpp:150] Setting up conv0/bn
I0228 10:24:28.480224 12900 net.cpp:157] Top shape: 8 32 150 150 (5760000)
I0228 10:24:28.480245 12900 net.cpp:165] Memory required for data: 115200032
I0228 10:24:28.480273 12900 layer_factory.hpp:77] Creating layer conv0/scale
I0228 10:24:28.480285 12900 net.cpp:100] Creating Layer conv0/scale
I0228 10:24:28.480290 12900 net.cpp:434] conv0/scale <- conv0
I0228 10:24:28.480296 12900 net.cpp:395] conv0/scale -> conv0 (in-place)
I0228 10:24:28.480419 12900 layer_factory.hpp:77] Creating layer conv0/scale
I0228 10:24:28.480633 12900 net.cpp:150] Setting up conv0/scale
I0228 10:24:28.480643 12900 net.cpp:157] Top shape: 8 32 150 150 (5760000)
I0228 10:24:28.480648 12900 net.cpp:165] Memory required for data: 138240032
I0228 10:24:28.480657 12900 layer_factory.hpp:77] Creating layer conv0/relu
I0228 10:24:28.480667 12900 net.cpp:100] Creating Layer conv0/relu
I0228 10:24:28.480672 12900 net.cpp:434] conv0/relu <- conv0
I0228 10:24:28.480679 12900 net.cpp:395] conv0/relu -> conv0 (in-place)
I0228 10:24:28.481195 12900 net.cpp:150] Setting up conv0/relu
I0228 10:24:28.481209 12900 net.cpp:157] Top shape: 8 32 150 150 (5760000)
I0228 10:24:28.481228 12900 net.cpp:165] Memory required for data: 161280032
I0228 10:24:28.481233 12900 layer_factory.hpp:77] Creating layer conv1/dw
I0228 10:24:28.481259 12900 net.cpp:100] Creating Layer conv1/dw
I0228 10:24:28.481266 12900 net.cpp:434] conv1/dw <- conv0
I0228 10:24:28.481274 12900 net.cpp:408] conv1/dw -> conv1/dw
I0228 10:24:28.481611 12900 net.cpp:150] Setting up conv1/dw
I0228 10:24:28.481621 12900 net.cpp:157] Top shape: 8 32 150 150 (5760000)
I0228 10:24:28.481640 12900 net.cpp:165] Memory required for data: 184320032
I0228 10:24:28.481662 12900 layer_factory.hpp:77] Creating layer conv1/dw/bn
I0228 10:24:28.481669 12900 net.cpp:100] Creating Layer conv1/dw/bn
I0228 10:24:28.481674 12900 net.cpp:434] conv1/dw/bn <- conv1/dw
I0228 10:24:28.481681 12900 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I0228 10:24:28.483319 12900 net.cpp:150] Setting up conv1/dw/bn
I0228 10:24:28.483332 12900 net.cpp:157] Top shape: 8 32 150 150 (5760000)
I0228 10:24:28.483352 12900 net.cpp:165] Memory required for data: 207360032
I0228 10:24:28.483364 12900 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0228 10:24:28.483374 12900 net.cpp:100] Creating Layer conv1/dw/scale
I0228 10:24:28.483379 12900 net.cpp:434] conv1/dw/scale <- conv1/dw
I0228 10:24:28.483386 12900 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I0228 10:24:28.483453 12900 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0228 10:24:28.483620 12900 net.cpp:150] Setting up conv1/dw/scale
I0228 10:24:28.483629 12900 net.cpp:157] Top shape: 8 32 150 150 (5760000)
I0228 10:24:28.483634 12900 net.cpp:165] Memory required for data: 230400032
I0228 10:24:28.483642 12900 layer_factory.hpp:77] Creating layer conv1/dw/relu
I0228 10:24:28.483649 12900 net.cpp:100] Creating Layer conv1/dw/relu
I0228 10:24:28.483654 12900 net.cpp:434] conv1/dw/relu <- conv1/dw
I0228 10:24:28.483671 12900 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I0228 10:24:28.484155 12900 net.cpp:150] Setting up conv1/dw/relu
I0228 10:24:28.484167 12900 net.cpp:157] Top shape: 8 32 150 150 (5760000)
I0228 10:24:28.484171 12900 net.cpp:165] Memory required for data: 253440032
I0228 10:24:28.484176 12900 layer_factory.hpp:77] Creating layer conv1
I0228 10:24:28.484186 12900 net.cpp:100] Creating Layer conv1
I0228 10:24:28.484191 12900 net.cpp:434] conv1 <- conv1/dw
I0228 10:24:28.484199 12900 net.cpp:408] conv1 -> conv1
I0228 10:24:28.486539 12900 net.cpp:150] Setting up conv1
I0228 10:24:28.486572 12900 net.cpp:157] Top shape: 8 64 150 150 (11520000)
I0228 10:24:28.486578 12900 net.cpp:165] Memory required for data: 299520032
I0228 10:24:28.486585 12900 layer_factory.hpp:77] Creating layer conv1/bn
I0228 10:24:28.486593 12900 net.cpp:100] Creating Layer conv1/bn
I0228 10:24:28.486599 12900 net.cpp:434] conv1/bn <- conv1
I0228 10:24:28.486608 12900 net.cpp:395] conv1/bn -> conv1 (in-place)
I0228 10:24:28.486903 12900 net.cpp:150] Setting up conv1/bn
I0228 10:24:28.486930 12900 net.cpp:157] Top shape: 8 64 150 150 (11520000)
I0228 10:24:28.486951 12900 net.cpp:165] Memory required for data: 345600032
I0228 10:24:28.486976 12900 layer_factory.hpp:77] Creating layer conv1/scale
I0228 10:24:28.486984 12900 net.cpp:100] Creating Layer conv1/scale
I0228 10:24:28.486989 12900 net.cpp:434] conv1/scale <- conv1
I0228 10:24:28.486996 12900 net.cpp:395] conv1/scale -> conv1 (in-place)
I0228 10:24:28.487046 12900 layer_factory.hpp:77] Creating layer conv1/scale
I0228 10:24:28.487226 12900 net.cpp:150] Setting up conv1/scale
I0228 10:24:28.487234 12900 net.cpp:157] Top shape: 8 64 150 150 (11520000)
I0228 10:24:28.487241 12900 net.cpp:165] Memory required for data: 391680032
I0228 10:24:28.487251 12900 layer_factory.hpp:77] Creating layer conv1/relu
I0228 10:24:28.487257 12900 net.cpp:100] Creating Layer conv1/relu
I0228 10:24:28.487262 12900 net.cpp:434] conv1/relu <- conv1
I0228 10:24:28.487268 12900 net.cpp:395] conv1/relu -> conv1 (in-place)
I0228 10:24:28.487735 12900 net.cpp:150] Setting up conv1/relu
I0228 10:24:28.487748 12900 net.cpp:157] Top shape: 8 64 150 150 (11520000)
I0228 10:24:28.487752 12900 net.cpp:165] Memory required for data: 437760032
I0228 10:24:28.487758 12900 layer_factory.hpp:77] Creating layer conv2/dw
I0228 10:24:28.487769 12900 net.cpp:100] Creating Layer conv2/dw
I0228 10:24:28.487774 12900 net.cpp:434] conv2/dw <- conv1
I0228 10:24:28.487782 12900 net.cpp:408] conv2/dw -> conv2/dw
I0228 10:24:28.488061 12900 net.cpp:150] Setting up conv2/dw
I0228 10:24:28.488072 12900 net.cpp:157] Top shape: 8 64 75 75 (2880000)
I0228 10:24:28.488076 12900 net.cpp:165] Memory required for data: 449280032
I0228 10:24:28.488082 12900 layer_factory.hpp:77] Creating layer conv2/dw/bn
I0228 10:24:28.488090 12900 net.cpp:100] Creating Layer conv2/dw/bn
I0228 10:24:28.488095 12900 net.cpp:434] conv2/dw/bn <- conv2/dw
I0228 10:24:28.488101 12900 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I0228 10:24:28.488389 12900 net.cpp:150] Setting up conv2/dw/bn
I0228 10:24:28.488401 12900 net.cpp:157] Top shape: 8 64 75 75 (2880000)
I0228 10:24:28.488406 12900 net.cpp:165] Memory required for data: 460800032
I0228 10:24:28.488415 12900 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0228 10:24:28.488441 12900 net.cpp:100] Creating Layer conv2/dw/scale
I0228 10:24:28.488450 12900 net.cpp:434] conv2/dw/scale <- conv2/dw
I0228 10:24:28.488456 12900 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I0228 10:24:28.488514 12900 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0228 10:24:28.488720 12900 net.cpp:150] Setting up conv2/dw/scale
I0228 10:24:28.488730 12900 net.cpp:157] Top shape: 8 64 75 75 (2880000)
I0228 10:24:28.488735 12900 net.cpp:165] Memory required for data: 472320032
I0228 10:24:28.488742 12900 layer_factory.hpp:77] Creating layer conv2/dw/relu
I0228 10:24:28.488749 12900 net.cpp:100] Creating Layer conv2/dw/relu
I0228 10:24:28.488755 12900 net.cpp:434] conv2/dw/relu <- conv2/dw
I0228 10:24:28.488773 12900 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I0228 10:24:28.489965 12900 net.cpp:150] Setting up conv2/dw/relu
I0228 10:24:28.489979 12900 net.cpp:157] Top shape: 8 64 75 75 (2880000)
I0228 10:24:28.490000 12900 net.cpp:165] Memory required for data: 483840032
I0228 10:24:28.490020 12900 layer_factory.hpp:77] Creating layer conv2
I0228 10:24:28.490031 12900 net.cpp:100] Creating Layer conv2
I0228 10:24:28.490036 12900 net.cpp:434] conv2 <- conv2/dw
I0228 10:24:28.490044 12900 net.cpp:408] conv2 -> conv2
I0228 10:24:28.492640 12900 net.cpp:150] Setting up conv2
I0228 10:24:28.492673 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.492678 12900 net.cpp:165] Memory required for data: 506880032
I0228 10:24:28.492704 12900 layer_factory.hpp:77] Creating layer conv2/bn
I0228 10:24:28.492727 12900 net.cpp:100] Creating Layer conv2/bn
I0228 10:24:28.492732 12900 net.cpp:434] conv2/bn <- conv2
I0228 10:24:28.492738 12900 net.cpp:395] conv2/bn -> conv2 (in-place)
I0228 10:24:28.493010 12900 net.cpp:150] Setting up conv2/bn
I0228 10:24:28.493018 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.493022 12900 net.cpp:165] Memory required for data: 529920032
I0228 10:24:28.493031 12900 layer_factory.hpp:77] Creating layer conv2/scale
I0228 10:24:28.493039 12900 net.cpp:100] Creating Layer conv2/scale
I0228 10:24:28.493043 12900 net.cpp:434] conv2/scale <- conv2
I0228 10:24:28.493052 12900 net.cpp:395] conv2/scale -> conv2 (in-place)
I0228 10:24:28.493098 12900 layer_factory.hpp:77] Creating layer conv2/scale
I0228 10:24:28.493245 12900 net.cpp:150] Setting up conv2/scale
I0228 10:24:28.493254 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.493258 12900 net.cpp:165] Memory required for data: 552960032
I0228 10:24:28.493265 12900 layer_factory.hpp:77] Creating layer conv2/relu
I0228 10:24:28.493273 12900 net.cpp:100] Creating Layer conv2/relu
I0228 10:24:28.493278 12900 net.cpp:434] conv2/relu <- conv2
I0228 10:24:28.493283 12900 net.cpp:395] conv2/relu -> conv2 (in-place)
I0228 10:24:28.493860 12900 net.cpp:150] Setting up conv2/relu
I0228 10:24:28.493873 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.493888 12900 net.cpp:165] Memory required for data: 576000032
I0228 10:24:28.493893 12900 layer_factory.hpp:77] Creating layer conv3/dw
I0228 10:24:28.493906 12900 net.cpp:100] Creating Layer conv3/dw
I0228 10:24:28.493911 12900 net.cpp:434] conv3/dw <- conv2
I0228 10:24:28.493932 12900 net.cpp:408] conv3/dw -> conv3/dw
I0228 10:24:28.494186 12900 net.cpp:150] Setting up conv3/dw
I0228 10:24:28.494195 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.494200 12900 net.cpp:165] Memory required for data: 599040032
I0228 10:24:28.494206 12900 layer_factory.hpp:77] Creating layer conv3/dw/bn
I0228 10:24:28.494212 12900 net.cpp:100] Creating Layer conv3/dw/bn
I0228 10:24:28.494217 12900 net.cpp:434] conv3/dw/bn <- conv3/dw
I0228 10:24:28.494223 12900 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I0228 10:24:28.494470 12900 net.cpp:150] Setting up conv3/dw/bn
I0228 10:24:28.494478 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.494483 12900 net.cpp:165] Memory required for data: 622080032
I0228 10:24:28.494495 12900 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0228 10:24:28.494503 12900 net.cpp:100] Creating Layer conv3/dw/scale
I0228 10:24:28.494508 12900 net.cpp:434] conv3/dw/scale <- conv3/dw
I0228 10:24:28.494518 12900 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I0228 10:24:28.494565 12900 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0228 10:24:28.494710 12900 net.cpp:150] Setting up conv3/dw/scale
I0228 10:24:28.494719 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.494724 12900 net.cpp:165] Memory required for data: 645120032
I0228 10:24:28.494731 12900 layer_factory.hpp:77] Creating layer conv3/dw/relu
I0228 10:24:28.494737 12900 net.cpp:100] Creating Layer conv3/dw/relu
I0228 10:24:28.494741 12900 net.cpp:434] conv3/dw/relu <- conv3/dw
I0228 10:24:28.494760 12900 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I0228 10:24:28.495257 12900 net.cpp:150] Setting up conv3/dw/relu
I0228 10:24:28.495268 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.495282 12900 net.cpp:165] Memory required for data: 668160032
I0228 10:24:28.495287 12900 layer_factory.hpp:77] Creating layer conv3
I0228 10:24:28.495299 12900 net.cpp:100] Creating Layer conv3
I0228 10:24:28.495303 12900 net.cpp:434] conv3 <- conv3/dw
I0228 10:24:28.495311 12900 net.cpp:408] conv3 -> conv3
I0228 10:24:28.497939 12900 net.cpp:150] Setting up conv3
I0228 10:24:28.497974 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.497980 12900 net.cpp:165] Memory required for data: 691200032
I0228 10:24:28.497987 12900 layer_factory.hpp:77] Creating layer conv3/bn
I0228 10:24:28.497995 12900 net.cpp:100] Creating Layer conv3/bn
I0228 10:24:28.498001 12900 net.cpp:434] conv3/bn <- conv3
I0228 10:24:28.498009 12900 net.cpp:395] conv3/bn -> conv3 (in-place)
I0228 10:24:28.498286 12900 net.cpp:150] Setting up conv3/bn
I0228 10:24:28.498294 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.498299 12900 net.cpp:165] Memory required for data: 714240032
I0228 10:24:28.498307 12900 layer_factory.hpp:77] Creating layer conv3/scale
I0228 10:24:28.498317 12900 net.cpp:100] Creating Layer conv3/scale
I0228 10:24:28.498322 12900 net.cpp:434] conv3/scale <- conv3
I0228 10:24:28.498328 12900 net.cpp:395] conv3/scale -> conv3 (in-place)
I0228 10:24:28.498394 12900 layer_factory.hpp:77] Creating layer conv3/scale
I0228 10:24:28.498544 12900 net.cpp:150] Setting up conv3/scale
I0228 10:24:28.498553 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.498558 12900 net.cpp:165] Memory required for data: 737280032
I0228 10:24:28.498565 12900 layer_factory.hpp:77] Creating layer conv3/relu
I0228 10:24:28.498574 12900 net.cpp:100] Creating Layer conv3/relu
I0228 10:24:28.498579 12900 net.cpp:434] conv3/relu <- conv3
I0228 10:24:28.498585 12900 net.cpp:395] conv3/relu -> conv3 (in-place)
I0228 10:24:28.499703 12900 net.cpp:150] Setting up conv3/relu
I0228 10:24:28.499718 12900 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0228 10:24:28.499734 12900 net.cpp:165] Memory required for data: 760320032
I0228 10:24:28.499740 12900 layer_factory.hpp:77] Creating layer conv4/dw
I0228 10:24:28.499752 12900 net.cpp:100] Creating Layer conv4/dw
I0228 10:24:28.499758 12900 net.cpp:434] conv4/dw <- conv3
I0228 10:24:28.499765 12900 net.cpp:408] conv4/dw -> conv4/dw
I0228 10:24:28.500027 12900 net.cpp:150] Setting up conv4/dw
I0228 10:24:28.500038 12900 net.cpp:157] Top shape: 8 128 38 38 (1478656)
I0228 10:24:28.500042 12900 net.cpp:165] Memory required for data: 766234656
I0228 10:24:28.500049 12900 layer_factory.hpp:77] Creating layer conv4/dw/bn
I0228 10:24:28.500056 12900 net.cpp:100] Creating Layer conv4/dw/bn
I0228 10:24:28.500061 12900 net.cpp:434] conv4/dw/bn <- conv4/dw
I0228 10:24:28.500068 12900 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I0228 10:24:28.500298 12900 net.cpp:150] Setting up conv4/dw/bn
I0228 10:24:28.500308 12900 net.cpp:157] Top shape: 8 128 38 38 (1478656)
I0228 10:24:28.500313 12900 net.cpp:165] Memory required for data: 772149280
I0228 10:24:28.500320 12900 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0228 10:24:28.500331 12900 net.cpp:100] Creating Layer conv4/dw/scale
I0228 10:24:28.500337 12900 net.cpp:434] conv4/dw/scale <- conv4/dw
I0228 10:24:28.500344 12900 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I0228 10:24:28.500427 12900 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0228 10:24:28.500571 12900 net.cpp:150] Setting up conv4/dw/scale
I0228 10:24:28.500581 12900 net.cpp:157] Top shape: 8 128 38 38 (1478656)
I0228 10:24:28.500586 12900 net.cpp:165] Memory required for data: 778063904
I0228 10:24:28.500593 12900 layer_factory.hpp:77] Creating layer conv4/dw/relu
I0228 10:24:28.500600 12900 net.cpp:100] Creating Layer conv4/dw/relu
I0228 10:24:28.500607 12900 net.cpp:434] conv4/dw/relu <- conv4/dw
I0228 10:24:28.500624 12900 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I0228 10:24:28.501200 12900 net.cpp:150] Setting up conv4/dw/relu
I0228 10:24:28.501211 12900 net.cpp:157] Top shape: 8 128 38 38 (1478656)
I0228 10:24:28.501227 12900 net.cpp:165] Memory required for data: 783978528
I0228 10:24:28.501232 12900 layer_factory.hpp:77] Creating layer conv4
I0228 10:24:28.501243 12900 net.cpp:100] Creating Layer conv4
I0228 10:24:28.501248 12900 net.cpp:434] conv4 <- conv4/dw
I0228 10:24:28.501258 12900 net.cpp:408] conv4 -> conv4
I0228 10:24:28.503934 12900 net.cpp:150] Setting up conv4
I0228 10:24:28.503949 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.503953 12900 net.cpp:165] Memory required for data: 795807776
I0228 10:24:28.503962 12900 layer_factory.hpp:77] Creating layer conv4/bn
I0228 10:24:28.503984 12900 net.cpp:100] Creating Layer conv4/bn
I0228 10:24:28.503989 12900 net.cpp:434] conv4/bn <- conv4
I0228 10:24:28.503996 12900 net.cpp:395] conv4/bn -> conv4 (in-place)
I0228 10:24:28.504242 12900 net.cpp:150] Setting up conv4/bn
I0228 10:24:28.504252 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.504256 12900 net.cpp:165] Memory required for data: 807637024
I0228 10:24:28.504264 12900 layer_factory.hpp:77] Creating layer conv4/scale
I0228 10:24:28.504272 12900 net.cpp:100] Creating Layer conv4/scale
I0228 10:24:28.504277 12900 net.cpp:434] conv4/scale <- conv4
I0228 10:24:28.504284 12900 net.cpp:395] conv4/scale -> conv4 (in-place)
I0228 10:24:28.504333 12900 layer_factory.hpp:77] Creating layer conv4/scale
I0228 10:24:28.504513 12900 net.cpp:150] Setting up conv4/scale
I0228 10:24:28.504524 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.504528 12900 net.cpp:165] Memory required for data: 819466272
I0228 10:24:28.504535 12900 layer_factory.hpp:77] Creating layer conv4/relu
I0228 10:24:28.504544 12900 net.cpp:100] Creating Layer conv4/relu
I0228 10:24:28.504549 12900 net.cpp:434] conv4/relu <- conv4
I0228 10:24:28.504555 12900 net.cpp:395] conv4/relu -> conv4 (in-place)
I0228 10:24:28.505084 12900 net.cpp:150] Setting up conv4/relu
I0228 10:24:28.505115 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.505120 12900 net.cpp:165] Memory required for data: 831295520
I0228 10:24:28.505125 12900 layer_factory.hpp:77] Creating layer conv5/dw
I0228 10:24:28.505136 12900 net.cpp:100] Creating Layer conv5/dw
I0228 10:24:28.505141 12900 net.cpp:434] conv5/dw <- conv4
I0228 10:24:28.505154 12900 net.cpp:408] conv5/dw -> conv5/dw
I0228 10:24:28.505462 12900 net.cpp:150] Setting up conv5/dw
I0228 10:24:28.505471 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.505487 12900 net.cpp:165] Memory required for data: 843124768
I0228 10:24:28.505493 12900 layer_factory.hpp:77] Creating layer conv5/dw/bn
I0228 10:24:28.505501 12900 net.cpp:100] Creating Layer conv5/dw/bn
I0228 10:24:28.505506 12900 net.cpp:434] conv5/dw/bn <- conv5/dw
I0228 10:24:28.505512 12900 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I0228 10:24:28.505744 12900 net.cpp:150] Setting up conv5/dw/bn
I0228 10:24:28.505753 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.505758 12900 net.cpp:165] Memory required for data: 854954016
I0228 10:24:28.505766 12900 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0228 10:24:28.505774 12900 net.cpp:100] Creating Layer conv5/dw/scale
I0228 10:24:28.505779 12900 net.cpp:434] conv5/dw/scale <- conv5/dw
I0228 10:24:28.505786 12900 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I0228 10:24:28.505834 12900 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0228 10:24:28.505971 12900 net.cpp:150] Setting up conv5/dw/scale
I0228 10:24:28.505980 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.505985 12900 net.cpp:165] Memory required for data: 866783264
I0228 10:24:28.505991 12900 layer_factory.hpp:77] Creating layer conv5/dw/relu
I0228 10:24:28.505998 12900 net.cpp:100] Creating Layer conv5/dw/relu
I0228 10:24:28.506003 12900 net.cpp:434] conv5/dw/relu <- conv5/dw
I0228 10:24:28.506021 12900 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I0228 10:24:28.507091 12900 net.cpp:150] Setting up conv5/dw/relu
I0228 10:24:28.507107 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.507122 12900 net.cpp:165] Memory required for data: 878612512
I0228 10:24:28.507128 12900 layer_factory.hpp:77] Creating layer conv5
I0228 10:24:28.507139 12900 net.cpp:100] Creating Layer conv5
I0228 10:24:28.507160 12900 net.cpp:434] conv5 <- conv5/dw
I0228 10:24:28.507170 12900 net.cpp:408] conv5 -> conv5
I0228 10:24:28.510416 12900 net.cpp:150] Setting up conv5
I0228 10:24:28.510448 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.510453 12900 net.cpp:165] Memory required for data: 890441760
I0228 10:24:28.510462 12900 layer_factory.hpp:77] Creating layer conv5/bn
I0228 10:24:28.510468 12900 net.cpp:100] Creating Layer conv5/bn
I0228 10:24:28.510474 12900 net.cpp:434] conv5/bn <- conv5
I0228 10:24:28.510483 12900 net.cpp:395] conv5/bn -> conv5 (in-place)
I0228 10:24:28.510735 12900 net.cpp:150] Setting up conv5/bn
I0228 10:24:28.510745 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.510751 12900 net.cpp:165] Memory required for data: 902271008
I0228 10:24:28.510758 12900 layer_factory.hpp:77] Creating layer conv5/scale
I0228 10:24:28.510768 12900 net.cpp:100] Creating Layer conv5/scale
I0228 10:24:28.510772 12900 net.cpp:434] conv5/scale <- conv5
I0228 10:24:28.510779 12900 net.cpp:395] conv5/scale -> conv5 (in-place)
I0228 10:24:28.510826 12900 layer_factory.hpp:77] Creating layer conv5/scale
I0228 10:24:28.510962 12900 net.cpp:150] Setting up conv5/scale
I0228 10:24:28.510970 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.510975 12900 net.cpp:165] Memory required for data: 914100256
I0228 10:24:28.510992 12900 layer_factory.hpp:77] Creating layer conv5/relu
I0228 10:24:28.510998 12900 net.cpp:100] Creating Layer conv5/relu
I0228 10:24:28.511003 12900 net.cpp:434] conv5/relu <- conv5
I0228 10:24:28.511009 12900 net.cpp:395] conv5/relu -> conv5 (in-place)
I0228 10:24:28.511515 12900 net.cpp:150] Setting up conv5/relu
I0228 10:24:28.511528 12900 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0228 10:24:28.511543 12900 net.cpp:165] Memory required for data: 925929504
I0228 10:24:28.511548 12900 layer_factory.hpp:77] Creating layer conv6/dw
I0228 10:24:28.511559 12900 net.cpp:100] Creating Layer conv6/dw
I0228 10:24:28.511564 12900 net.cpp:434] conv6/dw <- conv5
I0228 10:24:28.511571 12900 net.cpp:408] conv6/dw -> conv6/dw
I0228 10:24:28.511847 12900 net.cpp:150] Setting up conv6/dw
I0228 10:24:28.511857 12900 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0228 10:24:28.511871 12900 net.cpp:165] Memory required for data: 928886816
I0228 10:24:28.511878 12900 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0228 10:24:28.511894 12900 net.cpp:100] Creating Layer conv6/dw/bn
I0228 10:24:28.511899 12900 net.cpp:434] conv6/dw/bn <- conv6/dw
I0228 10:24:28.511905 12900 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I0228 10:24:28.512168 12900 net.cpp:150] Setting up conv6/dw/bn
I0228 10:24:28.512178 12900 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0228 10:24:28.512182 12900 net.cpp:165] Memory required for data: 931844128
I0228 10:24:28.512190 12900 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0228 10:24:28.512198 12900 net.cpp:100] Creating Layer conv6/dw/scale
I0228 10:24:28.512204 12900 net.cpp:434] conv6/dw/scale <- conv6/dw
I0228 10:24:28.512212 12900 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I0228 10:24:28.512261 12900 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0228 10:24:28.512467 12900 net.cpp:150] Setting up conv6/dw/scale
I0228 10:24:28.512480 12900 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0228 10:24:28.512485 12900 net.cpp:165] Memory required for data: 934801440
I0228 10:24:28.512492 12900 layer_factory.hpp:77] Creating layer conv6/dw/relu
I0228 10:24:28.512500 12900 net.cpp:100] Creating Layer conv6/dw/relu
I0228 10:24:28.512506 12900 net.cpp:434] conv6/dw/relu <- conv6/dw
I0228 10:24:28.512511 12900 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I0228 10:24:28.513069 12900 net.cpp:150] Setting up conv6/dw/relu
I0228 10:24:28.513092 12900 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0228 10:24:28.513098 12900 net.cpp:165] Memory required for data: 937758752
I0228 10:24:28.513103 12900 layer_factory.hpp:77] Creating layer conv6
I0228 10:24:28.513129 12900 net.cpp:100] Creating Layer conv6
I0228 10:24:28.513134 12900 net.cpp:434] conv6 <- conv6/dw
I0228 10:24:28.513142 12900 net.cpp:408] conv6 -> conv6
I0228 10:24:28.516832 12900 net.cpp:150] Setting up conv6
I0228 10:24:28.516860 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.516865 12900 net.cpp:165] Memory required for data: 943673376
I0228 10:24:28.516872 12900 layer_factory.hpp:77] Creating layer conv6/bn
I0228 10:24:28.516881 12900 net.cpp:100] Creating Layer conv6/bn
I0228 10:24:28.516886 12900 net.cpp:434] conv6/bn <- conv6
I0228 10:24:28.516893 12900 net.cpp:395] conv6/bn -> conv6 (in-place)
I0228 10:24:28.517143 12900 net.cpp:150] Setting up conv6/bn
I0228 10:24:28.517153 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.517158 12900 net.cpp:165] Memory required for data: 949588000
I0228 10:24:28.517166 12900 layer_factory.hpp:77] Creating layer conv6/scale
I0228 10:24:28.517175 12900 net.cpp:100] Creating Layer conv6/scale
I0228 10:24:28.517179 12900 net.cpp:434] conv6/scale <- conv6
I0228 10:24:28.517185 12900 net.cpp:395] conv6/scale -> conv6 (in-place)
I0228 10:24:28.517240 12900 layer_factory.hpp:77] Creating layer conv6/scale
I0228 10:24:28.517403 12900 net.cpp:150] Setting up conv6/scale
I0228 10:24:28.517413 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.517418 12900 net.cpp:165] Memory required for data: 955502624
I0228 10:24:28.517426 12900 layer_factory.hpp:77] Creating layer conv6/relu
I0228 10:24:28.517434 12900 net.cpp:100] Creating Layer conv6/relu
I0228 10:24:28.517439 12900 net.cpp:434] conv6/relu <- conv6
I0228 10:24:28.517444 12900 net.cpp:395] conv6/relu -> conv6 (in-place)
I0228 10:24:28.517961 12900 net.cpp:150] Setting up conv6/relu
I0228 10:24:28.517974 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.517978 12900 net.cpp:165] Memory required for data: 961417248
I0228 10:24:28.517982 12900 layer_factory.hpp:77] Creating layer conv7/dw
I0228 10:24:28.517993 12900 net.cpp:100] Creating Layer conv7/dw
I0228 10:24:28.517999 12900 net.cpp:434] conv7/dw <- conv6
I0228 10:24:28.518007 12900 net.cpp:408] conv7/dw -> conv7/dw
I0228 10:24:28.518321 12900 net.cpp:150] Setting up conv7/dw
I0228 10:24:28.518332 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.518337 12900 net.cpp:165] Memory required for data: 967331872
I0228 10:24:28.518342 12900 layer_factory.hpp:77] Creating layer conv7/dw/bn
I0228 10:24:28.518349 12900 net.cpp:100] Creating Layer conv7/dw/bn
I0228 10:24:28.518354 12900 net.cpp:434] conv7/dw/bn <- conv7/dw
I0228 10:24:28.518362 12900 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I0228 10:24:28.518602 12900 net.cpp:150] Setting up conv7/dw/bn
I0228 10:24:28.518611 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.518616 12900 net.cpp:165] Memory required for data: 973246496
I0228 10:24:28.518625 12900 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0228 10:24:28.518632 12900 net.cpp:100] Creating Layer conv7/dw/scale
I0228 10:24:28.518637 12900 net.cpp:434] conv7/dw/scale <- conv7/dw
I0228 10:24:28.518645 12900 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I0228 10:24:28.518697 12900 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0228 10:24:28.518841 12900 net.cpp:150] Setting up conv7/dw/scale
I0228 10:24:28.518849 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.518854 12900 net.cpp:165] Memory required for data: 979161120
I0228 10:24:28.518862 12900 layer_factory.hpp:77] Creating layer conv7/dw/relu
I0228 10:24:28.518868 12900 net.cpp:100] Creating Layer conv7/dw/relu
I0228 10:24:28.518873 12900 net.cpp:434] conv7/dw/relu <- conv7/dw
I0228 10:24:28.518878 12900 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I0228 10:24:28.520061 12900 net.cpp:150] Setting up conv7/dw/relu
I0228 10:24:28.520087 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.520092 12900 net.cpp:165] Memory required for data: 985075744
I0228 10:24:28.520097 12900 layer_factory.hpp:77] Creating layer conv7
I0228 10:24:28.520123 12900 net.cpp:100] Creating Layer conv7
I0228 10:24:28.520129 12900 net.cpp:434] conv7 <- conv7/dw
I0228 10:24:28.520136 12900 net.cpp:408] conv7 -> conv7
I0228 10:24:28.525257 12900 net.cpp:150] Setting up conv7
I0228 10:24:28.525291 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.525296 12900 net.cpp:165] Memory required for data: 990990368
I0228 10:24:28.525303 12900 layer_factory.hpp:77] Creating layer conv7/bn
I0228 10:24:28.525311 12900 net.cpp:100] Creating Layer conv7/bn
I0228 10:24:28.525317 12900 net.cpp:434] conv7/bn <- conv7
I0228 10:24:28.525324 12900 net.cpp:395] conv7/bn -> conv7 (in-place)
I0228 10:24:28.525580 12900 net.cpp:150] Setting up conv7/bn
I0228 10:24:28.525590 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.525596 12900 net.cpp:165] Memory required for data: 996904992
I0228 10:24:28.525605 12900 layer_factory.hpp:77] Creating layer conv7/scale
I0228 10:24:28.525614 12900 net.cpp:100] Creating Layer conv7/scale
I0228 10:24:28.525619 12900 net.cpp:434] conv7/scale <- conv7
I0228 10:24:28.525627 12900 net.cpp:395] conv7/scale -> conv7 (in-place)
I0228 10:24:28.525717 12900 layer_factory.hpp:77] Creating layer conv7/scale
I0228 10:24:28.525871 12900 net.cpp:150] Setting up conv7/scale
I0228 10:24:28.525880 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.525887 12900 net.cpp:165] Memory required for data: 1002819616
I0228 10:24:28.525893 12900 layer_factory.hpp:77] Creating layer conv7/relu
I0228 10:24:28.525900 12900 net.cpp:100] Creating Layer conv7/relu
I0228 10:24:28.525905 12900 net.cpp:434] conv7/relu <- conv7
I0228 10:24:28.525914 12900 net.cpp:395] conv7/relu -> conv7 (in-place)
I0228 10:24:28.526446 12900 net.cpp:150] Setting up conv7/relu
I0228 10:24:28.526458 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.526477 12900 net.cpp:165] Memory required for data: 1008734240
I0228 10:24:28.526482 12900 layer_factory.hpp:77] Creating layer conv8/dw
I0228 10:24:28.526494 12900 net.cpp:100] Creating Layer conv8/dw
I0228 10:24:28.526499 12900 net.cpp:434] conv8/dw <- conv7
I0228 10:24:28.526507 12900 net.cpp:408] conv8/dw -> conv8/dw
I0228 10:24:28.526840 12900 net.cpp:150] Setting up conv8/dw
I0228 10:24:28.526850 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.526870 12900 net.cpp:165] Memory required for data: 1014648864
I0228 10:24:28.526876 12900 layer_factory.hpp:77] Creating layer conv8/dw/bn
I0228 10:24:28.526885 12900 net.cpp:100] Creating Layer conv8/dw/bn
I0228 10:24:28.526888 12900 net.cpp:434] conv8/dw/bn <- conv8/dw
I0228 10:24:28.526895 12900 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I0228 10:24:28.527181 12900 net.cpp:150] Setting up conv8/dw/bn
I0228 10:24:28.527192 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.527196 12900 net.cpp:165] Memory required for data: 1020563488
I0228 10:24:28.527205 12900 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0228 10:24:28.527236 12900 net.cpp:100] Creating Layer conv8/dw/scale
I0228 10:24:28.527245 12900 net.cpp:434] conv8/dw/scale <- conv8/dw
I0228 10:24:28.527251 12900 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I0228 10:24:28.527305 12900 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0228 10:24:28.527451 12900 net.cpp:150] Setting up conv8/dw/scale
I0228 10:24:28.527462 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.527467 12900 net.cpp:165] Memory required for data: 1026478112
I0228 10:24:28.527474 12900 layer_factory.hpp:77] Creating layer conv8/dw/relu
I0228 10:24:28.527480 12900 net.cpp:100] Creating Layer conv8/dw/relu
I0228 10:24:28.527487 12900 net.cpp:434] conv8/dw/relu <- conv8/dw
I0228 10:24:28.527492 12900 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I0228 10:24:28.528041 12900 net.cpp:150] Setting up conv8/dw/relu
I0228 10:24:28.528069 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.528087 12900 net.cpp:165] Memory required for data: 1032392736
I0228 10:24:28.528092 12900 layer_factory.hpp:77] Creating layer conv8
I0228 10:24:28.528105 12900 net.cpp:100] Creating Layer conv8
I0228 10:24:28.528108 12900 net.cpp:434] conv8 <- conv8/dw
I0228 10:24:28.528117 12900 net.cpp:408] conv8 -> conv8
I0228 10:24:28.534438 12900 net.cpp:150] Setting up conv8
I0228 10:24:28.534471 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.534476 12900 net.cpp:165] Memory required for data: 1038307360
I0228 10:24:28.534483 12900 layer_factory.hpp:77] Creating layer conv8/bn
I0228 10:24:28.534492 12900 net.cpp:100] Creating Layer conv8/bn
I0228 10:24:28.534497 12900 net.cpp:434] conv8/bn <- conv8
I0228 10:24:28.534504 12900 net.cpp:395] conv8/bn -> conv8 (in-place)
I0228 10:24:28.534795 12900 net.cpp:150] Setting up conv8/bn
I0228 10:24:28.534804 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.534808 12900 net.cpp:165] Memory required for data: 1044221984
I0228 10:24:28.534817 12900 layer_factory.hpp:77] Creating layer conv8/scale
I0228 10:24:28.534827 12900 net.cpp:100] Creating Layer conv8/scale
I0228 10:24:28.534832 12900 net.cpp:434] conv8/scale <- conv8
I0228 10:24:28.534838 12900 net.cpp:395] conv8/scale -> conv8 (in-place)
I0228 10:24:28.534891 12900 layer_factory.hpp:77] Creating layer conv8/scale
I0228 10:24:28.535037 12900 net.cpp:150] Setting up conv8/scale
I0228 10:24:28.535049 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.535053 12900 net.cpp:165] Memory required for data: 1050136608
I0228 10:24:28.535060 12900 layer_factory.hpp:77] Creating layer conv8/relu
I0228 10:24:28.535069 12900 net.cpp:100] Creating Layer conv8/relu
I0228 10:24:28.535074 12900 net.cpp:434] conv8/relu <- conv8
I0228 10:24:28.535079 12900 net.cpp:395] conv8/relu -> conv8 (in-place)
I0228 10:24:28.536206 12900 net.cpp:150] Setting up conv8/relu
I0228 10:24:28.536222 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.536226 12900 net.cpp:165] Memory required for data: 1056051232
I0228 10:24:28.536231 12900 layer_factory.hpp:77] Creating layer conv9/dw
I0228 10:24:28.536244 12900 net.cpp:100] Creating Layer conv9/dw
I0228 10:24:28.536249 12900 net.cpp:434] conv9/dw <- conv8
I0228 10:24:28.536258 12900 net.cpp:408] conv9/dw -> conv9/dw
I0228 10:24:28.536619 12900 net.cpp:150] Setting up conv9/dw
I0228 10:24:28.536629 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.536650 12900 net.cpp:165] Memory required for data: 1061965856
I0228 10:24:28.536656 12900 layer_factory.hpp:77] Creating layer conv9/dw/bn
I0228 10:24:28.536664 12900 net.cpp:100] Creating Layer conv9/dw/bn
I0228 10:24:28.536682 12900 net.cpp:434] conv9/dw/bn <- conv9/dw
I0228 10:24:28.536689 12900 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I0228 10:24:28.536952 12900 net.cpp:150] Setting up conv9/dw/bn
I0228 10:24:28.536962 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.536965 12900 net.cpp:165] Memory required for data: 1067880480
I0228 10:24:28.536974 12900 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0228 10:24:28.536981 12900 net.cpp:100] Creating Layer conv9/dw/scale
I0228 10:24:28.536986 12900 net.cpp:434] conv9/dw/scale <- conv9/dw
I0228 10:24:28.536991 12900 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I0228 10:24:28.537045 12900 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0228 10:24:28.537189 12900 net.cpp:150] Setting up conv9/dw/scale
I0228 10:24:28.537199 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.537204 12900 net.cpp:165] Memory required for data: 1073795104
I0228 10:24:28.537211 12900 layer_factory.hpp:77] Creating layer conv9/dw/relu
I0228 10:24:28.537219 12900 net.cpp:100] Creating Layer conv9/dw/relu
I0228 10:24:28.537223 12900 net.cpp:434] conv9/dw/relu <- conv9/dw
I0228 10:24:28.537230 12900 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I0228 10:24:28.537739 12900 net.cpp:150] Setting up conv9/dw/relu
I0228 10:24:28.537761 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.537765 12900 net.cpp:165] Memory required for data: 1079709728
I0228 10:24:28.537770 12900 layer_factory.hpp:77] Creating layer conv9
I0228 10:24:28.537798 12900 net.cpp:100] Creating Layer conv9
I0228 10:24:28.537803 12900 net.cpp:434] conv9 <- conv9/dw
I0228 10:24:28.537812 12900 net.cpp:408] conv9 -> conv9
I0228 10:24:28.543332 12900 net.cpp:150] Setting up conv9
I0228 10:24:28.543365 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.543370 12900 net.cpp:165] Memory required for data: 1085624352
I0228 10:24:28.543378 12900 layer_factory.hpp:77] Creating layer conv9/bn
I0228 10:24:28.543387 12900 net.cpp:100] Creating Layer conv9/bn
I0228 10:24:28.543393 12900 net.cpp:434] conv9/bn <- conv9
I0228 10:24:28.543402 12900 net.cpp:395] conv9/bn -> conv9 (in-place)
I0228 10:24:28.543659 12900 net.cpp:150] Setting up conv9/bn
I0228 10:24:28.543668 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.543674 12900 net.cpp:165] Memory required for data: 1091538976
I0228 10:24:28.543682 12900 layer_factory.hpp:77] Creating layer conv9/scale
I0228 10:24:28.543690 12900 net.cpp:100] Creating Layer conv9/scale
I0228 10:24:28.543695 12900 net.cpp:434] conv9/scale <- conv9
I0228 10:24:28.543704 12900 net.cpp:395] conv9/scale -> conv9 (in-place)
I0228 10:24:28.543754 12900 layer_factory.hpp:77] Creating layer conv9/scale
I0228 10:24:28.543918 12900 net.cpp:150] Setting up conv9/scale
I0228 10:24:28.543927 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.543932 12900 net.cpp:165] Memory required for data: 1097453600
I0228 10:24:28.543941 12900 layer_factory.hpp:77] Creating layer conv9/relu
I0228 10:24:28.543946 12900 net.cpp:100] Creating Layer conv9/relu
I0228 10:24:28.543951 12900 net.cpp:434] conv9/relu <- conv9
I0228 10:24:28.543961 12900 net.cpp:395] conv9/relu -> conv9 (in-place)
I0228 10:24:28.544492 12900 net.cpp:150] Setting up conv9/relu
I0228 10:24:28.544503 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.544523 12900 net.cpp:165] Memory required for data: 1103368224
I0228 10:24:28.544529 12900 layer_factory.hpp:77] Creating layer conv10/dw
I0228 10:24:28.544539 12900 net.cpp:100] Creating Layer conv10/dw
I0228 10:24:28.544544 12900 net.cpp:434] conv10/dw <- conv9
I0228 10:24:28.544553 12900 net.cpp:408] conv10/dw -> conv10/dw
I0228 10:24:28.544862 12900 net.cpp:150] Setting up conv10/dw
I0228 10:24:28.544872 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.544875 12900 net.cpp:165] Memory required for data: 1109282848
I0228 10:24:28.544881 12900 layer_factory.hpp:77] Creating layer conv10/dw/bn
I0228 10:24:28.544904 12900 net.cpp:100] Creating Layer conv10/dw/bn
I0228 10:24:28.544909 12900 net.cpp:434] conv10/dw/bn <- conv10/dw
I0228 10:24:28.544915 12900 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I0228 10:24:28.545161 12900 net.cpp:150] Setting up conv10/dw/bn
I0228 10:24:28.545171 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.545174 12900 net.cpp:165] Memory required for data: 1115197472
I0228 10:24:28.545182 12900 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0228 10:24:28.545191 12900 net.cpp:100] Creating Layer conv10/dw/scale
I0228 10:24:28.545195 12900 net.cpp:434] conv10/dw/scale <- conv10/dw
I0228 10:24:28.545202 12900 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I0228 10:24:28.545253 12900 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0228 10:24:28.545395 12900 net.cpp:150] Setting up conv10/dw/scale
I0228 10:24:28.545404 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.545409 12900 net.cpp:165] Memory required for data: 1121112096
I0228 10:24:28.545415 12900 layer_factory.hpp:77] Creating layer conv10/dw/relu
I0228 10:24:28.545423 12900 net.cpp:100] Creating Layer conv10/dw/relu
I0228 10:24:28.545428 12900 net.cpp:434] conv10/dw/relu <- conv10/dw
I0228 10:24:28.545433 12900 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I0228 10:24:28.546555 12900 net.cpp:150] Setting up conv10/dw/relu
I0228 10:24:28.546572 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.546577 12900 net.cpp:165] Memory required for data: 1127026720
I0228 10:24:28.546582 12900 layer_factory.hpp:77] Creating layer conv10
I0228 10:24:28.546592 12900 net.cpp:100] Creating Layer conv10
I0228 10:24:28.546597 12900 net.cpp:434] conv10 <- conv10/dw
I0228 10:24:28.546605 12900 net.cpp:408] conv10 -> conv10
I0228 10:24:28.552806 12900 net.cpp:150] Setting up conv10
I0228 10:24:28.552824 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.552829 12900 net.cpp:165] Memory required for data: 1132941344
I0228 10:24:28.552837 12900 layer_factory.hpp:77] Creating layer conv10/bn
I0228 10:24:28.552845 12900 net.cpp:100] Creating Layer conv10/bn
I0228 10:24:28.552850 12900 net.cpp:434] conv10/bn <- conv10
I0228 10:24:28.552857 12900 net.cpp:395] conv10/bn -> conv10 (in-place)
I0228 10:24:28.553136 12900 net.cpp:150] Setting up conv10/bn
I0228 10:24:28.553146 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.553150 12900 net.cpp:165] Memory required for data: 1138855968
I0228 10:24:28.553158 12900 layer_factory.hpp:77] Creating layer conv10/scale
I0228 10:24:28.553167 12900 net.cpp:100] Creating Layer conv10/scale
I0228 10:24:28.553172 12900 net.cpp:434] conv10/scale <- conv10
I0228 10:24:28.553180 12900 net.cpp:395] conv10/scale -> conv10 (in-place)
I0228 10:24:28.553232 12900 layer_factory.hpp:77] Creating layer conv10/scale
I0228 10:24:28.553376 12900 net.cpp:150] Setting up conv10/scale
I0228 10:24:28.553385 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.553390 12900 net.cpp:165] Memory required for data: 1144770592
I0228 10:24:28.553396 12900 layer_factory.hpp:77] Creating layer conv10/relu
I0228 10:24:28.553403 12900 net.cpp:100] Creating Layer conv10/relu
I0228 10:24:28.553408 12900 net.cpp:434] conv10/relu <- conv10
I0228 10:24:28.553416 12900 net.cpp:395] conv10/relu -> conv10 (in-place)
I0228 10:24:28.553956 12900 net.cpp:150] Setting up conv10/relu
I0228 10:24:28.553968 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.553973 12900 net.cpp:165] Memory required for data: 1150685216
I0228 10:24:28.553977 12900 layer_factory.hpp:77] Creating layer conv11/dw
I0228 10:24:28.553987 12900 net.cpp:100] Creating Layer conv11/dw
I0228 10:24:28.553993 12900 net.cpp:434] conv11/dw <- conv10
I0228 10:24:28.554002 12900 net.cpp:408] conv11/dw -> conv11/dw
I0228 10:24:28.554294 12900 net.cpp:150] Setting up conv11/dw
I0228 10:24:28.554304 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.554311 12900 net.cpp:165] Memory required for data: 1156599840
I0228 10:24:28.554316 12900 layer_factory.hpp:77] Creating layer conv11/dw/bn
I0228 10:24:28.554323 12900 net.cpp:100] Creating Layer conv11/dw/bn
I0228 10:24:28.554328 12900 net.cpp:434] conv11/dw/bn <- conv11/dw
I0228 10:24:28.554334 12900 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I0228 10:24:28.554591 12900 net.cpp:150] Setting up conv11/dw/bn
I0228 10:24:28.554600 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.554605 12900 net.cpp:165] Memory required for data: 1162514464
I0228 10:24:28.554628 12900 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0228 10:24:28.554639 12900 net.cpp:100] Creating Layer conv11/dw/scale
I0228 10:24:28.554643 12900 net.cpp:434] conv11/dw/scale <- conv11/dw
I0228 10:24:28.554649 12900 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I0228 10:24:28.554707 12900 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0228 10:24:28.554847 12900 net.cpp:150] Setting up conv11/dw/scale
I0228 10:24:28.554855 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.554860 12900 net.cpp:165] Memory required for data: 1168429088
I0228 10:24:28.554867 12900 layer_factory.hpp:77] Creating layer conv11/dw/relu
I0228 10:24:28.554875 12900 net.cpp:100] Creating Layer conv11/dw/relu
I0228 10:24:28.554880 12900 net.cpp:434] conv11/dw/relu <- conv11/dw
I0228 10:24:28.554900 12900 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I0228 10:24:28.555400 12900 net.cpp:150] Setting up conv11/dw/relu
I0228 10:24:28.555413 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.555428 12900 net.cpp:165] Memory required for data: 1174343712
I0228 10:24:28.555433 12900 layer_factory.hpp:77] Creating layer conv11
I0228 10:24:28.555444 12900 net.cpp:100] Creating Layer conv11
I0228 10:24:28.555449 12900 net.cpp:434] conv11 <- conv11/dw
I0228 10:24:28.555456 12900 net.cpp:408] conv11 -> conv11
I0228 10:24:28.560586 12900 net.cpp:150] Setting up conv11
I0228 10:24:28.560618 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.560623 12900 net.cpp:165] Memory required for data: 1180258336
I0228 10:24:28.560631 12900 layer_factory.hpp:77] Creating layer conv11/bn
I0228 10:24:28.560637 12900 net.cpp:100] Creating Layer conv11/bn
I0228 10:24:28.560643 12900 net.cpp:434] conv11/bn <- conv11
I0228 10:24:28.560652 12900 net.cpp:395] conv11/bn -> conv11 (in-place)
I0228 10:24:28.560940 12900 net.cpp:150] Setting up conv11/bn
I0228 10:24:28.560950 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.560956 12900 net.cpp:165] Memory required for data: 1186172960
I0228 10:24:28.560963 12900 layer_factory.hpp:77] Creating layer conv11/scale
I0228 10:24:28.560971 12900 net.cpp:100] Creating Layer conv11/scale
I0228 10:24:28.560976 12900 net.cpp:434] conv11/scale <- conv11
I0228 10:24:28.560986 12900 net.cpp:395] conv11/scale -> conv11 (in-place)
I0228 10:24:28.561038 12900 layer_factory.hpp:77] Creating layer conv11/scale
I0228 10:24:28.561182 12900 net.cpp:150] Setting up conv11/scale
I0228 10:24:28.561192 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.561197 12900 net.cpp:165] Memory required for data: 1192087584
I0228 10:24:28.561203 12900 layer_factory.hpp:77] Creating layer conv11/relu
I0228 10:24:28.561211 12900 net.cpp:100] Creating Layer conv11/relu
I0228 10:24:28.561216 12900 net.cpp:434] conv11/relu <- conv11
I0228 10:24:28.561224 12900 net.cpp:395] conv11/relu -> conv11 (in-place)
I0228 10:24:28.561758 12900 net.cpp:150] Setting up conv11/relu
I0228 10:24:28.561769 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.561789 12900 net.cpp:165] Memory required for data: 1198002208
I0228 10:24:28.561794 12900 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I0228 10:24:28.561802 12900 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I0228 10:24:28.561807 12900 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I0228 10:24:28.561815 12900 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I0228 10:24:28.561830 12900 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I0228 10:24:28.561838 12900 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I0228 10:24:28.561846 12900 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I0228 10:24:28.561933 12900 net.cpp:150] Setting up conv11_conv11/relu_0_split
I0228 10:24:28.561942 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.561947 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.561952 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.561957 12900 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0228 10:24:28.561962 12900 net.cpp:165] Memory required for data: 1221660704
I0228 10:24:28.561967 12900 layer_factory.hpp:77] Creating layer conv12/dw
I0228 10:24:28.561980 12900 net.cpp:100] Creating Layer conv12/dw
I0228 10:24:28.561985 12900 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I0228 10:24:28.561991 12900 net.cpp:408] conv12/dw -> conv12/dw
I0228 10:24:28.562295 12900 net.cpp:150] Setting up conv12/dw
I0228 10:24:28.562305 12900 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0228 10:24:28.562309 12900 net.cpp:165] Memory required for data: 1223299104
I0228 10:24:28.562317 12900 layer_factory.hpp:77] Creating layer conv12/dw/bn
I0228 10:24:28.562325 12900 net.cpp:100] Creating Layer conv12/dw/bn
I0228 10:24:28.562330 12900 net.cpp:434] conv12/dw/bn <- conv12/dw
I0228 10:24:28.562347 12900 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I0228 10:24:28.562633 12900 net.cpp:150] Setting up conv12/dw/bn
I0228 10:24:28.562652 12900 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0228 10:24:28.562669 12900 net.cpp:165] Memory required for data: 1224937504
I0228 10:24:28.562676 12900 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0228 10:24:28.562686 12900 net.cpp:100] Creating Layer conv12/dw/scale
I0228 10:24:28.562691 12900 net.cpp:434] conv12/dw/scale <- conv12/dw
I0228 10:24:28.562697 12900 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I0228 10:24:28.562743 12900 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0228 10:24:28.562899 12900 net.cpp:150] Setting up conv12/dw/scale
I0228 10:24:28.562907 12900 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0228 10:24:28.562911 12900 net.cpp:165] Memory required for data: 1226575904
I0228 10:24:28.562918 12900 layer_factory.hpp:77] Creating layer conv12/dw/relu
I0228 10:24:28.562927 12900 net.cpp:100] Creating Layer conv12/dw/relu
I0228 10:24:28.562932 12900 net.cpp:434] conv12/dw/relu <- conv12/dw
I0228 10:24:28.562938 12900 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I0228 10:24:28.564189 12900 net.cpp:150] Setting up conv12/dw/relu
I0228 10:24:28.564205 12900 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0228 10:24:28.564221 12900 net.cpp:165] Memory required for data: 1228214304
I0228 10:24:28.564226 12900 layer_factory.hpp:77] Creating layer conv12
I0228 10:24:28.564239 12900 net.cpp:100] Creating Layer conv12
I0228 10:24:28.564245 12900 net.cpp:434] conv12 <- conv12/dw
I0228 10:24:28.564252 12900 net.cpp:408] conv12 -> conv12
I0228 10:24:28.573076 12900 net.cpp:150] Setting up conv12
I0228 10:24:28.573094 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.573099 12900 net.cpp:165] Memory required for data: 1231491104
I0228 10:24:28.573107 12900 layer_factory.hpp:77] Creating layer conv12/bn
I0228 10:24:28.573115 12900 net.cpp:100] Creating Layer conv12/bn
I0228 10:24:28.573122 12900 net.cpp:434] conv12/bn <- conv12
I0228 10:24:28.573128 12900 net.cpp:395] conv12/bn -> conv12 (in-place)
I0228 10:24:28.573429 12900 net.cpp:150] Setting up conv12/bn
I0228 10:24:28.573441 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.573444 12900 net.cpp:165] Memory required for data: 1234767904
I0228 10:24:28.573453 12900 layer_factory.hpp:77] Creating layer conv12/scale
I0228 10:24:28.573462 12900 net.cpp:100] Creating Layer conv12/scale
I0228 10:24:28.573467 12900 net.cpp:434] conv12/scale <- conv12
I0228 10:24:28.573487 12900 net.cpp:395] conv12/scale -> conv12 (in-place)
I0228 10:24:28.573555 12900 layer_factory.hpp:77] Creating layer conv12/scale
I0228 10:24:28.573709 12900 net.cpp:150] Setting up conv12/scale
I0228 10:24:28.573719 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.573724 12900 net.cpp:165] Memory required for data: 1238044704
I0228 10:24:28.573731 12900 layer_factory.hpp:77] Creating layer conv12/relu
I0228 10:24:28.573741 12900 net.cpp:100] Creating Layer conv12/relu
I0228 10:24:28.573745 12900 net.cpp:434] conv12/relu <- conv12
I0228 10:24:28.573751 12900 net.cpp:395] conv12/relu -> conv12 (in-place)
I0228 10:24:28.574314 12900 net.cpp:150] Setting up conv12/relu
I0228 10:24:28.574342 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.574347 12900 net.cpp:165] Memory required for data: 1241321504
I0228 10:24:28.574350 12900 layer_factory.hpp:77] Creating layer conv13/dw
I0228 10:24:28.574362 12900 net.cpp:100] Creating Layer conv13/dw
I0228 10:24:28.574367 12900 net.cpp:434] conv13/dw <- conv12
I0228 10:24:28.574375 12900 net.cpp:408] conv13/dw -> conv13/dw
I0228 10:24:28.574753 12900 net.cpp:150] Setting up conv13/dw
I0228 10:24:28.574765 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.574769 12900 net.cpp:165] Memory required for data: 1244598304
I0228 10:24:28.574775 12900 layer_factory.hpp:77] Creating layer conv13/dw/bn
I0228 10:24:28.574782 12900 net.cpp:100] Creating Layer conv13/dw/bn
I0228 10:24:28.574802 12900 net.cpp:434] conv13/dw/bn <- conv13/dw
I0228 10:24:28.574810 12900 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I0228 10:24:28.575069 12900 net.cpp:150] Setting up conv13/dw/bn
I0228 10:24:28.575080 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.575085 12900 net.cpp:165] Memory required for data: 1247875104
I0228 10:24:28.575094 12900 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0228 10:24:28.575101 12900 net.cpp:100] Creating Layer conv13/dw/scale
I0228 10:24:28.575106 12900 net.cpp:434] conv13/dw/scale <- conv13/dw
I0228 10:24:28.575114 12900 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I0228 10:24:28.575162 12900 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0228 10:24:28.575315 12900 net.cpp:150] Setting up conv13/dw/scale
I0228 10:24:28.575338 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.575343 12900 net.cpp:165] Memory required for data: 1251151904
I0228 10:24:28.575350 12900 layer_factory.hpp:77] Creating layer conv13/dw/relu
I0228 10:24:28.575356 12900 net.cpp:100] Creating Layer conv13/dw/relu
I0228 10:24:28.575361 12900 net.cpp:434] conv13/dw/relu <- conv13/dw
I0228 10:24:28.575368 12900 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I0228 10:24:28.575887 12900 net.cpp:150] Setting up conv13/dw/relu
I0228 10:24:28.575901 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.575904 12900 net.cpp:165] Memory required for data: 1254428704
I0228 10:24:28.575911 12900 layer_factory.hpp:77] Creating layer conv13
I0228 10:24:28.575922 12900 net.cpp:100] Creating Layer conv13
I0228 10:24:28.575927 12900 net.cpp:434] conv13 <- conv13/dw
I0228 10:24:28.575933 12900 net.cpp:408] conv13 -> conv13
I0228 10:24:28.590239 12900 net.cpp:150] Setting up conv13
I0228 10:24:28.590262 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.590267 12900 net.cpp:165] Memory required for data: 1257705504
I0228 10:24:28.590276 12900 layer_factory.hpp:77] Creating layer conv13/bn
I0228 10:24:28.590286 12900 net.cpp:100] Creating Layer conv13/bn
I0228 10:24:28.590291 12900 net.cpp:434] conv13/bn <- conv13
I0228 10:24:28.590298 12900 net.cpp:395] conv13/bn -> conv13 (in-place)
I0228 10:24:28.590584 12900 net.cpp:150] Setting up conv13/bn
I0228 10:24:28.590595 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.590600 12900 net.cpp:165] Memory required for data: 1260982304
I0228 10:24:28.590608 12900 layer_factory.hpp:77] Creating layer conv13/scale
I0228 10:24:28.590616 12900 net.cpp:100] Creating Layer conv13/scale
I0228 10:24:28.590622 12900 net.cpp:434] conv13/scale <- conv13
I0228 10:24:28.590631 12900 net.cpp:395] conv13/scale -> conv13 (in-place)
I0228 10:24:28.590682 12900 layer_factory.hpp:77] Creating layer conv13/scale
I0228 10:24:28.590839 12900 net.cpp:150] Setting up conv13/scale
I0228 10:24:28.590848 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.590853 12900 net.cpp:165] Memory required for data: 1264259104
I0228 10:24:28.590860 12900 layer_factory.hpp:77] Creating layer conv13/relu
I0228 10:24:28.590867 12900 net.cpp:100] Creating Layer conv13/relu
I0228 10:24:28.590873 12900 net.cpp:434] conv13/relu <- conv13
I0228 10:24:28.590879 12900 net.cpp:395] conv13/relu -> conv13 (in-place)
I0228 10:24:28.592038 12900 net.cpp:150] Setting up conv13/relu
I0228 10:24:28.592054 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.592059 12900 net.cpp:165] Memory required for data: 1267535904
I0228 10:24:28.592064 12900 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I0228 10:24:28.592074 12900 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I0228 10:24:28.592079 12900 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I0228 10:24:28.592087 12900 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I0228 10:24:28.592097 12900 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I0228 10:24:28.592106 12900 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I0228 10:24:28.592130 12900 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I0228 10:24:28.592222 12900 net.cpp:150] Setting up conv13_conv13/relu_0_split
I0228 10:24:28.592231 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.592236 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.592242 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.592248 12900 net.cpp:157] Top shape: 8 1024 10 10 (819200)
I0228 10:24:28.592252 12900 net.cpp:165] Memory required for data: 1280643104
I0228 10:24:28.592257 12900 layer_factory.hpp:77] Creating layer conv14_1
I0228 10:24:28.592269 12900 net.cpp:100] Creating Layer conv14_1
I0228 10:24:28.592275 12900 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I0228 10:24:28.592283 12900 net.cpp:408] conv14_1 -> conv14_1
I0228 10:24:28.598554 12900 net.cpp:150] Setting up conv14_1
I0228 10:24:28.598572 12900 net.cpp:157] Top shape: 8 256 10 10 (204800)
I0228 10:24:28.598577 12900 net.cpp:165] Memory required for data: 1281462304
I0228 10:24:28.598585 12900 layer_factory.hpp:77] Creating layer conv14_1/bn
I0228 10:24:28.598594 12900 net.cpp:100] Creating Layer conv14_1/bn
I0228 10:24:28.598599 12900 net.cpp:434] conv14_1/bn <- conv14_1
I0228 10:24:28.598608 12900 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I0228 10:24:28.598882 12900 net.cpp:150] Setting up conv14_1/bn
I0228 10:24:28.598892 12900 net.cpp:157] Top shape: 8 256 10 10 (204800)
I0228 10:24:28.598896 12900 net.cpp:165] Memory required for data: 1282281504
I0228 10:24:28.598906 12900 layer_factory.hpp:77] Creating layer conv14_1/scale
I0228 10:24:28.598913 12900 net.cpp:100] Creating Layer conv14_1/scale
I0228 10:24:28.598918 12900 net.cpp:434] conv14_1/scale <- conv14_1
I0228 10:24:28.598924 12900 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I0228 10:24:28.598980 12900 layer_factory.hpp:77] Creating layer conv14_1/scale
I0228 10:24:28.599125 12900 net.cpp:150] Setting up conv14_1/scale
I0228 10:24:28.599138 12900 net.cpp:157] Top shape: 8 256 10 10 (204800)
I0228 10:24:28.599141 12900 net.cpp:165] Memory required for data: 1283100704
I0228 10:24:28.599149 12900 layer_factory.hpp:77] Creating layer conv14_1/relu
I0228 10:24:28.599156 12900 net.cpp:100] Creating Layer conv14_1/relu
I0228 10:24:28.599160 12900 net.cpp:434] conv14_1/relu <- conv14_1
I0228 10:24:28.599166 12900 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I0228 10:24:28.599761 12900 net.cpp:150] Setting up conv14_1/relu
I0228 10:24:28.599773 12900 net.cpp:157] Top shape: 8 256 10 10 (204800)
I0228 10:24:28.599777 12900 net.cpp:165] Memory required for data: 1283919904
I0228 10:24:28.599782 12900 layer_factory.hpp:77] Creating layer conv14_2
I0228 10:24:28.599792 12900 net.cpp:100] Creating Layer conv14_2
I0228 10:24:28.599797 12900 net.cpp:434] conv14_2 <- conv14_1
I0228 10:24:28.599804 12900 net.cpp:408] conv14_2 -> conv14_2
I0228 10:24:28.616010 12900 net.cpp:150] Setting up conv14_2
I0228 10:24:28.616050 12900 net.cpp:157] Top shape: 8 512 5 5 (102400)
I0228 10:24:28.616055 12900 net.cpp:165] Memory required for data: 1284329504
I0228 10:24:28.616063 12900 layer_factory.hpp:77] Creating layer conv14_2/bn
I0228 10:24:28.616076 12900 net.cpp:100] Creating Layer conv14_2/bn
I0228 10:24:28.616083 12900 net.cpp:434] conv14_2/bn <- conv14_2
I0228 10:24:28.616091 12900 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I0228 10:24:28.616457 12900 net.cpp:150] Setting up conv14_2/bn
I0228 10:24:28.616467 12900 net.cpp:157] Top shape: 8 512 5 5 (102400)
I0228 10:24:28.616488 12900 net.cpp:165] Memory required for data: 1284739104
I0228 10:24:28.616497 12900 layer_factory.hpp:77] Creating layer conv14_2/scale
I0228 10:24:28.616505 12900 net.cpp:100] Creating Layer conv14_2/scale
I0228 10:24:28.616510 12900 net.cpp:434] conv14_2/scale <- conv14_2
I0228 10:24:28.616519 12900 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I0228 10:24:28.616575 12900 layer_factory.hpp:77] Creating layer conv14_2/scale
I0228 10:24:28.616749 12900 net.cpp:150] Setting up conv14_2/scale
I0228 10:24:28.616757 12900 net.cpp:157] Top shape: 8 512 5 5 (102400)
I0228 10:24:28.616777 12900 net.cpp:165] Memory required for data: 1285148704
I0228 10:24:28.616801 12900 layer_factory.hpp:77] Creating layer conv14_2/relu
I0228 10:24:28.616824 12900 net.cpp:100] Creating Layer conv14_2/relu
I0228 10:24:28.616830 12900 net.cpp:434] conv14_2/relu <- conv14_2
I0228 10:24:28.616837 12900 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I0228 10:24:28.617396 12900 net.cpp:150] Setting up conv14_2/relu
I0228 10:24:28.617408 12900 net.cpp:157] Top shape: 8 512 5 5 (102400)
I0228 10:24:28.617429 12900 net.cpp:165] Memory required for data: 1285558304
I0228 10:24:28.617434 12900 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I0228 10:24:28.617442 12900 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I0228 10:24:28.617447 12900 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I0228 10:24:28.617456 12900 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I0228 10:24:28.617467 12900 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I0228 10:24:28.617489 12900 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I0228 10:24:28.617497 12900 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I0228 10:24:28.617601 12900 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I0228 10:24:28.617611 12900 net.cpp:157] Top shape: 8 512 5 5 (102400)
I0228 10:24:28.617616 12900 net.cpp:157] Top shape: 8 512 5 5 (102400)
I0228 10:24:28.617621 12900 net.cpp:157] Top shape: 8 512 5 5 (102400)
I0228 10:24:28.617626 12900 net.cpp:157] Top shape: 8 512 5 5 (102400)
I0228 10:24:28.617631 12900 net.cpp:165] Memory required for data: 1287196704
I0228 10:24:28.617636 12900 layer_factory.hpp:77] Creating layer conv15_1
I0228 10:24:28.617648 12900 net.cpp:100] Creating Layer conv15_1
I0228 10:24:28.617653 12900 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I0228 10:24:28.617662 12900 net.cpp:408] conv15_1 -> conv15_1
I0228 10:24:28.621527 12900 net.cpp:150] Setting up conv15_1
I0228 10:24:28.621564 12900 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0228 10:24:28.621569 12900 net.cpp:165] Memory required for data: 1287299104
I0228 10:24:28.621578 12900 layer_factory.hpp:77] Creating layer conv15_1/bn
I0228 10:24:28.621587 12900 net.cpp:100] Creating Layer conv15_1/bn
I0228 10:24:28.621593 12900 net.cpp:434] conv15_1/bn <- conv15_1
I0228 10:24:28.621610 12900 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I0228 10:24:28.621908 12900 net.cpp:150] Setting up conv15_1/bn
I0228 10:24:28.621918 12900 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0228 10:24:28.621922 12900 net.cpp:165] Memory required for data: 1287401504
I0228 10:24:28.621932 12900 layer_factory.hpp:77] Creating layer conv15_1/scale
I0228 10:24:28.621943 12900 net.cpp:100] Creating Layer conv15_1/scale
I0228 10:24:28.621948 12900 net.cpp:434] conv15_1/scale <- conv15_1
I0228 10:24:28.621954 12900 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I0228 10:24:28.622014 12900 layer_factory.hpp:77] Creating layer conv15_1/scale
I0228 10:24:28.622172 12900 net.cpp:150] Setting up conv15_1/scale
I0228 10:24:28.622182 12900 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0228 10:24:28.622186 12900 net.cpp:165] Memory required for data: 1287503904
I0228 10:24:28.622195 12900 layer_factory.hpp:77] Creating layer conv15_1/relu
I0228 10:24:28.622202 12900 net.cpp:100] Creating Layer conv15_1/relu
I0228 10:24:28.622208 12900 net.cpp:434] conv15_1/relu <- conv15_1
I0228 10:24:28.622217 12900 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I0228 10:24:28.623432 12900 net.cpp:150] Setting up conv15_1/relu
I0228 10:24:28.623450 12900 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0228 10:24:28.623453 12900 net.cpp:165] Memory required for data: 1287606304
I0228 10:24:28.623458 12900 layer_factory.hpp:77] Creating layer conv15_2
I0228 10:24:28.623487 12900 net.cpp:100] Creating Layer conv15_2
I0228 10:24:28.623495 12900 net.cpp:434] conv15_2 <- conv15_1
I0228 10:24:28.623522 12900 net.cpp:408] conv15_2 -> conv15_2
I0228 10:24:28.630203 12900 net.cpp:150] Setting up conv15_2
I0228 10:24:28.630223 12900 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0228 10:24:28.630228 12900 net.cpp:165] Memory required for data: 1287680032
I0228 10:24:28.630250 12900 layer_factory.hpp:77] Creating layer conv15_2/bn
I0228 10:24:28.630259 12900 net.cpp:100] Creating Layer conv15_2/bn
I0228 10:24:28.630264 12900 net.cpp:434] conv15_2/bn <- conv15_2
I0228 10:24:28.630272 12900 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I0228 10:24:28.630578 12900 net.cpp:150] Setting up conv15_2/bn
I0228 10:24:28.630602 12900 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0228 10:24:28.630621 12900 net.cpp:165] Memory required for data: 1287753760
I0228 10:24:28.630630 12900 layer_factory.hpp:77] Creating layer conv15_2/scale
I0228 10:24:28.630638 12900 net.cpp:100] Creating Layer conv15_2/scale
I0228 10:24:28.630643 12900 net.cpp:434] conv15_2/scale <- conv15_2
I0228 10:24:28.630648 12900 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I0228 10:24:28.630703 12900 layer_factory.hpp:77] Creating layer conv15_2/scale
I0228 10:24:28.630865 12900 net.cpp:150] Setting up conv15_2/scale
I0228 10:24:28.630875 12900 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0228 10:24:28.630879 12900 net.cpp:165] Memory required for data: 1287827488
I0228 10:24:28.630887 12900 layer_factory.hpp:77] Creating layer conv15_2/relu
I0228 10:24:28.630908 12900 net.cpp:100] Creating Layer conv15_2/relu
I0228 10:24:28.630915 12900 net.cpp:434] conv15_2/relu <- conv15_2
I0228 10:24:28.630921 12900 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I0228 10:24:28.631475 12900 net.cpp:150] Setting up conv15_2/relu
I0228 10:24:28.631486 12900 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0228 10:24:28.631506 12900 net.cpp:165] Memory required for data: 1287901216
I0228 10:24:28.631511 12900 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I0228 10:24:28.631521 12900 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I0228 10:24:28.631526 12900 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I0228 10:24:28.631534 12900 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I0228 10:24:28.631543 12900 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I0228 10:24:28.631551 12900 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I0228 10:24:28.631559 12900 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I0228 10:24:28.631665 12900 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I0228 10:24:28.631676 12900 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0228 10:24:28.631700 12900 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0228 10:24:28.631705 12900 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0228 10:24:28.631709 12900 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0228 10:24:28.631714 12900 net.cpp:165] Memory required for data: 1288196128
I0228 10:24:28.631721 12900 layer_factory.hpp:77] Creating layer conv16_1
I0228 10:24:28.631731 12900 net.cpp:100] Creating Layer conv16_1
I0228 10:24:28.631736 12900 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I0228 10:24:28.631744 12900 net.cpp:408] conv16_1 -> conv16_1
I0228 10:24:28.634573 12900 net.cpp:150] Setting up conv16_1
I0228 10:24:28.634590 12900 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0228 10:24:28.634595 12900 net.cpp:165] Memory required for data: 1288232992
I0228 10:24:28.634603 12900 layer_factory.hpp:77] Creating layer conv16_1/bn
I0228 10:24:28.634613 12900 net.cpp:100] Creating Layer conv16_1/bn
I0228 10:24:28.634618 12900 net.cpp:434] conv16_1/bn <- conv16_1
I0228 10:24:28.634625 12900 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I0228 10:24:28.634901 12900 net.cpp:150] Setting up conv16_1/bn
I0228 10:24:28.634912 12900 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0228 10:24:28.634915 12900 net.cpp:165] Memory required for data: 1288269856
I0228 10:24:28.634924 12900 layer_factory.hpp:77] Creating layer conv16_1/scale
I0228 10:24:28.634932 12900 net.cpp:100] Creating Layer conv16_1/scale
I0228 10:24:28.634948 12900 net.cpp:434] conv16_1/scale <- conv16_1
I0228 10:24:28.634956 12900 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I0228 10:24:28.635016 12900 layer_factory.hpp:77] Creating layer conv16_1/scale
I0228 10:24:28.635169 12900 net.cpp:150] Setting up conv16_1/scale
I0228 10:24:28.635180 12900 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0228 10:24:28.635185 12900 net.cpp:165] Memory required for data: 1288306720
I0228 10:24:28.635192 12900 layer_factory.hpp:77] Creating layer conv16_1/relu
I0228 10:24:28.635200 12900 net.cpp:100] Creating Layer conv16_1/relu
I0228 10:24:28.635206 12900 net.cpp:434] conv16_1/relu <- conv16_1
I0228 10:24:28.635211 12900 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I0228 10:24:28.635754 12900 net.cpp:150] Setting up conv16_1/relu
I0228 10:24:28.635767 12900 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0228 10:24:28.635773 12900 net.cpp:165] Memory required for data: 1288343584
I0228 10:24:28.635777 12900 layer_factory.hpp:77] Creating layer conv16_2
I0228 10:24:28.635788 12900 net.cpp:100] Creating Layer conv16_2
I0228 10:24:28.635794 12900 net.cpp:434] conv16_2 <- conv16_1
I0228 10:24:28.635802 12900 net.cpp:408] conv16_2 -> conv16_2
I0228 10:24:28.642238 12900 net.cpp:150] Setting up conv16_2
I0228 10:24:28.642256 12900 net.cpp:157] Top shape: 8 256 2 2 (8192)
I0228 10:24:28.642261 12900 net.cpp:165] Memory required for data: 1288376352
I0228 10:24:28.642268 12900 layer_factory.hpp:77] Creating layer conv16_2/bn
I0228 10:24:28.642278 12900 net.cpp:100] Creating Layer conv16_2/bn
I0228 10:24:28.642283 12900 net.cpp:434] conv16_2/bn <- conv16_2
I0228 10:24:28.642289 12900 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I0228 10:24:28.642568 12900 net.cpp:150] Setting up conv16_2/bn
I0228 10:24:28.642578 12900 net.cpp:157] Top shape: 8 256 2 2 (8192)
I0228 10:24:28.642582 12900 net.cpp:165] Memory required for data: 1288409120
I0228 10:24:28.642590 12900 layer_factory.hpp:77] Creating layer conv16_2/scale
I0228 10:24:28.642601 12900 net.cpp:100] Creating Layer conv16_2/scale
I0228 10:24:28.642606 12900 net.cpp:434] conv16_2/scale <- conv16_2
I0228 10:24:28.642611 12900 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I0228 10:24:28.642664 12900 layer_factory.hpp:77] Creating layer conv16_2/scale
I0228 10:24:28.642812 12900 net.cpp:150] Setting up conv16_2/scale
I0228 10:24:28.642820 12900 net.cpp:157] Top shape: 8 256 2 2 (8192)
I0228 10:24:28.642841 12900 net.cpp:165] Memory required for data: 1288441888
I0228 10:24:28.642849 12900 layer_factory.hpp:77] Creating layer conv16_2/relu
I0228 10:24:28.642858 12900 net.cpp:100] Creating Layer conv16_2/relu
I0228 10:24:28.642880 12900 net.cpp:434] conv16_2/relu <- conv16_2
I0228 10:24:28.642886 12900 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I0228 10:24:28.643441 12900 net.cpp:150] Setting up conv16_2/relu
I0228 10:24:28.643455 12900 net.cpp:157] Top shape: 8 256 2 2 (8192)
I0228 10:24:28.643473 12900 net.cpp:165] Memory required for data: 1288474656
I0228 10:24:28.643478 12900 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I0228 10:24:28.643486 12900 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I0228 10:24:28.643491 12900 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I0228 10:24:28.643499 12900 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I0228 10:24:28.643524 12900 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I0228 10:24:28.643532 12900 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I0228 10:24:28.643541 12900 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I0228 10:24:28.643635 12900 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I0228 10:24:28.643643 12900 net.cpp:157] Top shape: 8 256 2 2 (8192)
I0228 10:24:28.643649 12900 net.cpp:157] Top shape: 8 256 2 2 (8192)
I0228 10:24:28.643656 12900 net.cpp:157] Top shape: 8 256 2 2 (8192)
I0228 10:24:28.643661 12900 net.cpp:157] Top shape: 8 256 2 2 (8192)
I0228 10:24:28.643697 12900 net.cpp:165] Memory required for data: 1288605728
I0228 10:24:28.643702 12900 layer_factory.hpp:77] Creating layer conv17_1
I0228 10:24:28.643713 12900 net.cpp:100] Creating Layer conv17_1
I0228 10:24:28.643719 12900 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I0228 10:24:28.643728 12900 net.cpp:408] conv17_1 -> conv17_1
I0228 10:24:28.646355 12900 net.cpp:150] Setting up conv17_1
I0228 10:24:28.646378 12900 net.cpp:157] Top shape: 8 64 2 2 (2048)
I0228 10:24:28.646384 12900 net.cpp:165] Memory required for data: 1288613920
I0228 10:24:28.646389 12900 layer_factory.hpp:77] Creating layer conv17_1/bn
I0228 10:24:28.646396 12900 net.cpp:100] Creating Layer conv17_1/bn
I0228 10:24:28.646402 12900 net.cpp:434] conv17_1/bn <- conv17_1
I0228 10:24:28.646410 12900 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I0228 10:24:28.646701 12900 net.cpp:150] Setting up conv17_1/bn
I0228 10:24:28.646710 12900 net.cpp:157] Top shape: 8 64 2 2 (2048)
I0228 10:24:28.646716 12900 net.cpp:165] Memory required for data: 1288622112
I0228 10:24:28.646724 12900 layer_factory.hpp:77] Creating layer conv17_1/scale
I0228 10:24:28.646733 12900 net.cpp:100] Creating Layer conv17_1/scale
I0228 10:24:28.646737 12900 net.cpp:434] conv17_1/scale <- conv17_1
I0228 10:24:28.646744 12900 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I0228 10:24:28.646798 12900 layer_factory.hpp:77] Creating layer conv17_1/scale
I0228 10:24:28.646953 12900 net.cpp:150] Setting up conv17_1/scale
I0228 10:24:28.646962 12900 net.cpp:157] Top shape: 8 64 2 2 (2048)
I0228 10:24:28.646966 12900 net.cpp:165] Memory required for data: 1288630304
I0228 10:24:28.646973 12900 layer_factory.hpp:77] Creating layer conv17_1/relu
I0228 10:24:28.646981 12900 net.cpp:100] Creating Layer conv17_1/relu
I0228 10:24:28.646986 12900 net.cpp:434] conv17_1/relu <- conv17_1
I0228 10:24:28.646993 12900 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I0228 10:24:28.648123 12900 net.cpp:150] Setting up conv17_1/relu
I0228 10:24:28.648138 12900 net.cpp:157] Top shape: 8 64 2 2 (2048)
I0228 10:24:28.648156 12900 net.cpp:165] Memory required for data: 1288638496
I0228 10:24:28.648164 12900 layer_factory.hpp:77] Creating layer conv17_2
I0228 10:24:28.648175 12900 net.cpp:100] Creating Layer conv17_2
I0228 10:24:28.648180 12900 net.cpp:434] conv17_2 <- conv17_1
I0228 10:24:28.648188 12900 net.cpp:408] conv17_2 -> conv17_2
I0228 10:24:28.651407 12900 net.cpp:150] Setting up conv17_2
I0228 10:24:28.651422 12900 net.cpp:157] Top shape: 8 128 1 1 (1024)
I0228 10:24:28.651427 12900 net.cpp:165] Memory required for data: 1288642592
I0228 10:24:28.651433 12900 layer_factory.hpp:77] Creating layer conv17_2/bn
I0228 10:24:28.651441 12900 net.cpp:100] Creating Layer conv17_2/bn
I0228 10:24:28.651446 12900 net.cpp:434] conv17_2/bn <- conv17_2
I0228 10:24:28.651454 12900 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I0228 10:24:28.651736 12900 net.cpp:150] Setting up conv17_2/bn
I0228 10:24:28.651746 12900 net.cpp:157] Top shape: 8 128 1 1 (1024)
I0228 10:24:28.651751 12900 net.cpp:165] Memory required for data: 1288646688
I0228 10:24:28.651759 12900 layer_factory.hpp:77] Creating layer conv17_2/scale
I0228 10:24:28.651767 12900 net.cpp:100] Creating Layer conv17_2/scale
I0228 10:24:28.651772 12900 net.cpp:434] conv17_2/scale <- conv17_2
I0228 10:24:28.651779 12900 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I0228 10:24:28.651835 12900 layer_factory.hpp:77] Creating layer conv17_2/scale
I0228 10:24:28.651983 12900 net.cpp:150] Setting up conv17_2/scale
I0228 10:24:28.651993 12900 net.cpp:157] Top shape: 8 128 1 1 (1024)
I0228 10:24:28.651998 12900 net.cpp:165] Memory required for data: 1288650784
I0228 10:24:28.652004 12900 layer_factory.hpp:77] Creating layer conv17_2/relu
I0228 10:24:28.652011 12900 net.cpp:100] Creating Layer conv17_2/relu
I0228 10:24:28.652016 12900 net.cpp:434] conv17_2/relu <- conv17_2
I0228 10:24:28.652024 12900 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I0228 10:24:28.652601 12900 net.cpp:150] Setting up conv17_2/relu
I0228 10:24:28.652626 12900 net.cpp:157] Top shape: 8 128 1 1 (1024)
I0228 10:24:28.652643 12900 net.cpp:165] Memory required for data: 1288654880
I0228 10:24:28.652648 12900 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I0228 10:24:28.652657 12900 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I0228 10:24:28.652662 12900 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I0228 10:24:28.652670 12900 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I0228 10:24:28.652716 12900 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I0228 10:24:28.652725 12900 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I0228 10:24:28.652799 12900 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I0228 10:24:28.652809 12900 net.cpp:157] Top shape: 8 128 1 1 (1024)
I0228 10:24:28.652814 12900 net.cpp:157] Top shape: 8 128 1 1 (1024)
I0228 10:24:28.652819 12900 net.cpp:157] Top shape: 8 128 1 1 (1024)
I0228 10:24:28.652823 12900 net.cpp:165] Memory required for data: 1288667168
I0228 10:24:28.652829 12900 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I0228 10:24:28.652839 12900 net.cpp:100] Creating Layer conv11_mbox_loc
I0228 10:24:28.652844 12900 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I0228 10:24:28.652854 12900 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I0228 10:24:28.655450 12900 net.cpp:150] Setting up conv11_mbox_loc
I0228 10:24:28.655481 12900 net.cpp:157] Top shape: 8 12 19 19 (34656)
I0228 10:24:28.655486 12900 net.cpp:165] Memory required for data: 1288805792
I0228 10:24:28.655495 12900 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I0228 10:24:28.655505 12900 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I0228 10:24:28.655517 12900 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I0228 10:24:28.655524 12900 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I0228 10:24:28.655671 12900 net.cpp:150] Setting up conv11_mbox_loc_perm
I0228 10:24:28.655681 12900 net.cpp:157] Top shape: 8 19 19 12 (34656)
I0228 10:24:28.655686 12900 net.cpp:165] Memory required for data: 1288944416
I0228 10:24:28.655690 12900 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I0228 10:24:28.655699 12900 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I0228 10:24:28.655705 12900 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I0228 10:24:28.655712 12900 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I0228 10:24:28.655747 12900 net.cpp:150] Setting up conv11_mbox_loc_flat
I0228 10:24:28.655755 12900 net.cpp:157] Top shape: 8 4332 (34656)
I0228 10:24:28.655761 12900 net.cpp:165] Memory required for data: 1289083040
I0228 10:24:28.655766 12900 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I0228 10:24:28.655777 12900 net.cpp:100] Creating Layer conv11_mbox_conf_new
I0228 10:24:28.655782 12900 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I0228 10:24:28.655791 12900 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I0228 10:24:28.658455 12900 net.cpp:150] Setting up conv11_mbox_conf_new
I0228 10:24:28.658471 12900 net.cpp:157] Top shape: 8 12 19 19 (34656)
I0228 10:24:28.658476 12900 net.cpp:165] Memory required for data: 1289221664
I0228 10:24:28.658485 12900 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I0228 10:24:28.658496 12900 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I0228 10:24:28.658501 12900 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I0228 10:24:28.658509 12900 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I0228 10:24:28.658665 12900 net.cpp:150] Setting up conv11_mbox_conf_perm
I0228 10:24:28.658674 12900 net.cpp:157] Top shape: 8 19 19 12 (34656)
I0228 10:24:28.658679 12900 net.cpp:165] Memory required for data: 1289360288
I0228 10:24:28.658684 12900 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I0228 10:24:28.658691 12900 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I0228 10:24:28.658695 12900 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I0228 10:24:28.658715 12900 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I0228 10:24:28.658752 12900 net.cpp:150] Setting up conv11_mbox_conf_flat
I0228 10:24:28.658761 12900 net.cpp:157] Top shape: 8 4332 (34656)
I0228 10:24:28.658766 12900 net.cpp:165] Memory required for data: 1289498912
I0228 10:24:28.658771 12900 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I0228 10:24:28.658782 12900 net.cpp:100] Creating Layer conv11_mbox_priorbox
I0228 10:24:28.658787 12900 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I0228 10:24:28.658793 12900 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I0228 10:24:28.658800 12900 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I0228 10:24:28.658838 12900 net.cpp:150] Setting up conv11_mbox_priorbox
I0228 10:24:28.658848 12900 net.cpp:157] Top shape: 1 2 4332 (8664)
I0228 10:24:28.658851 12900 net.cpp:165] Memory required for data: 1289533568
I0228 10:24:28.658855 12900 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I0228 10:24:28.658866 12900 net.cpp:100] Creating Layer conv13_mbox_loc
I0228 10:24:28.658872 12900 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I0228 10:24:28.658880 12900 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I0228 10:24:28.662463 12900 net.cpp:150] Setting up conv13_mbox_loc
I0228 10:24:28.662479 12900 net.cpp:157] Top shape: 8 24 10 10 (19200)
I0228 10:24:28.662485 12900 net.cpp:165] Memory required for data: 1289610368
I0228 10:24:28.662492 12900 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I0228 10:24:28.662502 12900 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I0228 10:24:28.662506 12900 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I0228 10:24:28.662516 12900 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I0228 10:24:28.662681 12900 net.cpp:150] Setting up conv13_mbox_loc_perm
I0228 10:24:28.662691 12900 net.cpp:157] Top shape: 8 10 10 24 (19200)
I0228 10:24:28.662695 12900 net.cpp:165] Memory required for data: 1289687168
I0228 10:24:28.662701 12900 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I0228 10:24:28.662710 12900 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I0228 10:24:28.662715 12900 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I0228 10:24:28.662721 12900 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I0228 10:24:28.662755 12900 net.cpp:150] Setting up conv13_mbox_loc_flat
I0228 10:24:28.662762 12900 net.cpp:157] Top shape: 8 2400 (19200)
I0228 10:24:28.662766 12900 net.cpp:165] Memory required for data: 1289763968
I0228 10:24:28.662770 12900 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I0228 10:24:28.662783 12900 net.cpp:100] Creating Layer conv13_mbox_conf_new
I0228 10:24:28.662788 12900 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I0228 10:24:28.662796 12900 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I0228 10:24:28.665654 12900 net.cpp:150] Setting up conv13_mbox_conf_new
I0228 10:24:28.665671 12900 net.cpp:157] Top shape: 8 24 10 10 (19200)
I0228 10:24:28.665675 12900 net.cpp:165] Memory required for data: 1289840768
I0228 10:24:28.665683 12900 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I0228 10:24:28.665693 12900 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I0228 10:24:28.665700 12900 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I0228 10:24:28.665707 12900 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I0228 10:24:28.665866 12900 net.cpp:150] Setting up conv13_mbox_conf_perm
I0228 10:24:28.665875 12900 net.cpp:157] Top shape: 8 10 10 24 (19200)
I0228 10:24:28.665880 12900 net.cpp:165] Memory required for data: 1289917568
I0228 10:24:28.665884 12900 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I0228 10:24:28.665894 12900 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I0228 10:24:28.665899 12900 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I0228 10:24:28.665906 12900 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I0228 10:24:28.665953 12900 net.cpp:150] Setting up conv13_mbox_conf_flat
I0228 10:24:28.665962 12900 net.cpp:157] Top shape: 8 2400 (19200)
I0228 10:24:28.665966 12900 net.cpp:165] Memory required for data: 1289994368
I0228 10:24:28.665971 12900 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I0228 10:24:28.665982 12900 net.cpp:100] Creating Layer conv13_mbox_priorbox
I0228 10:24:28.665987 12900 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I0228 10:24:28.665993 12900 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I0228 10:24:28.666000 12900 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I0228 10:24:28.666038 12900 net.cpp:150] Setting up conv13_mbox_priorbox
I0228 10:24:28.666046 12900 net.cpp:157] Top shape: 1 2 2400 (4800)
I0228 10:24:28.666050 12900 net.cpp:165] Memory required for data: 1290013568
I0228 10:24:28.666056 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I0228 10:24:28.666067 12900 net.cpp:100] Creating Layer conv14_2_mbox_loc
I0228 10:24:28.666072 12900 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I0228 10:24:28.666081 12900 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I0228 10:24:28.668764 12900 net.cpp:150] Setting up conv14_2_mbox_loc
I0228 10:24:28.668781 12900 net.cpp:157] Top shape: 8 24 5 5 (4800)
I0228 10:24:28.668800 12900 net.cpp:165] Memory required for data: 1290032768
I0228 10:24:28.668809 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I0228 10:24:28.668835 12900 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I0228 10:24:28.668841 12900 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I0228 10:24:28.668849 12900 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I0228 10:24:28.668992 12900 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I0228 10:24:28.669003 12900 net.cpp:157] Top shape: 8 5 5 24 (4800)
I0228 10:24:28.669008 12900 net.cpp:165] Memory required for data: 1290051968
I0228 10:24:28.669011 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I0228 10:24:28.669018 12900 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I0228 10:24:28.669024 12900 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I0228 10:24:28.669030 12900 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I0228 10:24:28.669080 12900 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I0228 10:24:28.669103 12900 net.cpp:157] Top shape: 8 600 (4800)
I0228 10:24:28.669109 12900 net.cpp:165] Memory required for data: 1290071168
I0228 10:24:28.669113 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I0228 10:24:28.669124 12900 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I0228 10:24:28.669131 12900 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I0228 10:24:28.669142 12900 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I0228 10:24:28.671844 12900 net.cpp:150] Setting up conv14_2_mbox_conf_new
I0228 10:24:28.671861 12900 net.cpp:157] Top shape: 8 24 5 5 (4800)
I0228 10:24:28.671865 12900 net.cpp:165] Memory required for data: 1290090368
I0228 10:24:28.671875 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I0228 10:24:28.671885 12900 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I0228 10:24:28.671890 12900 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I0228 10:24:28.671910 12900 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I0228 10:24:28.672057 12900 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I0228 10:24:28.672068 12900 net.cpp:157] Top shape: 8 5 5 24 (4800)
I0228 10:24:28.672073 12900 net.cpp:165] Memory required for data: 1290109568
I0228 10:24:28.672077 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I0228 10:24:28.672086 12900 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I0228 10:24:28.672091 12900 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I0228 10:24:28.672099 12900 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I0228 10:24:28.672132 12900 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I0228 10:24:28.672154 12900 net.cpp:157] Top shape: 8 600 (4800)
I0228 10:24:28.672159 12900 net.cpp:165] Memory required for data: 1290128768
I0228 10:24:28.672164 12900 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I0228 10:24:28.672173 12900 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I0228 10:24:28.672178 12900 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I0228 10:24:28.672184 12900 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I0228 10:24:28.672194 12900 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I0228 10:24:28.672231 12900 net.cpp:150] Setting up conv14_2_mbox_priorbox
I0228 10:24:28.672242 12900 net.cpp:157] Top shape: 1 2 600 (1200)
I0228 10:24:28.672247 12900 net.cpp:165] Memory required for data: 1290133568
I0228 10:24:28.672251 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I0228 10:24:28.672264 12900 net.cpp:100] Creating Layer conv15_2_mbox_loc
I0228 10:24:28.672271 12900 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I0228 10:24:28.672277 12900 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I0228 10:24:28.674980 12900 net.cpp:150] Setting up conv15_2_mbox_loc
I0228 10:24:28.674996 12900 net.cpp:157] Top shape: 8 24 3 3 (1728)
I0228 10:24:28.675001 12900 net.cpp:165] Memory required for data: 1290140480
I0228 10:24:28.675009 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I0228 10:24:28.675034 12900 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I0228 10:24:28.675043 12900 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I0228 10:24:28.675052 12900 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I0228 10:24:28.675199 12900 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I0228 10:24:28.675209 12900 net.cpp:157] Top shape: 8 3 3 24 (1728)
I0228 10:24:28.675212 12900 net.cpp:165] Memory required for data: 1290147392
I0228 10:24:28.675217 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I0228 10:24:28.675225 12900 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I0228 10:24:28.675230 12900 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I0228 10:24:28.675237 12900 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I0228 10:24:28.675272 12900 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I0228 10:24:28.675282 12900 net.cpp:157] Top shape: 8 216 (1728)
I0228 10:24:28.675285 12900 net.cpp:165] Memory required for data: 1290154304
I0228 10:24:28.675289 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I0228 10:24:28.675302 12900 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I0228 10:24:28.675307 12900 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I0228 10:24:28.675315 12900 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I0228 10:24:28.677963 12900 net.cpp:150] Setting up conv15_2_mbox_conf_new
I0228 10:24:28.677978 12900 net.cpp:157] Top shape: 8 24 3 3 (1728)
I0228 10:24:28.677983 12900 net.cpp:165] Memory required for data: 1290161216
I0228 10:24:28.677990 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I0228 10:24:28.677999 12900 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I0228 10:24:28.678006 12900 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I0228 10:24:28.678012 12900 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I0228 10:24:28.678172 12900 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I0228 10:24:28.678181 12900 net.cpp:157] Top shape: 8 3 3 24 (1728)
I0228 10:24:28.678186 12900 net.cpp:165] Memory required for data: 1290168128
I0228 10:24:28.678191 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I0228 10:24:28.678198 12900 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I0228 10:24:28.678202 12900 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I0228 10:24:28.678212 12900 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I0228 10:24:28.678246 12900 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I0228 10:24:28.678253 12900 net.cpp:157] Top shape: 8 216 (1728)
I0228 10:24:28.678268 12900 net.cpp:165] Memory required for data: 1290175040
I0228 10:24:28.678274 12900 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I0228 10:24:28.678283 12900 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I0228 10:24:28.678288 12900 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I0228 10:24:28.678294 12900 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I0228 10:24:28.678304 12900 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I0228 10:24:28.678342 12900 net.cpp:150] Setting up conv15_2_mbox_priorbox
I0228 10:24:28.678351 12900 net.cpp:157] Top shape: 1 2 216 (432)
I0228 10:24:28.678355 12900 net.cpp:165] Memory required for data: 1290176768
I0228 10:24:28.678360 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I0228 10:24:28.678371 12900 net.cpp:100] Creating Layer conv16_2_mbox_loc
I0228 10:24:28.678377 12900 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I0228 10:24:28.678385 12900 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I0228 10:24:28.681107 12900 net.cpp:150] Setting up conv16_2_mbox_loc
I0228 10:24:28.681123 12900 net.cpp:157] Top shape: 8 24 2 2 (768)
I0228 10:24:28.681143 12900 net.cpp:165] Memory required for data: 1290179840
I0228 10:24:28.681162 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I0228 10:24:28.681174 12900 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I0228 10:24:28.681179 12900 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I0228 10:24:28.681186 12900 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I0228 10:24:28.681360 12900 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I0228 10:24:28.681390 12900 net.cpp:157] Top shape: 8 2 2 24 (768)
I0228 10:24:28.681394 12900 net.cpp:165] Memory required for data: 1290182912
I0228 10:24:28.681401 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I0228 10:24:28.681409 12900 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I0228 10:24:28.681416 12900 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I0228 10:24:28.681422 12900 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I0228 10:24:28.681460 12900 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I0228 10:24:28.681470 12900 net.cpp:157] Top shape: 8 96 (768)
I0228 10:24:28.681476 12900 net.cpp:165] Memory required for data: 1290185984
I0228 10:24:28.681480 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I0228 10:24:28.681493 12900 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I0228 10:24:28.681497 12900 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I0228 10:24:28.681509 12900 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I0228 10:24:28.684392 12900 net.cpp:150] Setting up conv16_2_mbox_conf_new
I0228 10:24:28.684408 12900 net.cpp:157] Top shape: 8 24 2 2 (768)
I0228 10:24:28.684428 12900 net.cpp:165] Memory required for data: 1290189056
I0228 10:24:28.684442 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I0228 10:24:28.684453 12900 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I0228 10:24:28.684458 12900 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I0228 10:24:28.684466 12900 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I0228 10:24:28.684614 12900 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I0228 10:24:28.684623 12900 net.cpp:157] Top shape: 8 2 2 24 (768)
I0228 10:24:28.684628 12900 net.cpp:165] Memory required for data: 1290192128
I0228 10:24:28.684631 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I0228 10:24:28.684641 12900 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I0228 10:24:28.684646 12900 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I0228 10:24:28.684653 12900 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I0228 10:24:28.684689 12900 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I0228 10:24:28.684697 12900 net.cpp:157] Top shape: 8 96 (768)
I0228 10:24:28.684701 12900 net.cpp:165] Memory required for data: 1290195200
I0228 10:24:28.684716 12900 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I0228 10:24:28.684726 12900 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I0228 10:24:28.684733 12900 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I0228 10:24:28.684741 12900 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I0228 10:24:28.684747 12900 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I0228 10:24:28.684787 12900 net.cpp:150] Setting up conv16_2_mbox_priorbox
I0228 10:24:28.684797 12900 net.cpp:157] Top shape: 1 2 96 (192)
I0228 10:24:28.684800 12900 net.cpp:165] Memory required for data: 1290195968
I0228 10:24:28.684804 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I0228 10:24:28.684816 12900 net.cpp:100] Creating Layer conv17_2_mbox_loc
I0228 10:24:28.684826 12900 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I0228 10:24:28.684834 12900 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I0228 10:24:28.687640 12900 net.cpp:150] Setting up conv17_2_mbox_loc
I0228 10:24:28.687656 12900 net.cpp:157] Top shape: 8 24 1 1 (192)
I0228 10:24:28.687661 12900 net.cpp:165] Memory required for data: 1290196736
I0228 10:24:28.687669 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I0228 10:24:28.687680 12900 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I0228 10:24:28.687685 12900 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I0228 10:24:28.687695 12900 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I0228 10:24:28.687878 12900 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I0228 10:24:28.687888 12900 net.cpp:157] Top shape: 8 1 1 24 (192)
I0228 10:24:28.687892 12900 net.cpp:165] Memory required for data: 1290197504
I0228 10:24:28.687898 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I0228 10:24:28.687906 12900 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I0228 10:24:28.687911 12900 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I0228 10:24:28.687921 12900 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I0228 10:24:28.687955 12900 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I0228 10:24:28.687963 12900 net.cpp:157] Top shape: 8 24 (192)
I0228 10:24:28.687968 12900 net.cpp:165] Memory required for data: 1290198272
I0228 10:24:28.687973 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I0228 10:24:28.687986 12900 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I0228 10:24:28.687991 12900 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I0228 10:24:28.687999 12900 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I0228 10:24:28.690594 12900 net.cpp:150] Setting up conv17_2_mbox_conf_new
I0228 10:24:28.690614 12900 net.cpp:157] Top shape: 8 24 1 1 (192)
I0228 10:24:28.690619 12900 net.cpp:165] Memory required for data: 1290199040
I0228 10:24:28.690627 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I0228 10:24:28.690635 12900 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I0228 10:24:28.690641 12900 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I0228 10:24:28.690650 12900 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I0228 10:24:28.690814 12900 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I0228 10:24:28.690824 12900 net.cpp:157] Top shape: 8 1 1 24 (192)
I0228 10:24:28.690829 12900 net.cpp:165] Memory required for data: 1290199808
I0228 10:24:28.690850 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I0228 10:24:28.690858 12900 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I0228 10:24:28.690863 12900 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I0228 10:24:28.690872 12900 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I0228 10:24:28.690907 12900 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I0228 10:24:28.690915 12900 net.cpp:157] Top shape: 8 24 (192)
I0228 10:24:28.690919 12900 net.cpp:165] Memory required for data: 1290200576
I0228 10:24:28.690937 12900 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I0228 10:24:28.690949 12900 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I0228 10:24:28.690955 12900 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I0228 10:24:28.690961 12900 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I0228 10:24:28.690971 12900 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I0228 10:24:28.691010 12900 net.cpp:150] Setting up conv17_2_mbox_priorbox
I0228 10:24:28.691020 12900 net.cpp:157] Top shape: 1 2 24 (48)
I0228 10:24:28.691025 12900 net.cpp:165] Memory required for data: 1290200768
I0228 10:24:28.691030 12900 layer_factory.hpp:77] Creating layer mbox_loc
I0228 10:24:28.691040 12900 net.cpp:100] Creating Layer mbox_loc
I0228 10:24:28.691046 12900 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I0228 10:24:28.691052 12900 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I0228 10:24:28.691061 12900 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I0228 10:24:28.691066 12900 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I0228 10:24:28.691071 12900 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I0228 10:24:28.691076 12900 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I0228 10:24:28.691085 12900 net.cpp:408] mbox_loc -> mbox_loc
I0228 10:24:28.691121 12900 net.cpp:150] Setting up mbox_loc
I0228 10:24:28.691130 12900 net.cpp:157] Top shape: 8 7668 (61344)
I0228 10:24:28.691134 12900 net.cpp:165] Memory required for data: 1290446144
I0228 10:24:28.691140 12900 layer_factory.hpp:77] Creating layer mbox_conf
I0228 10:24:28.691148 12900 net.cpp:100] Creating Layer mbox_conf
I0228 10:24:28.691154 12900 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I0228 10:24:28.691160 12900 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I0228 10:24:28.691167 12900 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I0228 10:24:28.691174 12900 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I0228 10:24:28.691179 12900 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I0228 10:24:28.691184 12900 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I0228 10:24:28.691191 12900 net.cpp:408] mbox_conf -> mbox_conf
I0228 10:24:28.691224 12900 net.cpp:150] Setting up mbox_conf
I0228 10:24:28.691232 12900 net.cpp:157] Top shape: 8 7668 (61344)
I0228 10:24:28.691236 12900 net.cpp:165] Memory required for data: 1290691520
I0228 10:24:28.691242 12900 layer_factory.hpp:77] Creating layer mbox_priorbox
I0228 10:24:28.691251 12900 net.cpp:100] Creating Layer mbox_priorbox
I0228 10:24:28.691256 12900 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I0228 10:24:28.691262 12900 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I0228 10:24:28.691267 12900 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I0228 10:24:28.691273 12900 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I0228 10:24:28.691278 12900 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I0228 10:24:28.691283 12900 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I0228 10:24:28.691290 12900 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0228 10:24:28.691340 12900 net.cpp:150] Setting up mbox_priorbox
I0228 10:24:28.691349 12900 net.cpp:157] Top shape: 1 2 7668 (15336)
I0228 10:24:28.691354 12900 net.cpp:165] Memory required for data: 1290752864
I0228 10:24:28.691359 12900 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0228 10:24:28.691367 12900 net.cpp:100] Creating Layer mbox_conf_reshape
I0228 10:24:28.691372 12900 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0228 10:24:28.691380 12900 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0228 10:24:28.691424 12900 net.cpp:150] Setting up mbox_conf_reshape
I0228 10:24:28.691433 12900 net.cpp:157] Top shape: 8 1917 4 (61344)
I0228 10:24:28.691437 12900 net.cpp:165] Memory required for data: 1290998240
I0228 10:24:28.691442 12900 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0228 10:24:28.691452 12900 net.cpp:100] Creating Layer mbox_conf_softmax
I0228 10:24:28.691457 12900 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0228 10:24:28.691476 12900 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0228 10:24:28.692132 12900 net.cpp:150] Setting up mbox_conf_softmax
I0228 10:24:28.692147 12900 net.cpp:157] Top shape: 8 1917 4 (61344)
I0228 10:24:28.692152 12900 net.cpp:165] Memory required for data: 1291243616
I0228 10:24:28.692157 12900 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0228 10:24:28.692165 12900 net.cpp:100] Creating Layer mbox_conf_flatten
I0228 10:24:28.692173 12900 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0228 10:24:28.692180 12900 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0228 10:24:28.692220 12900 net.cpp:150] Setting up mbox_conf_flatten
I0228 10:24:28.692230 12900 net.cpp:157] Top shape: 8 7668 (61344)
I0228 10:24:28.692236 12900 net.cpp:165] Memory required for data: 1291488992
I0228 10:24:28.692241 12900 layer_factory.hpp:77] Creating layer detection_out
I0228 10:24:28.692253 12900 net.cpp:100] Creating Layer detection_out
I0228 10:24:28.692258 12900 net.cpp:434] detection_out <- mbox_loc
I0228 10:24:28.692266 12900 net.cpp:434] detection_out <- mbox_conf_flatten
I0228 10:24:28.692271 12900 net.cpp:434] detection_out <- mbox_priorbox
I0228 10:24:28.692281 12900 net.cpp:408] detection_out -> detection_out
I0228 10:24:28.692396 12900 net.cpp:150] Setting up detection_out
I0228 10:24:28.692409 12900 net.cpp:157] Top shape: 1 1 1 7 (7)
I0228 10:24:28.692414 12900 net.cpp:165] Memory required for data: 1291489020
I0228 10:24:28.692418 12900 layer_factory.hpp:77] Creating layer detection_eval
I0228 10:24:28.692428 12900 net.cpp:100] Creating Layer detection_eval
I0228 10:24:28.692435 12900 net.cpp:434] detection_eval <- detection_out
I0228 10:24:28.692440 12900 net.cpp:434] detection_eval <- label
I0228 10:24:28.692448 12900 net.cpp:408] detection_eval -> detection_eval
I0228 10:24:28.692524 12900 net.cpp:150] Setting up detection_eval
I0228 10:24:28.692534 12900 net.cpp:157] Top shape: 1 1 4 5 (20)
I0228 10:24:28.692538 12900 net.cpp:165] Memory required for data: 1291489100
I0228 10:24:28.692543 12900 net.cpp:228] detection_eval does not need backward computation.
I0228 10:24:28.692548 12900 net.cpp:228] detection_out does not need backward computation.
I0228 10:24:28.692555 12900 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0228 10:24:28.692560 12900 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0228 10:24:28.692566 12900 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0228 10:24:28.692570 12900 net.cpp:228] mbox_priorbox does not need backward computation.
I0228 10:24:28.692581 12900 net.cpp:228] mbox_conf does not need backward computation.
I0228 10:24:28.692589 12900 net.cpp:228] mbox_loc does not need backward computation.
I0228 10:24:28.692596 12900 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I0228 10:24:28.692603 12900 net.cpp:228] conv17_2_mbox_conf_flat does not need backward computation.
I0228 10:24:28.692610 12900 net.cpp:228] conv17_2_mbox_conf_perm does not need backward computation.
I0228 10:24:28.692615 12900 net.cpp:228] conv17_2_mbox_conf_new does not need backward computation.
I0228 10:24:28.692620 12900 net.cpp:228] conv17_2_mbox_loc_flat does not need backward computation.
I0228 10:24:28.692625 12900 net.cpp:228] conv17_2_mbox_loc_perm does not need backward computation.
I0228 10:24:28.692631 12900 net.cpp:228] conv17_2_mbox_loc does not need backward computation.
I0228 10:24:28.692636 12900 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I0228 10:24:28.692642 12900 net.cpp:228] conv16_2_mbox_conf_flat does not need backward computation.
I0228 10:24:28.692647 12900 net.cpp:228] conv16_2_mbox_conf_perm does not need backward computation.
I0228 10:24:28.692653 12900 net.cpp:228] conv16_2_mbox_conf_new does not need backward computation.
I0228 10:24:28.692658 12900 net.cpp:228] conv16_2_mbox_loc_flat does not need backward computation.
I0228 10:24:28.692663 12900 net.cpp:228] conv16_2_mbox_loc_perm does not need backward computation.
I0228 10:24:28.692669 12900 net.cpp:228] conv16_2_mbox_loc does not need backward computation.
I0228 10:24:28.692685 12900 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I0228 10:24:28.692692 12900 net.cpp:228] conv15_2_mbox_conf_flat does not need backward computation.
I0228 10:24:28.692698 12900 net.cpp:228] conv15_2_mbox_conf_perm does not need backward computation.
I0228 10:24:28.692703 12900 net.cpp:228] conv15_2_mbox_conf_new does not need backward computation.
I0228 10:24:28.692710 12900 net.cpp:228] conv15_2_mbox_loc_flat does not need backward computation.
I0228 10:24:28.692715 12900 net.cpp:228] conv15_2_mbox_loc_perm does not need backward computation.
I0228 10:24:28.692720 12900 net.cpp:228] conv15_2_mbox_loc does not need backward computation.
I0228 10:24:28.692726 12900 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I0228 10:24:28.692733 12900 net.cpp:228] conv14_2_mbox_conf_flat does not need backward computation.
I0228 10:24:28.692739 12900 net.cpp:228] conv14_2_mbox_conf_perm does not need backward computation.
I0228 10:24:28.692744 12900 net.cpp:228] conv14_2_mbox_conf_new does not need backward computation.
I0228 10:24:28.692749 12900 net.cpp:228] conv14_2_mbox_loc_flat does not need backward computation.
I0228 10:24:28.692754 12900 net.cpp:228] conv14_2_mbox_loc_perm does not need backward computation.
I0228 10:24:28.692760 12900 net.cpp:228] conv14_2_mbox_loc does not need backward computation.
I0228 10:24:28.692765 12900 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I0228 10:24:28.692771 12900 net.cpp:228] conv13_mbox_conf_flat does not need backward computation.
I0228 10:24:28.692778 12900 net.cpp:228] conv13_mbox_conf_perm does not need backward computation.
I0228 10:24:28.692785 12900 net.cpp:228] conv13_mbox_conf_new does not need backward computation.
I0228 10:24:28.692790 12900 net.cpp:228] conv13_mbox_loc_flat does not need backward computation.
I0228 10:24:28.692795 12900 net.cpp:228] conv13_mbox_loc_perm does not need backward computation.
I0228 10:24:28.692801 12900 net.cpp:228] conv13_mbox_loc does not need backward computation.
I0228 10:24:28.692807 12900 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I0228 10:24:28.692813 12900 net.cpp:228] conv11_mbox_conf_flat does not need backward computation.
I0228 10:24:28.692818 12900 net.cpp:228] conv11_mbox_conf_perm does not need backward computation.
I0228 10:24:28.692826 12900 net.cpp:228] conv11_mbox_conf_new does not need backward computation.
I0228 10:24:28.692831 12900 net.cpp:228] conv11_mbox_loc_flat does not need backward computation.
I0228 10:24:28.692836 12900 net.cpp:228] conv11_mbox_loc_perm does not need backward computation.
I0228 10:24:28.692842 12900 net.cpp:228] conv11_mbox_loc does not need backward computation.
I0228 10:24:28.692848 12900 net.cpp:228] conv17_2_conv17_2/relu_0_split does not need backward computation.
I0228 10:24:28.692853 12900 net.cpp:228] conv17_2/relu does not need backward computation.
I0228 10:24:28.692859 12900 net.cpp:228] conv17_2/scale does not need backward computation.
I0228 10:24:28.692864 12900 net.cpp:228] conv17_2/bn does not need backward computation.
I0228 10:24:28.692870 12900 net.cpp:228] conv17_2 does not need backward computation.
I0228 10:24:28.692875 12900 net.cpp:228] conv17_1/relu does not need backward computation.
I0228 10:24:28.692880 12900 net.cpp:228] conv17_1/scale does not need backward computation.
I0228 10:24:28.692885 12900 net.cpp:228] conv17_1/bn does not need backward computation.
I0228 10:24:28.692890 12900 net.cpp:228] conv17_1 does not need backward computation.
I0228 10:24:28.692896 12900 net.cpp:228] conv16_2_conv16_2/relu_0_split does not need backward computation.
I0228 10:24:28.692903 12900 net.cpp:228] conv16_2/relu does not need backward computation.
I0228 10:24:28.692908 12900 net.cpp:228] conv16_2/scale does not need backward computation.
I0228 10:24:28.692912 12900 net.cpp:228] conv16_2/bn does not need backward computation.
I0228 10:24:28.692919 12900 net.cpp:228] conv16_2 does not need backward computation.
I0228 10:24:28.692945 12900 net.cpp:228] conv16_1/relu does not need backward computation.
I0228 10:24:28.692951 12900 net.cpp:228] conv16_1/scale does not need backward computation.
I0228 10:24:28.692958 12900 net.cpp:228] conv16_1/bn does not need backward computation.
I0228 10:24:28.692965 12900 net.cpp:228] conv16_1 does not need backward computation.
I0228 10:24:28.692970 12900 net.cpp:228] conv15_2_conv15_2/relu_0_split does not need backward computation.
I0228 10:24:28.692975 12900 net.cpp:228] conv15_2/relu does not need backward computation.
I0228 10:24:28.692981 12900 net.cpp:228] conv15_2/scale does not need backward computation.
I0228 10:24:28.692986 12900 net.cpp:228] conv15_2/bn does not need backward computation.
I0228 10:24:28.692992 12900 net.cpp:228] conv15_2 does not need backward computation.
I0228 10:24:28.692997 12900 net.cpp:228] conv15_1/relu does not need backward computation.
I0228 10:24:28.693003 12900 net.cpp:228] conv15_1/scale does not need backward computation.
I0228 10:24:28.693008 12900 net.cpp:228] conv15_1/bn does not need backward computation.
I0228 10:24:28.693013 12900 net.cpp:228] conv15_1 does not need backward computation.
I0228 10:24:28.693019 12900 net.cpp:228] conv14_2_conv14_2/relu_0_split does not need backward computation.
I0228 10:24:28.693027 12900 net.cpp:228] conv14_2/relu does not need backward computation.
I0228 10:24:28.693032 12900 net.cpp:228] conv14_2/scale does not need backward computation.
I0228 10:24:28.693037 12900 net.cpp:228] conv14_2/bn does not need backward computation.
I0228 10:24:28.693042 12900 net.cpp:228] conv14_2 does not need backward computation.
I0228 10:24:28.693048 12900 net.cpp:228] conv14_1/relu does not need backward computation.
I0228 10:24:28.693053 12900 net.cpp:228] conv14_1/scale does not need backward computation.
I0228 10:24:28.693058 12900 net.cpp:228] conv14_1/bn does not need backward computation.
I0228 10:24:28.693063 12900 net.cpp:228] conv14_1 does not need backward computation.
I0228 10:24:28.693070 12900 net.cpp:228] conv13_conv13/relu_0_split does not need backward computation.
I0228 10:24:28.693076 12900 net.cpp:228] conv13/relu does not need backward computation.
I0228 10:24:28.693081 12900 net.cpp:228] conv13/scale does not need backward computation.
I0228 10:24:28.693086 12900 net.cpp:228] conv13/bn does not need backward computation.
I0228 10:24:28.693092 12900 net.cpp:228] conv13 does not need backward computation.
I0228 10:24:28.693099 12900 net.cpp:228] conv13/dw/relu does not need backward computation.
I0228 10:24:28.693104 12900 net.cpp:228] conv13/dw/scale does not need backward computation.
I0228 10:24:28.693109 12900 net.cpp:228] conv13/dw/bn does not need backward computation.
I0228 10:24:28.693114 12900 net.cpp:228] conv13/dw does not need backward computation.
I0228 10:24:28.693120 12900 net.cpp:228] conv12/relu does not need backward computation.
I0228 10:24:28.693125 12900 net.cpp:228] conv12/scale does not need backward computation.
I0228 10:24:28.693130 12900 net.cpp:228] conv12/bn does not need backward computation.
I0228 10:24:28.693136 12900 net.cpp:228] conv12 does not need backward computation.
I0228 10:24:28.693141 12900 net.cpp:228] conv12/dw/relu does not need backward computation.
I0228 10:24:28.693152 12900 net.cpp:228] conv12/dw/scale does not need backward computation.
I0228 10:24:28.693157 12900 net.cpp:228] conv12/dw/bn does not need backward computation.
I0228 10:24:28.693163 12900 net.cpp:228] conv12/dw does not need backward computation.
I0228 10:24:28.693169 12900 net.cpp:228] conv11_conv11/relu_0_split does not need backward computation.
I0228 10:24:28.693176 12900 net.cpp:228] conv11/relu does not need backward computation.
I0228 10:24:28.693181 12900 net.cpp:228] conv11/scale does not need backward computation.
I0228 10:24:28.693186 12900 net.cpp:228] conv11/bn does not need backward computation.
I0228 10:24:28.693192 12900 net.cpp:228] conv11 does not need backward computation.
I0228 10:24:28.693197 12900 net.cpp:228] conv11/dw/relu does not need backward computation.
I0228 10:24:28.693207 12900 net.cpp:228] conv11/dw/scale does not need backward computation.
I0228 10:24:28.693213 12900 net.cpp:228] conv11/dw/bn does not need backward computation.
I0228 10:24:28.693218 12900 net.cpp:228] conv11/dw does not need backward computation.
I0228 10:24:28.693224 12900 net.cpp:228] conv10/relu does not need backward computation.
I0228 10:24:28.693228 12900 net.cpp:228] conv10/scale does not need backward computation.
I0228 10:24:28.693235 12900 net.cpp:228] conv10/bn does not need backward computation.
I0228 10:24:28.693239 12900 net.cpp:228] conv10 does not need backward computation.
I0228 10:24:28.693244 12900 net.cpp:228] conv10/dw/relu does not need backward computation.
I0228 10:24:28.693249 12900 net.cpp:228] conv10/dw/scale does not need backward computation.
I0228 10:24:28.693256 12900 net.cpp:228] conv10/dw/bn does not need backward computation.
I0228 10:24:28.693261 12900 net.cpp:228] conv10/dw does not need backward computation.
I0228 10:24:28.693267 12900 net.cpp:228] conv9/relu does not need backward computation.
I0228 10:24:28.693272 12900 net.cpp:228] conv9/scale does not need backward computation.
I0228 10:24:28.693279 12900 net.cpp:228] conv9/bn does not need backward computation.
I0228 10:24:28.693284 12900 net.cpp:228] conv9 does not need backward computation.
I0228 10:24:28.693290 12900 net.cpp:228] conv9/dw/relu does not need backward computation.
I0228 10:24:28.693295 12900 net.cpp:228] conv9/dw/scale does not need backward computation.
I0228 10:24:28.693301 12900 net.cpp:228] conv9/dw/bn does not need backward computation.
I0228 10:24:28.693307 12900 net.cpp:228] conv9/dw does not need backward computation.
I0228 10:24:28.693312 12900 net.cpp:228] conv8/relu does not need backward computation.
I0228 10:24:28.693317 12900 net.cpp:228] conv8/scale does not need backward computation.
I0228 10:24:28.693323 12900 net.cpp:228] conv8/bn does not need backward computation.
I0228 10:24:28.693328 12900 net.cpp:228] conv8 does not need backward computation.
I0228 10:24:28.693334 12900 net.cpp:228] conv8/dw/relu does not need backward computation.
I0228 10:24:28.693339 12900 net.cpp:228] conv8/dw/scale does not need backward computation.
I0228 10:24:28.693344 12900 net.cpp:228] conv8/dw/bn does not need backward computation.
I0228 10:24:28.693349 12900 net.cpp:228] conv8/dw does not need backward computation.
I0228 10:24:28.693354 12900 net.cpp:228] conv7/relu does not need backward computation.
I0228 10:24:28.693359 12900 net.cpp:228] conv7/scale does not need backward computation.
I0228 10:24:28.693365 12900 net.cpp:228] conv7/bn does not need backward computation.
I0228 10:24:28.693369 12900 net.cpp:228] conv7 does not need backward computation.
I0228 10:24:28.693375 12900 net.cpp:228] conv7/dw/relu does not need backward computation.
I0228 10:24:28.693379 12900 net.cpp:228] conv7/dw/scale does not need backward computation.
I0228 10:24:28.693385 12900 net.cpp:228] conv7/dw/bn does not need backward computation.
I0228 10:24:28.693389 12900 net.cpp:228] conv7/dw does not need backward computation.
I0228 10:24:28.693394 12900 net.cpp:228] conv6/relu does not need backward computation.
I0228 10:24:28.693398 12900 net.cpp:228] conv6/scale does not need backward computation.
I0228 10:24:28.693404 12900 net.cpp:228] conv6/bn does not need backward computation.
I0228 10:24:28.693409 12900 net.cpp:228] conv6 does not need backward computation.
I0228 10:24:28.693414 12900 net.cpp:228] conv6/dw/relu does not need backward computation.
I0228 10:24:28.693418 12900 net.cpp:228] conv6/dw/scale does not need backward computation.
I0228 10:24:28.693424 12900 net.cpp:228] conv6/dw/bn does not need backward computation.
I0228 10:24:28.693428 12900 net.cpp:228] conv6/dw does not need backward computation.
I0228 10:24:28.693434 12900 net.cpp:228] conv5/relu does not need backward computation.
I0228 10:24:28.693439 12900 net.cpp:228] conv5/scale does not need backward computation.
I0228 10:24:28.693444 12900 net.cpp:228] conv5/bn does not need backward computation.
I0228 10:24:28.693449 12900 net.cpp:228] conv5 does not need backward computation.
I0228 10:24:28.693459 12900 net.cpp:228] conv5/dw/relu does not need backward computation.
I0228 10:24:28.693464 12900 net.cpp:228] conv5/dw/scale does not need backward computation.
I0228 10:24:28.693470 12900 net.cpp:228] conv5/dw/bn does not need backward computation.
I0228 10:24:28.693475 12900 net.cpp:228] conv5/dw does not need backward computation.
I0228 10:24:28.693478 12900 net.cpp:228] conv4/relu does not need backward computation.
I0228 10:24:28.693483 12900 net.cpp:228] conv4/scale does not need backward computation.
I0228 10:24:28.693490 12900 net.cpp:228] conv4/bn does not need backward computation.
I0228 10:24:28.693493 12900 net.cpp:228] conv4 does not need backward computation.
I0228 10:24:28.693498 12900 net.cpp:228] conv4/dw/relu does not need backward computation.
I0228 10:24:28.693503 12900 net.cpp:228] conv4/dw/scale does not need backward computation.
I0228 10:24:28.693509 12900 net.cpp:228] conv4/dw/bn does not need backward computation.
I0228 10:24:28.693514 12900 net.cpp:228] conv4/dw does not need backward computation.
I0228 10:24:28.693518 12900 net.cpp:228] conv3/relu does not need backward computation.
I0228 10:24:28.693523 12900 net.cpp:228] conv3/scale does not need backward computation.
I0228 10:24:28.693529 12900 net.cpp:228] conv3/bn does not need backward computation.
I0228 10:24:28.693534 12900 net.cpp:228] conv3 does not need backward computation.
I0228 10:24:28.693539 12900 net.cpp:228] conv3/dw/relu does not need backward computation.
I0228 10:24:28.693544 12900 net.cpp:228] conv3/dw/scale does not need backward computation.
I0228 10:24:28.693549 12900 net.cpp:228] conv3/dw/bn does not need backward computation.
I0228 10:24:28.693554 12900 net.cpp:228] conv3/dw does not need backward computation.
I0228 10:24:28.693559 12900 net.cpp:228] conv2/relu does not need backward computation.
I0228 10:24:28.693564 12900 net.cpp:228] conv2/scale does not need backward computation.
I0228 10:24:28.693569 12900 net.cpp:228] conv2/bn does not need backward computation.
I0228 10:24:28.693574 12900 net.cpp:228] conv2 does not need backward computation.
I0228 10:24:28.693579 12900 net.cpp:228] conv2/dw/relu does not need backward computation.
I0228 10:24:28.693584 12900 net.cpp:228] conv2/dw/scale does not need backward computation.
I0228 10:24:28.693589 12900 net.cpp:228] conv2/dw/bn does not need backward computation.
I0228 10:24:28.693594 12900 net.cpp:228] conv2/dw does not need backward computation.
I0228 10:24:28.693599 12900 net.cpp:228] conv1/relu does not need backward computation.
I0228 10:24:28.693604 12900 net.cpp:228] conv1/scale does not need backward computation.
I0228 10:24:28.693610 12900 net.cpp:228] conv1/bn does not need backward computation.
I0228 10:24:28.693614 12900 net.cpp:228] conv1 does not need backward computation.
I0228 10:24:28.693619 12900 net.cpp:228] conv1/dw/relu does not need backward computation.
I0228 10:24:28.693624 12900 net.cpp:228] conv1/dw/scale does not need backward computation.
I0228 10:24:28.693630 12900 net.cpp:228] conv1/dw/bn does not need backward computation.
I0228 10:24:28.693634 12900 net.cpp:228] conv1/dw does not need backward computation.
I0228 10:24:28.693639 12900 net.cpp:228] conv0/relu does not need backward computation.
I0228 10:24:28.693645 12900 net.cpp:228] conv0/scale does not need backward computation.
I0228 10:24:28.693650 12900 net.cpp:228] conv0/bn does not need backward computation.
I0228 10:24:28.693655 12900 net.cpp:228] conv0 does not need backward computation.
I0228 10:24:28.693661 12900 net.cpp:228] data_data_0_split does not need backward computation.
I0228 10:24:28.693666 12900 net.cpp:228] data does not need backward computation.
I0228 10:24:28.693671 12900 net.cpp:270] This network produces output detection_eval
I0228 10:24:28.693806 12900 net.cpp:283] Network initialization done.
I0228 10:24:28.694317 12900 solver.cpp:75] Solver scaffolding done.
I0228 10:24:28.707619 12900 caffe.cpp:155] Finetuning from ../mobilenet_iter_73000.caffemodel
I0228 10:24:28.723938 12900 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ../mobilenet_iter_73000.caffemodel
I0228 10:24:28.723986 12900 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0228 10:24:28.728605 12900 net.cpp:761] Ignoring source layer conv11_mbox_conf
I0228 10:24:28.728652 12900 net.cpp:761] Ignoring source layer conv13_mbox_conf
I0228 10:24:28.728675 12900 net.cpp:761] Ignoring source layer conv14_2_mbox_conf
I0228 10:24:28.728709 12900 net.cpp:761] Ignoring source layer conv15_2_mbox_conf
I0228 10:24:28.728729 12900 net.cpp:761] Ignoring source layer conv16_2_mbox_conf
I0228 10:24:28.728740 12900 net.cpp:761] Ignoring source layer conv17_2_mbox_conf
I0228 10:24:28.739472 12900 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ../mobilenet_iter_73000.caffemodel
I0228 10:24:28.739516 12900 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0228 10:24:28.743901 12900 net.cpp:761] Ignoring source layer conv11_mbox_conf
I0228 10:24:28.743952 12900 net.cpp:761] Ignoring source layer conv13_mbox_conf
I0228 10:24:28.743973 12900 net.cpp:761] Ignoring source layer conv14_2_mbox_conf
I0228 10:24:28.743988 12900 net.cpp:761] Ignoring source layer conv15_2_mbox_conf
I0228 10:24:28.744004 12900 net.cpp:761] Ignoring source layer conv16_2_mbox_conf
I0228 10:24:28.744016 12900 net.cpp:761] Ignoring source layer conv17_2_mbox_conf
I0228 10:24:28.744025 12900 net.cpp:761] Ignoring source layer mbox_loss
I0228 10:24:28.744256 12900 caffe.cpp:251] Starting Optimization
I0228 10:24:28.744266 12900 solver.cpp:294] Solving MobileNet-SSD
I0228 10:24:28.744272 12900 solver.cpp:295] Learning Rate Policy: multistep
I0228 10:24:28.751701 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 10:24:33.003247 12900 solver.cpp:243] Iteration 0, loss = 21.5038
I0228 10:24:33.003311 12900 solver.cpp:259]     Train net output #0: mbox_loss = 21.5038 (* 1 = 21.5038 loss)
I0228 10:24:33.003340 12900 sgd_solver.cpp:138] Iteration 0, lr = 0.0005
I0228 10:24:57.882184 12900 solver.cpp:243] Iteration 10, loss = 8.41158
I0228 10:24:57.882454 12900 solver.cpp:259]     Train net output #0: mbox_loss = 6.07657 (* 1 = 6.07657 loss)
I0228 10:24:57.882467 12900 sgd_solver.cpp:138] Iteration 10, lr = 0.0005
I0228 10:25:31.843399 12900 solver.cpp:243] Iteration 20, loss = 5.64336
I0228 10:25:31.843555 12900 solver.cpp:259]     Train net output #0: mbox_loss = 5.69037 (* 1 = 5.69037 loss)
I0228 10:25:31.843565 12900 sgd_solver.cpp:138] Iteration 20, lr = 0.0005
I0228 10:26:00.156997 12900 solver.cpp:243] Iteration 30, loss = 5.19233
I0228 10:26:00.157052 12900 solver.cpp:259]     Train net output #0: mbox_loss = 4.43564 (* 1 = 4.43564 loss)
I0228 10:26:00.157061 12900 sgd_solver.cpp:138] Iteration 30, lr = 0.0005
I0228 10:26:34.840611 12900 solver.cpp:243] Iteration 40, loss = 4.51068
I0228 10:26:34.840761 12900 solver.cpp:259]     Train net output #0: mbox_loss = 4.31732 (* 1 = 4.31732 loss)
I0228 10:26:34.840772 12900 sgd_solver.cpp:138] Iteration 40, lr = 0.0005
I0228 10:26:59.999007 12900 solver.cpp:243] Iteration 50, loss = 4.47864
I0228 10:26:59.999065 12900 solver.cpp:259]     Train net output #0: mbox_loss = 4.06315 (* 1 = 4.06315 loss)
I0228 10:26:59.999076 12900 sgd_solver.cpp:138] Iteration 50, lr = 0.0005
I0228 10:27:33.903570 12900 solver.cpp:243] Iteration 60, loss = 4.22468
I0228 10:27:33.903746 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.97982 (* 1 = 3.97982 loss)
I0228 10:27:33.903758 12900 sgd_solver.cpp:138] Iteration 60, lr = 0.0005
I0228 10:28:02.369830 12900 solver.cpp:243] Iteration 70, loss = 4.2673
I0228 10:28:02.369873 12900 solver.cpp:259]     Train net output #0: mbox_loss = 4.67259 (* 1 = 4.67259 loss)
I0228 10:28:02.369884 12900 sgd_solver.cpp:138] Iteration 70, lr = 0.0005
I0228 10:28:30.214385 12900 solver.cpp:243] Iteration 80, loss = 3.90681
I0228 10:28:30.214553 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.86664 (* 1 = 3.86664 loss)
I0228 10:28:30.214565 12900 sgd_solver.cpp:138] Iteration 80, lr = 0.0005
I0228 10:29:03.889351 12900 solver.cpp:243] Iteration 90, loss = 3.79439
I0228 10:29:03.889516 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.28447 (* 1 = 3.28447 loss)
I0228 10:29:03.889528 12900 sgd_solver.cpp:138] Iteration 90, lr = 0.0005
I0228 10:29:36.643411 12900 solver.cpp:243] Iteration 100, loss = 3.81625
I0228 10:29:36.643594 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.61759 (* 1 = 3.61759 loss)
I0228 10:29:36.643606 12900 sgd_solver.cpp:138] Iteration 100, lr = 0.0005
I0228 10:30:11.959283 12900 solver.cpp:243] Iteration 110, loss = 4.05899
I0228 10:30:11.959442 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.49248 (* 1 = 3.49248 loss)
I0228 10:30:11.959455 12900 sgd_solver.cpp:138] Iteration 110, lr = 0.0005
I0228 10:30:38.653465 12900 solver.cpp:243] Iteration 120, loss = 3.70611
I0228 10:30:38.653514 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.67484 (* 1 = 2.67484 loss)
I0228 10:30:38.653523 12900 sgd_solver.cpp:138] Iteration 120, lr = 0.0005
I0228 10:31:11.261505 12900 solver.cpp:243] Iteration 130, loss = 3.70238
I0228 10:31:11.261668 12900 solver.cpp:259]     Train net output #0: mbox_loss = 4.9525 (* 1 = 4.9525 loss)
I0228 10:31:11.261680 12900 sgd_solver.cpp:138] Iteration 130, lr = 0.0005
I0228 10:31:43.455840 12900 solver.cpp:243] Iteration 140, loss = 3.68049
I0228 10:31:43.455991 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.09489 (* 1 = 3.09489 loss)
I0228 10:31:43.456004 12900 sgd_solver.cpp:138] Iteration 140, lr = 0.0005
I0228 10:32:13.417409 12900 solver.cpp:243] Iteration 150, loss = 3.43131
I0228 10:32:13.417462 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.5025 (* 1 = 3.5025 loss)
I0228 10:32:13.417474 12900 sgd_solver.cpp:138] Iteration 150, lr = 0.0005
I0228 10:32:47.793112 12900 solver.cpp:243] Iteration 160, loss = 3.24403
I0228 10:32:47.793277 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.24301 (* 1 = 3.24301 loss)
I0228 10:32:47.793288 12900 sgd_solver.cpp:138] Iteration 160, lr = 0.0005
I0228 10:33:21.421257 12900 solver.cpp:243] Iteration 170, loss = 3.20156
I0228 10:33:21.421420 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.11758 (* 1 = 3.11758 loss)
I0228 10:33:21.421432 12900 sgd_solver.cpp:138] Iteration 170, lr = 0.0005
I0228 10:33:48.590662 12900 solver.cpp:243] Iteration 180, loss = 3.33663
I0228 10:33:48.590714 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.22812 (* 1 = 3.22812 loss)
I0228 10:33:48.590724 12900 sgd_solver.cpp:138] Iteration 180, lr = 0.0005
I0228 10:34:17.844259 12900 solver.cpp:243] Iteration 190, loss = 3.05001
I0228 10:34:17.844435 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.21071 (* 1 = 3.21071 loss)
I0228 10:34:17.844449 12900 sgd_solver.cpp:138] Iteration 190, lr = 0.0005
I0228 10:34:42.952849 12900 solver.cpp:243] Iteration 200, loss = 3.16629
I0228 10:34:42.952900 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.68062 (* 1 = 2.68062 loss)
I0228 10:34:42.952910 12900 sgd_solver.cpp:138] Iteration 200, lr = 0.0005
I0228 10:35:09.031515 12900 solver.cpp:243] Iteration 210, loss = 3.11643
I0228 10:35:09.031632 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.62122 (* 1 = 3.62122 loss)
I0228 10:35:09.031642 12900 sgd_solver.cpp:138] Iteration 210, lr = 0.0005
I0228 10:35:37.934622 12900 solver.cpp:243] Iteration 220, loss = 3.28602
I0228 10:35:37.934676 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.65226 (* 1 = 2.65226 loss)
I0228 10:35:37.934685 12900 sgd_solver.cpp:138] Iteration 220, lr = 0.0005
I0228 10:36:05.628316 12900 solver.cpp:243] Iteration 230, loss = 3.03727
I0228 10:36:05.628566 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.75595 (* 1 = 2.75595 loss)
I0228 10:36:05.628582 12900 sgd_solver.cpp:138] Iteration 230, lr = 0.0005
I0228 10:36:29.961730 12900 solver.cpp:243] Iteration 240, loss = 2.7761
I0228 10:36:29.961802 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.50065 (* 1 = 2.50065 loss)
I0228 10:36:29.961814 12900 sgd_solver.cpp:138] Iteration 240, lr = 0.0005
I0228 10:36:55.618569 12900 solver.cpp:243] Iteration 250, loss = 3.3934
I0228 10:36:55.618758 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.96388 (* 1 = 2.96388 loss)
I0228 10:36:55.618770 12900 sgd_solver.cpp:138] Iteration 250, lr = 0.0005
I0228 10:37:33.658614 12900 solver.cpp:243] Iteration 260, loss = 3.14051
I0228 10:37:33.658803 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.92624 (* 1 = 2.92624 loss)
I0228 10:37:33.658819 12900 sgd_solver.cpp:138] Iteration 260, lr = 0.0005
I0228 10:38:09.884795 12900 solver.cpp:243] Iteration 270, loss = 3.09627
I0228 10:38:09.884973 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.95516 (* 1 = 2.95516 loss)
I0228 10:38:09.884985 12900 sgd_solver.cpp:138] Iteration 270, lr = 0.0005
I0228 10:38:37.364614 12900 solver.cpp:243] Iteration 280, loss = 2.9783
I0228 10:38:37.364663 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.16515 (* 1 = 3.16515 loss)
I0228 10:38:37.364675 12900 sgd_solver.cpp:138] Iteration 280, lr = 0.0005
I0228 10:39:02.022006 12900 solver.cpp:243] Iteration 290, loss = 3.16335
I0228 10:39:02.022204 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.95158 (* 1 = 2.95158 loss)
I0228 10:39:02.022217 12900 sgd_solver.cpp:138] Iteration 290, lr = 0.0005
I0228 10:39:31.286049 12900 solver.cpp:243] Iteration 300, loss = 2.90211
I0228 10:39:31.286109 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.60676 (* 1 = 2.60676 loss)
I0228 10:39:31.286120 12900 sgd_solver.cpp:138] Iteration 300, lr = 0.0005
I0228 10:40:04.134407 12900 solver.cpp:243] Iteration 310, loss = 3.10625
I0228 10:40:04.134577 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.92058 (* 1 = 3.92058 loss)
I0228 10:40:04.134590 12900 sgd_solver.cpp:138] Iteration 310, lr = 0.0005
I0228 10:40:32.452853 12900 solver.cpp:243] Iteration 320, loss = 2.80379
I0228 10:40:32.452913 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.60644 (* 1 = 2.60644 loss)
I0228 10:40:32.452924 12900 sgd_solver.cpp:138] Iteration 320, lr = 0.0005
I0228 10:40:58.118767 12900 solver.cpp:243] Iteration 330, loss = 2.94962
I0228 10:40:58.118934 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.46819 (* 1 = 3.46819 loss)
I0228 10:40:58.118947 12900 sgd_solver.cpp:138] Iteration 330, lr = 0.0005
I0228 10:41:25.300550 12900 solver.cpp:243] Iteration 340, loss = 3.16542
I0228 10:41:25.300607 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.73561 (* 1 = 2.73561 loss)
I0228 10:41:25.300618 12900 sgd_solver.cpp:138] Iteration 340, lr = 0.0005
I0228 10:42:01.499336 12900 solver.cpp:243] Iteration 350, loss = 2.99064
I0228 10:42:01.499508 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.98778 (* 1 = 2.98778 loss)
I0228 10:42:01.499523 12900 sgd_solver.cpp:138] Iteration 350, lr = 0.0005
I0228 10:42:30.501240 12900 solver.cpp:243] Iteration 360, loss = 2.82028
I0228 10:42:30.501293 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.50252 (* 1 = 3.50252 loss)
I0228 10:42:30.501303 12900 sgd_solver.cpp:138] Iteration 360, lr = 0.0005
I0228 10:42:56.262717 12900 solver.cpp:243] Iteration 370, loss = 2.72776
I0228 10:42:56.262898 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.8141 (* 1 = 2.8141 loss)
I0228 10:42:56.262912 12900 sgd_solver.cpp:138] Iteration 370, lr = 0.0005
I0228 10:43:21.143000 12900 solver.cpp:243] Iteration 380, loss = 2.93126
I0228 10:43:21.143051 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.73887 (* 1 = 2.73887 loss)
I0228 10:43:21.143060 12900 sgd_solver.cpp:138] Iteration 380, lr = 0.0005
I0228 10:43:52.642534 12900 solver.cpp:243] Iteration 390, loss = 2.80546
I0228 10:43:52.642704 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.53938 (* 1 = 3.53938 loss)
I0228 10:43:52.642717 12900 sgd_solver.cpp:138] Iteration 390, lr = 0.0005
I0228 10:44:20.438736 12900 solver.cpp:243] Iteration 400, loss = 2.8834
I0228 10:44:20.438793 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.84738 (* 1 = 2.84738 loss)
I0228 10:44:20.438803 12900 sgd_solver.cpp:138] Iteration 400, lr = 0.0005
I0228 10:44:52.955816 12900 solver.cpp:243] Iteration 410, loss = 2.7251
I0228 10:44:52.956006 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.62454 (* 1 = 2.62454 loss)
I0228 10:44:52.956017 12900 sgd_solver.cpp:138] Iteration 410, lr = 0.0005
I0228 10:45:22.700198 12900 solver.cpp:243] Iteration 420, loss = 2.98749
I0228 10:45:22.700242 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.86913 (* 1 = 2.86913 loss)
I0228 10:45:22.700251 12900 sgd_solver.cpp:138] Iteration 420, lr = 0.0005
I0228 10:45:55.199434 12900 solver.cpp:243] Iteration 430, loss = 2.8858
I0228 10:45:55.199625 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.1527 (* 1 = 2.1527 loss)
I0228 10:45:55.199640 12900 sgd_solver.cpp:138] Iteration 430, lr = 0.0005
I0228 10:46:21.246121 12900 solver.cpp:243] Iteration 440, loss = 2.52933
I0228 10:46:21.246172 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.01701 (* 1 = 3.01701 loss)
I0228 10:46:21.246181 12900 sgd_solver.cpp:138] Iteration 440, lr = 0.0005
I0228 10:46:50.733032 12900 solver.cpp:243] Iteration 450, loss = 2.89525
I0228 10:46:50.733209 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.75541 (* 1 = 2.75541 loss)
I0228 10:46:50.733222 12900 sgd_solver.cpp:138] Iteration 450, lr = 0.0005
I0228 10:47:19.822108 12900 solver.cpp:243] Iteration 460, loss = 2.66696
I0228 10:47:19.822160 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.56962 (* 1 = 2.56962 loss)
I0228 10:47:19.822170 12900 sgd_solver.cpp:138] Iteration 460, lr = 0.0005
I0228 10:47:49.281785 12900 solver.cpp:243] Iteration 470, loss = 2.81448
I0228 10:47:49.281956 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.02054 (* 1 = 3.02054 loss)
I0228 10:47:49.281973 12900 sgd_solver.cpp:138] Iteration 470, lr = 0.0005
I0228 10:48:19.728099 12900 solver.cpp:243] Iteration 480, loss = 2.72853
I0228 10:48:19.728305 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.78782 (* 1 = 2.78782 loss)
I0228 10:48:19.728318 12900 sgd_solver.cpp:138] Iteration 480, lr = 0.0005
I0228 10:48:53.802812 12900 solver.cpp:243] Iteration 490, loss = 2.5365
I0228 10:48:53.802984 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.25003 (* 1 = 3.25003 loss)
I0228 10:48:53.802996 12900 sgd_solver.cpp:138] Iteration 490, lr = 0.0005
I0228 10:49:19.129354 12900 solver.cpp:243] Iteration 500, loss = 2.65049
I0228 10:49:19.129405 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.47599 (* 1 = 3.47599 loss)
I0228 10:49:19.129415 12900 sgd_solver.cpp:138] Iteration 500, lr = 0.0005
I0228 10:50:04.069046 12900 solver.cpp:243] Iteration 510, loss = 2.57396
I0228 10:50:04.069198 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.44485 (* 1 = 2.44485 loss)
I0228 10:50:04.069211 12900 sgd_solver.cpp:138] Iteration 510, lr = 0.0005
I0228 10:50:30.161765 12900 solver.cpp:243] Iteration 520, loss = 2.73189
I0228 10:50:30.161813 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.10342 (* 1 = 2.10342 loss)
I0228 10:50:30.161823 12900 sgd_solver.cpp:138] Iteration 520, lr = 0.0005
I0228 10:50:55.585656 12900 solver.cpp:243] Iteration 530, loss = 2.38858
I0228 10:50:55.585834 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.73821 (* 1 = 2.73821 loss)
I0228 10:50:55.585865 12900 sgd_solver.cpp:138] Iteration 530, lr = 0.0005
I0228 10:51:21.225291 12900 solver.cpp:243] Iteration 540, loss = 2.68509
I0228 10:51:21.225329 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.02023 (* 1 = 3.02023 loss)
I0228 10:51:21.225338 12900 sgd_solver.cpp:138] Iteration 540, lr = 0.0005
I0228 10:51:50.036242 12900 solver.cpp:243] Iteration 550, loss = 2.50293
I0228 10:51:50.036435 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.4263 (* 1 = 2.4263 loss)
I0228 10:51:50.036448 12900 sgd_solver.cpp:138] Iteration 550, lr = 0.0005
I0228 10:52:32.971412 12900 solver.cpp:243] Iteration 560, loss = 2.59579
I0228 10:52:32.971700 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.6337 (* 1 = 2.6337 loss)
I0228 10:52:32.971724 12900 sgd_solver.cpp:138] Iteration 560, lr = 0.0005
I0228 10:53:02.848074 12900 solver.cpp:243] Iteration 570, loss = 2.46718
I0228 10:53:02.848124 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.26216 (* 1 = 3.26216 loss)
I0228 10:53:02.848134 12900 sgd_solver.cpp:138] Iteration 570, lr = 0.0005
I0228 10:53:32.736480 12900 solver.cpp:243] Iteration 580, loss = 2.64784
I0228 10:53:32.736654 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.45068 (* 1 = 2.45068 loss)
I0228 10:53:32.736667 12900 sgd_solver.cpp:138] Iteration 580, lr = 0.0005
I0228 10:54:01.813943 12900 solver.cpp:243] Iteration 590, loss = 2.94774
I0228 10:54:01.813998 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.26263 (* 1 = 2.26263 loss)
I0228 10:54:01.814009 12900 sgd_solver.cpp:138] Iteration 590, lr = 0.0005
I0228 10:54:41.944623 12900 solver.cpp:243] Iteration 600, loss = 2.71345
I0228 10:54:41.944814 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.17015 (* 1 = 3.17015 loss)
I0228 10:54:41.944826 12900 sgd_solver.cpp:138] Iteration 600, lr = 0.0005
I0228 10:55:06.809229 12900 solver.cpp:243] Iteration 610, loss = 2.43836
I0228 10:55:06.809281 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.51804 (* 1 = 2.51804 loss)
I0228 10:55:06.809290 12900 sgd_solver.cpp:138] Iteration 610, lr = 0.0005
I0228 10:55:34.134330 12900 solver.cpp:243] Iteration 620, loss = 2.63254
I0228 10:55:34.134503 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96971 (* 1 = 1.96971 loss)
I0228 10:55:34.134517 12900 sgd_solver.cpp:138] Iteration 620, lr = 0.0005
I0228 10:56:02.561520 12900 solver.cpp:243] Iteration 630, loss = 2.52729
I0228 10:56:02.561563 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.88634 (* 1 = 2.88634 loss)
I0228 10:56:02.561574 12900 sgd_solver.cpp:138] Iteration 630, lr = 0.0005
I0228 10:56:25.777770 12900 solver.cpp:243] Iteration 640, loss = 2.44538
I0228 10:56:25.777959 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.11477 (* 1 = 2.11477 loss)
I0228 10:56:25.777971 12900 sgd_solver.cpp:138] Iteration 640, lr = 0.0005
I0228 10:57:33.336007 12900 solver.cpp:243] Iteration 650, loss = 2.82732
I0228 10:57:33.336194 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.8069 (* 1 = 1.8069 loss)
I0228 10:57:33.336205 12900 sgd_solver.cpp:138] Iteration 650, lr = 0.0005
I0228 10:57:58.427841 12900 solver.cpp:243] Iteration 660, loss = 2.35715
I0228 10:57:58.427877 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.21617 (* 1 = 2.21617 loss)
I0228 10:57:58.427886 12900 sgd_solver.cpp:138] Iteration 660, lr = 0.0005
I0228 10:58:29.042397 12900 solver.cpp:243] Iteration 670, loss = 2.64865
I0228 10:58:29.042488 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.37725 (* 1 = 2.37725 loss)
I0228 10:58:29.042501 12900 sgd_solver.cpp:138] Iteration 670, lr = 0.0005
I0228 10:58:56.284428 12900 solver.cpp:243] Iteration 680, loss = 2.85064
I0228 10:58:56.284476 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.38177 (* 1 = 3.38177 loss)
I0228 10:58:56.284485 12900 sgd_solver.cpp:138] Iteration 680, lr = 0.0005
I0228 10:59:22.650898 12900 solver.cpp:243] Iteration 690, loss = 2.38429
I0228 10:59:22.651090 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.28983 (* 1 = 2.28983 loss)
I0228 10:59:22.651108 12900 sgd_solver.cpp:138] Iteration 690, lr = 0.0005
I0228 10:59:49.974556 12900 solver.cpp:243] Iteration 700, loss = 2.48019
I0228 10:59:49.974611 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07308 (* 1 = 2.07308 loss)
I0228 10:59:49.974622 12900 sgd_solver.cpp:138] Iteration 700, lr = 0.0005
I0228 11:00:17.108155 12900 solver.cpp:243] Iteration 710, loss = 2.29562
I0228 11:00:17.108327 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.82264 (* 1 = 2.82264 loss)
I0228 11:00:17.108343 12900 sgd_solver.cpp:138] Iteration 710, lr = 0.0005
I0228 11:00:44.173357 12900 solver.cpp:243] Iteration 720, loss = 2.44642
I0228 11:00:44.173393 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.7803 (* 1 = 2.7803 loss)
I0228 11:00:44.173401 12900 sgd_solver.cpp:138] Iteration 720, lr = 0.0005
I0228 11:01:15.436496 12900 solver.cpp:243] Iteration 730, loss = 2.59535
I0228 11:01:15.436710 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.63517 (* 1 = 3.63517 loss)
I0228 11:01:15.436724 12900 sgd_solver.cpp:138] Iteration 730, lr = 0.0005
I0228 11:02:33.430385 12900 solver.cpp:243] Iteration 740, loss = 2.61062
I0228 11:02:33.430569 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.84636 (* 1 = 3.84636 loss)
I0228 11:02:33.430582 12900 sgd_solver.cpp:138] Iteration 740, lr = 0.0005
I0228 11:03:25.608428 12900 solver.cpp:243] Iteration 750, loss = 2.32155
I0228 11:03:25.608636 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07957 (* 1 = 2.07957 loss)
I0228 11:03:25.608654 12900 sgd_solver.cpp:138] Iteration 750, lr = 0.0005
I0228 11:04:18.808225 12900 solver.cpp:243] Iteration 760, loss = 2.49148
I0228 11:04:18.808439 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.35218 (* 1 = 2.35218 loss)
I0228 11:04:18.808456 12900 sgd_solver.cpp:138] Iteration 760, lr = 0.0005
I0228 11:04:50.680842 12900 solver.cpp:243] Iteration 770, loss = 2.52098
I0228 11:04:50.680989 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.18776 (* 1 = 2.18776 loss)
I0228 11:04:50.681000 12900 sgd_solver.cpp:138] Iteration 770, lr = 0.0005
I0228 11:05:23.644568 12900 solver.cpp:243] Iteration 780, loss = 2.41018
I0228 11:05:23.644726 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38331 (* 1 = 2.38331 loss)
I0228 11:05:23.644738 12900 sgd_solver.cpp:138] Iteration 780, lr = 0.0005
I0228 11:05:51.202446 12900 solver.cpp:243] Iteration 790, loss = 2.37236
I0228 11:05:51.202495 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.37832 (* 1 = 2.37832 loss)
I0228 11:05:51.202522 12900 sgd_solver.cpp:138] Iteration 790, lr = 0.0005
I0228 11:06:15.313844 12900 solver.cpp:243] Iteration 800, loss = 2.46628
I0228 11:06:15.314021 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.1544 (* 1 = 2.1544 loss)
I0228 11:06:15.314033 12900 sgd_solver.cpp:138] Iteration 800, lr = 0.0005
I0228 11:06:46.667696 12900 solver.cpp:243] Iteration 810, loss = 2.57796
I0228 11:06:46.667866 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.08753 (* 1 = 2.08753 loss)
I0228 11:06:46.667878 12900 sgd_solver.cpp:138] Iteration 810, lr = 0.0005
I0228 11:07:40.353538 12900 solver.cpp:243] Iteration 820, loss = 2.33852
I0228 11:07:40.353718 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.11592 (* 1 = 2.11592 loss)
I0228 11:07:40.353729 12900 sgd_solver.cpp:138] Iteration 820, lr = 0.0005
I0228 11:08:04.273084 12900 solver.cpp:243] Iteration 830, loss = 2.48399
I0228 11:08:04.273139 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.66922 (* 1 = 2.66922 loss)
I0228 11:08:04.273150 12900 sgd_solver.cpp:138] Iteration 830, lr = 0.0005
I0228 11:08:30.007772 12900 solver.cpp:243] Iteration 840, loss = 2.38553
I0228 11:08:30.007961 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.89818 (* 1 = 1.89818 loss)
I0228 11:08:30.007972 12900 sgd_solver.cpp:138] Iteration 840, lr = 0.0005
I0228 11:08:56.371419 12900 solver.cpp:243] Iteration 850, loss = 2.51789
I0228 11:08:56.371469 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.35771 (* 1 = 2.35771 loss)
I0228 11:08:56.371479 12900 sgd_solver.cpp:138] Iteration 850, lr = 0.0005
I0228 11:09:23.599267 12900 solver.cpp:243] Iteration 860, loss = 2.38108
I0228 11:09:23.599418 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.43811 (* 1 = 2.43811 loss)
I0228 11:09:23.599431 12900 sgd_solver.cpp:138] Iteration 860, lr = 0.0005
I0228 11:10:19.910235 12900 solver.cpp:243] Iteration 870, loss = 2.40952
I0228 11:10:19.910468 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.29285 (* 1 = 3.29285 loss)
I0228 11:10:19.910482 12900 sgd_solver.cpp:138] Iteration 870, lr = 0.0005
I0228 11:10:58.742162 12900 solver.cpp:243] Iteration 880, loss = 2.55024
I0228 11:10:58.742317 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.12717 (* 1 = 3.12717 loss)
I0228 11:10:58.742347 12900 sgd_solver.cpp:138] Iteration 880, lr = 0.0005
I0228 11:11:31.689672 12900 solver.cpp:243] Iteration 890, loss = 2.26821
I0228 11:11:31.689867 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96522 (* 1 = 1.96522 loss)
I0228 11:11:31.689878 12900 sgd_solver.cpp:138] Iteration 890, lr = 0.0005
I0228 11:12:01.508543 12900 solver.cpp:243] Iteration 900, loss = 2.38633
I0228 11:12:01.508586 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.18527 (* 1 = 2.18527 loss)
I0228 11:12:01.508597 12900 sgd_solver.cpp:138] Iteration 900, lr = 0.0005
I0228 11:12:38.759801 12900 solver.cpp:243] Iteration 910, loss = 2.65646
I0228 11:12:38.759953 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.45378 (* 1 = 2.45378 loss)
I0228 11:12:38.759986 12900 sgd_solver.cpp:138] Iteration 910, lr = 0.0005
I0228 11:13:04.015372 12900 solver.cpp:243] Iteration 920, loss = 2.19309
I0228 11:13:04.015421 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.39792 (* 1 = 2.39792 loss)
I0228 11:13:04.015430 12900 sgd_solver.cpp:138] Iteration 920, lr = 0.0005
I0228 11:13:36.742894 12900 solver.cpp:243] Iteration 930, loss = 2.47674
I0228 11:13:36.743065 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.15452 (* 1 = 2.15452 loss)
I0228 11:13:36.743078 12900 sgd_solver.cpp:138] Iteration 930, lr = 0.0005
I0228 11:14:09.529825 12900 solver.cpp:243] Iteration 940, loss = 2.29191
I0228 11:14:09.529969 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.67825 (* 1 = 2.67825 loss)
I0228 11:14:09.529980 12900 sgd_solver.cpp:138] Iteration 940, lr = 0.0005
I0228 11:14:46.271899 12900 solver.cpp:243] Iteration 950, loss = 2.629
I0228 11:14:46.272034 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.20652 (* 1 = 2.20652 loss)
I0228 11:14:46.272047 12900 sgd_solver.cpp:138] Iteration 950, lr = 0.0005
I0228 11:15:09.476691 12900 solver.cpp:243] Iteration 960, loss = 2.65034
I0228 11:15:09.476745 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.74396 (* 1 = 2.74396 loss)
I0228 11:15:09.476755 12900 sgd_solver.cpp:138] Iteration 960, lr = 0.0005
I0228 11:15:36.421545 12900 solver.cpp:243] Iteration 970, loss = 2.69589
I0228 11:15:36.421739 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.60194 (* 1 = 2.60194 loss)
I0228 11:15:36.421752 12900 sgd_solver.cpp:138] Iteration 970, lr = 0.0005
I0228 11:16:03.533097 12900 solver.cpp:243] Iteration 980, loss = 2.4674
I0228 11:16:03.533154 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.30728 (* 1 = 2.30728 loss)
I0228 11:16:03.533165 12900 sgd_solver.cpp:138] Iteration 980, lr = 0.0005
I0228 11:16:38.952081 12900 solver.cpp:243] Iteration 990, loss = 2.54875
I0228 11:16:38.952237 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.43899 (* 1 = 2.43899 loss)
I0228 11:16:38.952251 12900 sgd_solver.cpp:138] Iteration 990, lr = 0.0005
I0228 11:17:03.325453 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_1000.caffemodel
I0228 11:17:03.435462 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_1000.solverstate
I0228 11:17:05.505767 12900 solver.cpp:243] Iteration 1000, loss = 2.16447
I0228 11:17:05.505831 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.28826 (* 1 = 2.28826 loss)
I0228 11:17:05.505842 12900 sgd_solver.cpp:138] Iteration 1000, lr = 0.0005
I0228 11:17:38.013070 12900 solver.cpp:243] Iteration 1010, loss = 2.53471
I0228 11:17:38.013200 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.5621 (* 1 = 2.5621 loss)
I0228 11:17:38.013214 12900 sgd_solver.cpp:138] Iteration 1010, lr = 0.0005
I0228 11:18:11.465231 12900 solver.cpp:243] Iteration 1020, loss = 2.18447
I0228 11:18:11.465404 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.2558 (* 1 = 2.2558 loss)
I0228 11:18:11.465415 12900 sgd_solver.cpp:138] Iteration 1020, lr = 0.0005
I0228 11:18:37.708019 12900 solver.cpp:243] Iteration 1030, loss = 2.47867
I0228 11:18:37.708081 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.58438 (* 1 = 2.58438 loss)
I0228 11:18:37.708092 12900 sgd_solver.cpp:138] Iteration 1030, lr = 0.0005
I0228 11:19:12.402443 12900 solver.cpp:243] Iteration 1040, loss = 2.23116
I0228 11:19:12.402634 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38866 (* 1 = 2.38866 loss)
I0228 11:19:12.402647 12900 sgd_solver.cpp:138] Iteration 1040, lr = 0.0005
I0228 11:19:42.655021 12900 solver.cpp:243] Iteration 1050, loss = 2.59032
I0228 11:19:42.655177 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.54639 (* 1 = 2.54639 loss)
I0228 11:19:42.655190 12900 sgd_solver.cpp:138] Iteration 1050, lr = 0.0005
I0228 11:20:18.455188 12900 solver.cpp:243] Iteration 1060, loss = 2.18831
I0228 11:20:18.455359 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.85224 (* 1 = 2.85224 loss)
I0228 11:20:18.455373 12900 sgd_solver.cpp:138] Iteration 1060, lr = 0.0005
I0228 11:20:48.090991 12900 solver.cpp:243] Iteration 1070, loss = 2.38317
I0228 11:20:48.091042 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.66382 (* 1 = 2.66382 loss)
I0228 11:20:48.091053 12900 sgd_solver.cpp:138] Iteration 1070, lr = 0.0005
I0228 11:21:09.874794 12900 solver.cpp:243] Iteration 1080, loss = 2.3884
I0228 11:21:09.874979 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.906 (* 1 = 1.906 loss)
I0228 11:21:09.874990 12900 sgd_solver.cpp:138] Iteration 1080, lr = 0.0005
I0228 11:21:41.090821 12900 solver.cpp:243] Iteration 1090, loss = 2.25654
I0228 11:21:41.090975 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.79691 (* 1 = 1.79691 loss)
I0228 11:21:41.090989 12900 sgd_solver.cpp:138] Iteration 1090, lr = 0.0005
I0228 11:22:09.100764 12900 solver.cpp:243] Iteration 1100, loss = 2.35724
I0228 11:22:09.100822 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.97017 (* 1 = 1.97017 loss)
I0228 11:22:09.100833 12900 sgd_solver.cpp:138] Iteration 1100, lr = 0.0005
I0228 11:22:24.614936 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 11:22:36.621265 12900 solver.cpp:243] Iteration 1110, loss = 2.54227
I0228 11:22:36.621311 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.69711 (* 1 = 1.69711 loss)
I0228 11:22:36.621321 12900 sgd_solver.cpp:138] Iteration 1110, lr = 0.0005
I0228 11:23:10.691035 12900 solver.cpp:243] Iteration 1120, loss = 2.4511
I0228 11:23:10.691195 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.02001 (* 1 = 3.02001 loss)
I0228 11:23:10.691208 12900 sgd_solver.cpp:138] Iteration 1120, lr = 0.0005
I0228 11:23:39.153240 12900 solver.cpp:243] Iteration 1130, loss = 2.36804
I0228 11:23:39.153321 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.17303 (* 1 = 2.17303 loss)
I0228 11:23:39.153331 12900 sgd_solver.cpp:138] Iteration 1130, lr = 0.0005
I0228 11:24:09.548341 12900 solver.cpp:243] Iteration 1140, loss = 2.47326
I0228 11:24:09.548519 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.90177 (* 1 = 2.90177 loss)
I0228 11:24:09.548534 12900 sgd_solver.cpp:138] Iteration 1140, lr = 0.0005
I0228 11:24:36.211699 12900 solver.cpp:243] Iteration 1150, loss = 2.31947
I0228 11:24:36.211755 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.09734 (* 1 = 3.09734 loss)
I0228 11:24:36.211766 12900 sgd_solver.cpp:138] Iteration 1150, lr = 0.0005
I0228 11:25:08.416645 12900 solver.cpp:243] Iteration 1160, loss = 2.33841
I0228 11:25:08.416826 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.58782 (* 1 = 2.58782 loss)
I0228 11:25:08.416839 12900 sgd_solver.cpp:138] Iteration 1160, lr = 0.0005
I0228 11:25:43.404865 12900 solver.cpp:243] Iteration 1170, loss = 2.33779
I0228 11:25:43.405035 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.93603 (* 1 = 2.93603 loss)
I0228 11:25:43.405047 12900 sgd_solver.cpp:138] Iteration 1170, lr = 0.0005
I0228 11:26:11.807814 12900 solver.cpp:243] Iteration 1180, loss = 2.37396
I0228 11:26:11.807875 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.60327 (* 1 = 2.60327 loss)
I0228 11:26:11.807888 12900 sgd_solver.cpp:138] Iteration 1180, lr = 0.0005
I0228 11:26:45.473908 12900 solver.cpp:243] Iteration 1190, loss = 2.32629
I0228 11:26:45.474095 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.31955 (* 1 = 2.31955 loss)
I0228 11:26:45.474109 12900 sgd_solver.cpp:138] Iteration 1190, lr = 0.0005
I0228 11:27:19.852236 12900 solver.cpp:243] Iteration 1200, loss = 2.35635
I0228 11:27:19.852371 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80608 (* 1 = 1.80608 loss)
I0228 11:27:19.852385 12900 sgd_solver.cpp:138] Iteration 1200, lr = 0.0005
I0228 11:27:48.102890 12900 solver.cpp:243] Iteration 1210, loss = 2.21908
I0228 11:27:48.102936 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78948 (* 1 = 1.78948 loss)
I0228 11:27:48.102947 12900 sgd_solver.cpp:138] Iteration 1210, lr = 0.0005
I0228 11:28:17.324601 12900 solver.cpp:243] Iteration 1220, loss = 2.38543
I0228 11:28:17.324754 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.09236 (* 1 = 2.09236 loss)
I0228 11:28:17.324769 12900 sgd_solver.cpp:138] Iteration 1220, lr = 0.0005
I0228 11:28:49.106385 12900 solver.cpp:243] Iteration 1230, loss = 2.31161
I0228 11:28:49.106515 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.61075 (* 1 = 2.61075 loss)
I0228 11:28:49.106528 12900 sgd_solver.cpp:138] Iteration 1230, lr = 0.0005
I0228 11:29:28.737169 12900 solver.cpp:243] Iteration 1240, loss = 2.28846
I0228 11:29:28.737329 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.28458 (* 1 = 2.28458 loss)
I0228 11:29:28.737341 12900 sgd_solver.cpp:138] Iteration 1240, lr = 0.0005
I0228 11:29:56.917726 12900 solver.cpp:243] Iteration 1250, loss = 2.45497
I0228 11:29:56.917770 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.24282 (* 1 = 2.24282 loss)
I0228 11:29:56.917781 12900 sgd_solver.cpp:138] Iteration 1250, lr = 0.0005
I0228 11:30:27.384606 12900 solver.cpp:243] Iteration 1260, loss = 2.15423
I0228 11:30:27.384765 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80176 (* 1 = 1.80176 loss)
I0228 11:30:27.384778 12900 sgd_solver.cpp:138] Iteration 1260, lr = 0.0005
I0228 11:31:00.486515 12900 solver.cpp:243] Iteration 1270, loss = 2.10403
I0228 11:31:00.486649 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.51235 (* 1 = 2.51235 loss)
I0228 11:31:00.486665 12900 sgd_solver.cpp:138] Iteration 1270, lr = 0.0005
I0228 11:31:24.140841 12900 solver.cpp:243] Iteration 1280, loss = 2.14955
I0228 11:31:24.140899 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.80322 (* 1 = 2.80322 loss)
I0228 11:31:24.140910 12900 sgd_solver.cpp:138] Iteration 1280, lr = 0.0005
I0228 11:31:58.530562 12900 solver.cpp:243] Iteration 1290, loss = 2.60703
I0228 11:31:58.530726 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.7398 (* 1 = 2.7398 loss)
I0228 11:31:58.530738 12900 sgd_solver.cpp:138] Iteration 1290, lr = 0.0005
I0228 11:32:29.102033 12900 solver.cpp:243] Iteration 1300, loss = 2.28433
I0228 11:32:29.102205 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.71083 (* 1 = 2.71083 loss)
I0228 11:32:29.102218 12900 sgd_solver.cpp:138] Iteration 1300, lr = 0.0005
I0228 11:32:57.931393 12900 solver.cpp:243] Iteration 1310, loss = 2.21335
I0228 11:32:57.931449 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41831 (* 1 = 2.41831 loss)
I0228 11:32:57.931460 12900 sgd_solver.cpp:138] Iteration 1310, lr = 0.0005
I0228 11:33:39.271706 12900 solver.cpp:243] Iteration 1320, loss = 2.35346
I0228 11:33:39.271872 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07311 (* 1 = 2.07311 loss)
I0228 11:33:39.271886 12900 sgd_solver.cpp:138] Iteration 1320, lr = 0.0005
I0228 11:34:09.083612 12900 solver.cpp:243] Iteration 1330, loss = 2.4987
I0228 11:34:09.083668 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.36183 (* 1 = 3.36183 loss)
I0228 11:34:09.083679 12900 sgd_solver.cpp:138] Iteration 1330, lr = 0.0005
I0228 11:34:43.747948 12900 solver.cpp:243] Iteration 1340, loss = 2.19202
I0228 11:34:43.748155 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.32812 (* 1 = 3.32812 loss)
I0228 11:34:43.748170 12900 sgd_solver.cpp:138] Iteration 1340, lr = 0.0005
I0228 11:35:19.610638 12900 solver.cpp:243] Iteration 1350, loss = 2.53443
I0228 11:35:19.610810 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.93841 (* 1 = 2.93841 loss)
I0228 11:35:19.610823 12900 sgd_solver.cpp:138] Iteration 1350, lr = 0.0005
I0228 11:35:48.501199 12900 solver.cpp:243] Iteration 1360, loss = 2.32457
I0228 11:35:48.501260 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.50203 (* 1 = 1.50203 loss)
I0228 11:35:48.501271 12900 sgd_solver.cpp:138] Iteration 1360, lr = 0.0005
I0228 11:36:16.265043 12900 solver.cpp:243] Iteration 1370, loss = 2.28174
I0228 11:36:16.265198 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.3105 (* 1 = 2.3105 loss)
I0228 11:36:16.265211 12900 sgd_solver.cpp:138] Iteration 1370, lr = 0.0005
I0228 11:37:46.163964 12900 solver.cpp:243] Iteration 1380, loss = 1.94504
I0228 11:37:46.164140 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.68674 (* 1 = 1.68674 loss)
I0228 11:37:46.164155 12900 sgd_solver.cpp:138] Iteration 1380, lr = 0.0005
I0228 11:39:05.354480 12900 solver.cpp:243] Iteration 1390, loss = 2.26098
I0228 11:39:05.354647 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.45948 (* 1 = 2.45948 loss)
I0228 11:39:05.354660 12900 sgd_solver.cpp:138] Iteration 1390, lr = 0.0005
I0228 11:39:35.313100 12900 solver.cpp:243] Iteration 1400, loss = 2.07972
I0228 11:39:35.313158 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.18458 (* 1 = 2.18458 loss)
I0228 11:39:35.313169 12900 sgd_solver.cpp:138] Iteration 1400, lr = 0.0005
I0228 11:40:08.349879 12900 solver.cpp:243] Iteration 1410, loss = 2.38709
I0228 11:40:08.350037 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.51865 (* 1 = 3.51865 loss)
I0228 11:40:08.350049 12900 sgd_solver.cpp:138] Iteration 1410, lr = 0.0005
I0228 11:40:37.220294 12900 solver.cpp:243] Iteration 1420, loss = 2.37419
I0228 11:40:37.220372 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.83373 (* 1 = 1.83373 loss)
I0228 11:40:37.220387 12900 sgd_solver.cpp:138] Iteration 1420, lr = 0.0005
I0228 11:41:12.696044 12900 solver.cpp:243] Iteration 1430, loss = 2.17906
I0228 11:41:12.696213 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.90045 (* 1 = 1.90045 loss)
I0228 11:41:12.696225 12900 sgd_solver.cpp:138] Iteration 1430, lr = 0.0005
I0228 11:41:40.895257 12900 solver.cpp:243] Iteration 1440, loss = 2.48252
I0228 11:41:40.895293 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.32387 (* 1 = 2.32387 loss)
I0228 11:41:40.895303 12900 sgd_solver.cpp:138] Iteration 1440, lr = 0.0005
I0228 11:42:08.709100 12900 solver.cpp:243] Iteration 1450, loss = 2.35839
I0228 11:42:08.709250 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.4868 (* 1 = 2.4868 loss)
I0228 11:42:08.709264 12900 sgd_solver.cpp:138] Iteration 1450, lr = 0.0005
I0228 11:42:37.702769 12900 solver.cpp:243] Iteration 1460, loss = 2.22812
I0228 11:42:37.702834 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.26353 (* 1 = 3.26353 loss)
I0228 11:42:37.702846 12900 sgd_solver.cpp:138] Iteration 1460, lr = 0.0005
I0228 11:43:13.022790 12900 solver.cpp:243] Iteration 1470, loss = 2.31317
I0228 11:43:13.022943 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.4158 (* 1 = 2.4158 loss)
I0228 11:43:13.022955 12900 sgd_solver.cpp:138] Iteration 1470, lr = 0.0005
I0228 11:43:51.681218 12900 solver.cpp:243] Iteration 1480, loss = 2.1115
I0228 11:43:51.681354 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.6486 (* 1 = 2.6486 loss)
I0228 11:43:51.681366 12900 sgd_solver.cpp:138] Iteration 1480, lr = 0.0005
I0228 11:44:21.438671 12900 solver.cpp:243] Iteration 1490, loss = 2.19779
I0228 11:44:21.438726 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.98011 (* 1 = 1.98011 loss)
I0228 11:44:21.438738 12900 sgd_solver.cpp:138] Iteration 1490, lr = 0.0005
I0228 11:45:45.153264 12900 solver.cpp:243] Iteration 1500, loss = 2.40003
I0228 11:45:45.153466 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.71627 (* 1 = 2.71627 loss)
I0228 11:45:45.153481 12900 sgd_solver.cpp:138] Iteration 1500, lr = 0.0005
I0228 11:47:30.286057 12900 solver.cpp:243] Iteration 1510, loss = 2.09624
I0228 11:47:30.286231 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.25413 (* 1 = 2.25413 loss)
I0228 11:47:30.286243 12900 sgd_solver.cpp:138] Iteration 1510, lr = 0.0005
I0228 11:48:32.634624 12900 solver.cpp:243] Iteration 1520, loss = 2.53875
I0228 11:48:32.634815 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.3151 (* 1 = 2.3151 loss)
I0228 11:48:32.634830 12900 sgd_solver.cpp:138] Iteration 1520, lr = 0.0005
I0228 11:49:58.702993 12900 solver.cpp:243] Iteration 1530, loss = 2.29595
I0228 11:49:58.703208 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.80549 (* 1 = 2.80549 loss)
I0228 11:49:58.703255 12900 sgd_solver.cpp:138] Iteration 1530, lr = 0.0005
I0228 11:51:28.015713 12900 solver.cpp:243] Iteration 1540, loss = 2.05199
I0228 11:51:28.015877 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.10805 (* 1 = 2.10805 loss)
I0228 11:51:28.015890 12900 sgd_solver.cpp:138] Iteration 1540, lr = 0.0005
I0228 11:51:54.933923 12900 solver.cpp:243] Iteration 1550, loss = 2.19364
I0228 11:51:54.933970 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.81963 (* 1 = 2.81963 loss)
I0228 11:51:54.933980 12900 sgd_solver.cpp:138] Iteration 1550, lr = 0.0005
I0228 11:52:26.310453 12900 solver.cpp:243] Iteration 1560, loss = 2.14757
I0228 11:52:26.310649 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.70802 (* 1 = 1.70802 loss)
I0228 11:52:26.310662 12900 sgd_solver.cpp:138] Iteration 1560, lr = 0.0005
I0228 11:53:00.270771 12900 solver.cpp:243] Iteration 1570, loss = 2.26821
I0228 11:53:00.270958 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.72067 (* 1 = 2.72067 loss)
I0228 11:53:00.270972 12900 sgd_solver.cpp:138] Iteration 1570, lr = 0.0005
I0228 11:53:35.154673 12900 solver.cpp:243] Iteration 1580, loss = 2.39258
I0228 11:53:35.154830 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.82165 (* 1 = 2.82165 loss)
I0228 11:53:35.154844 12900 sgd_solver.cpp:138] Iteration 1580, lr = 0.0005
I0228 11:54:08.058357 12900 solver.cpp:243] Iteration 1590, loss = 2.15148
I0228 11:54:08.058545 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80805 (* 1 = 1.80805 loss)
I0228 11:54:08.058559 12900 sgd_solver.cpp:138] Iteration 1590, lr = 0.0005
I0228 11:54:34.660486 12900 solver.cpp:243] Iteration 1600, loss = 2.37165
I0228 11:54:34.660539 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.86595 (* 1 = 2.86595 loss)
I0228 11:54:34.660549 12900 sgd_solver.cpp:138] Iteration 1600, lr = 0.0005
I0228 11:55:22.539754 12900 solver.cpp:243] Iteration 1610, loss = 2.24458
I0228 11:55:22.539968 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.48826 (* 1 = 2.48826 loss)
I0228 11:55:22.539991 12900 sgd_solver.cpp:138] Iteration 1610, lr = 0.0005
I0228 11:55:51.769347 12900 solver.cpp:243] Iteration 1620, loss = 2.16908
I0228 11:55:51.769398 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.49111 (* 1 = 1.49111 loss)
I0228 11:55:51.769408 12900 sgd_solver.cpp:138] Iteration 1620, lr = 0.0005
I0228 11:57:11.210418 12900 solver.cpp:243] Iteration 1630, loss = 2.08984
I0228 11:57:11.210569 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.1825 (* 1 = 3.1825 loss)
I0228 11:57:11.210582 12900 sgd_solver.cpp:138] Iteration 1630, lr = 0.0005
I0228 11:58:28.410115 12900 solver.cpp:243] Iteration 1640, loss = 2.23429
I0228 11:58:28.410290 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.79609 (* 1 = 1.79609 loss)
I0228 11:58:28.410302 12900 sgd_solver.cpp:138] Iteration 1640, lr = 0.0005
I0228 11:58:51.345958 12900 solver.cpp:243] Iteration 1650, loss = 2.31053
I0228 11:58:51.346024 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.22801 (* 1 = 2.22801 loss)
I0228 11:58:51.346035 12900 sgd_solver.cpp:138] Iteration 1650, lr = 0.0005
I0228 11:59:19.417032 12900 solver.cpp:243] Iteration 1660, loss = 2.34765
I0228 11:59:19.417245 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.45069 (* 1 = 2.45069 loss)
I0228 11:59:19.417259 12900 sgd_solver.cpp:138] Iteration 1660, lr = 0.0005
I0228 11:59:50.669579 12900 solver.cpp:243] Iteration 1670, loss = 2.1302
I0228 11:59:50.669756 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.32822 (* 1 = 2.32822 loss)
I0228 11:59:50.669769 12900 sgd_solver.cpp:138] Iteration 1670, lr = 0.0005
I0228 12:00:23.589555 12900 solver.cpp:243] Iteration 1680, loss = 2.00125
I0228 12:00:23.589751 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.514 (* 1 = 1.514 loss)
I0228 12:00:23.589763 12900 sgd_solver.cpp:138] Iteration 1680, lr = 0.0005
I0228 12:01:00.380868 12900 solver.cpp:243] Iteration 1690, loss = 2.23007
I0228 12:01:00.381044 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.1696 (* 1 = 2.1696 loss)
I0228 12:01:00.381057 12900 sgd_solver.cpp:138] Iteration 1690, lr = 0.0005
I0228 12:01:34.461447 12900 solver.cpp:243] Iteration 1700, loss = 2.1214
I0228 12:01:34.461642 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74594 (* 1 = 1.74594 loss)
I0228 12:01:34.461657 12900 sgd_solver.cpp:138] Iteration 1700, lr = 0.0005
I0228 12:02:10.709987 12900 solver.cpp:243] Iteration 1710, loss = 2.66554
I0228 12:02:10.710147 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61402 (* 1 = 1.61402 loss)
I0228 12:02:10.710158 12900 sgd_solver.cpp:138] Iteration 1710, lr = 0.0005
I0228 12:02:37.328805 12900 solver.cpp:243] Iteration 1720, loss = 2.5506
I0228 12:02:37.328855 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.33177 (* 1 = 3.33177 loss)
I0228 12:02:37.328864 12900 sgd_solver.cpp:138] Iteration 1720, lr = 0.0005
I0228 12:04:16.206713 12900 solver.cpp:243] Iteration 1730, loss = 2.72821
I0228 12:04:16.206909 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.45942 (* 1 = 3.45942 loss)
I0228 12:04:16.206923 12900 sgd_solver.cpp:138] Iteration 1730, lr = 0.0005
I0228 12:05:49.232547 12900 solver.cpp:243] Iteration 1740, loss = 2.26547
I0228 12:05:49.232729 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41834 (* 1 = 2.41834 loss)
I0228 12:05:49.232743 12900 sgd_solver.cpp:138] Iteration 1740, lr = 0.0005
I0228 12:07:15.417255 12900 solver.cpp:243] Iteration 1750, loss = 2.14635
I0228 12:07:15.417415 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72358 (* 1 = 1.72358 loss)
I0228 12:07:15.417430 12900 sgd_solver.cpp:138] Iteration 1750, lr = 0.0005
I0228 12:07:47.068689 12900 solver.cpp:243] Iteration 1760, loss = 2.3549
I0228 12:07:47.068852 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.56187 (* 1 = 1.56187 loss)
I0228 12:07:47.068864 12900 sgd_solver.cpp:138] Iteration 1760, lr = 0.0005
I0228 12:08:18.829155 12900 solver.cpp:243] Iteration 1770, loss = 2.22386
I0228 12:08:18.829339 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.13803 (* 1 = 3.13803 loss)
I0228 12:08:18.829352 12900 sgd_solver.cpp:138] Iteration 1770, lr = 0.0005
I0228 12:08:59.704115 12900 solver.cpp:243] Iteration 1780, loss = 2.60594
I0228 12:08:59.704223 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.49185 (* 1 = 3.49185 loss)
I0228 12:08:59.704237 12900 sgd_solver.cpp:138] Iteration 1780, lr = 0.0005
I0228 12:09:30.696457 12900 solver.cpp:243] Iteration 1790, loss = 2.19893
I0228 12:09:30.696581 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.20447 (* 1 = 2.20447 loss)
I0228 12:09:30.696593 12900 sgd_solver.cpp:138] Iteration 1790, lr = 0.0005
I0228 12:10:00.395197 12900 solver.cpp:243] Iteration 1800, loss = 1.86722
I0228 12:10:00.395256 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.48306 (* 1 = 1.48306 loss)
I0228 12:10:00.395267 12900 sgd_solver.cpp:138] Iteration 1800, lr = 0.0005
I0228 12:10:30.247989 12900 solver.cpp:243] Iteration 1810, loss = 2.31273
I0228 12:10:30.248210 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.445 (* 1 = 3.445 loss)
I0228 12:10:30.248224 12900 sgd_solver.cpp:138] Iteration 1810, lr = 0.0005
I0228 12:11:01.413945 12900 solver.cpp:243] Iteration 1820, loss = 2.26502
I0228 12:11:01.414098 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38345 (* 1 = 2.38345 loss)
I0228 12:11:01.414130 12900 sgd_solver.cpp:138] Iteration 1820, lr = 0.0005
I0228 12:11:28.711339 12900 solver.cpp:243] Iteration 1830, loss = 2.0398
I0228 12:11:28.711400 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.89756 (* 1 = 1.89756 loss)
I0228 12:11:28.711410 12900 sgd_solver.cpp:138] Iteration 1830, lr = 0.0005
I0228 12:11:57.329715 12900 solver.cpp:243] Iteration 1840, loss = 2.17835
I0228 12:11:57.329933 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.06067 (* 1 = 3.06067 loss)
I0228 12:11:57.329952 12900 sgd_solver.cpp:138] Iteration 1840, lr = 0.0005
I0228 12:12:27.589843 12900 solver.cpp:243] Iteration 1850, loss = 1.99399
I0228 12:12:27.590036 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.12317 (* 1 = 1.12317 loss)
I0228 12:12:27.590050 12900 sgd_solver.cpp:138] Iteration 1850, lr = 0.0005
I0228 12:14:09.195215 12900 solver.cpp:243] Iteration 1860, loss = 2.11416
I0228 12:14:09.195389 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41043 (* 1 = 2.41043 loss)
I0228 12:14:09.195402 12900 sgd_solver.cpp:138] Iteration 1860, lr = 0.0005
I0228 12:14:47.570523 12900 solver.cpp:243] Iteration 1870, loss = 2.39948
I0228 12:14:47.570708 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.20767 (* 1 = 3.20767 loss)
I0228 12:14:47.570721 12900 sgd_solver.cpp:138] Iteration 1870, lr = 0.0005
I0228 12:16:01.877008 12900 solver.cpp:243] Iteration 1880, loss = 2.27403
I0228 12:16:01.877265 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.67283 (* 1 = 1.67283 loss)
I0228 12:16:01.877317 12900 sgd_solver.cpp:138] Iteration 1880, lr = 0.0005
I0228 12:17:36.279840 12900 solver.cpp:243] Iteration 1890, loss = 2.13911
I0228 12:17:36.280026 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07655 (* 1 = 2.07655 loss)
I0228 12:17:36.280040 12900 sgd_solver.cpp:138] Iteration 1890, lr = 0.0005
I0228 12:18:12.696817 12900 solver.cpp:243] Iteration 1900, loss = 1.98513
I0228 12:18:12.696996 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.11894 (* 1 = 2.11894 loss)
I0228 12:18:12.697011 12900 sgd_solver.cpp:138] Iteration 1900, lr = 0.0005
I0228 12:18:47.790756 12900 solver.cpp:243] Iteration 1910, loss = 2.3571
I0228 12:18:47.790916 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.39416 (* 1 = 2.39416 loss)
I0228 12:18:47.790936 12900 sgd_solver.cpp:138] Iteration 1910, lr = 0.0005
I0228 12:20:45.684662 12900 solver.cpp:243] Iteration 1920, loss = 2.23587
I0228 12:20:45.684847 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.48813 (* 1 = 2.48813 loss)
I0228 12:20:45.684864 12900 sgd_solver.cpp:138] Iteration 1920, lr = 0.0005
I0228 12:21:21.468859 12900 solver.cpp:243] Iteration 1930, loss = 2.0548
I0228 12:21:21.469007 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.3585 (* 1 = 2.3585 loss)
I0228 12:21:21.469019 12900 sgd_solver.cpp:138] Iteration 1930, lr = 0.0005
I0228 12:22:44.504434 12900 solver.cpp:243] Iteration 1940, loss = 2.19776
I0228 12:22:44.504575 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00145 (* 1 = 2.00145 loss)
I0228 12:22:44.504590 12900 sgd_solver.cpp:138] Iteration 1940, lr = 0.0005
I0228 12:24:29.942016 12900 solver.cpp:243] Iteration 1950, loss = 2.19371
I0228 12:24:29.942188 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.88242 (* 1 = 2.88242 loss)
I0228 12:24:29.942200 12900 sgd_solver.cpp:138] Iteration 1950, lr = 0.0005
I0228 12:25:02.687227 12900 solver.cpp:243] Iteration 1960, loss = 2.10819
I0228 12:25:02.687409 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.13675 (* 1 = 2.13675 loss)
I0228 12:25:02.687422 12900 sgd_solver.cpp:138] Iteration 1960, lr = 0.0005
I0228 12:25:36.027190 12900 solver.cpp:243] Iteration 1970, loss = 2.1582
I0228 12:25:36.027336 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.52918 (* 1 = 1.52918 loss)
I0228 12:25:36.027349 12900 sgd_solver.cpp:138] Iteration 1970, lr = 0.0005
I0228 12:26:05.391391 12900 solver.cpp:243] Iteration 1980, loss = 2.07989
I0228 12:26:05.391453 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.12991 (* 1 = 2.12991 loss)
I0228 12:26:05.391465 12900 sgd_solver.cpp:138] Iteration 1980, lr = 0.0005
I0228 12:26:31.494081 12900 solver.cpp:243] Iteration 1990, loss = 2.52834
I0228 12:26:31.494246 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.65611 (* 1 = 1.65611 loss)
I0228 12:26:31.494258 12900 sgd_solver.cpp:138] Iteration 1990, lr = 0.0005
I0228 12:27:01.045969 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_2000.caffemodel
I0228 12:27:01.112911 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_2000.solverstate
I0228 12:27:03.295953 12900 solver.cpp:243] Iteration 2000, loss = 2.15949
I0228 12:27:03.296188 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.20019 (* 1 = 2.20019 loss)
I0228 12:27:03.296205 12900 sgd_solver.cpp:138] Iteration 2000, lr = 0.0005
I0228 12:27:28.672462 12900 solver.cpp:243] Iteration 2010, loss = 1.7685
I0228 12:27:28.672520 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.16098 (* 1 = 2.16098 loss)
I0228 12:27:28.672533 12900 sgd_solver.cpp:138] Iteration 2010, lr = 0.0005
I0228 12:27:55.408211 12900 solver.cpp:243] Iteration 2020, loss = 2.04787
I0228 12:27:55.408427 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.65316 (* 1 = 2.65316 loss)
I0228 12:27:55.408464 12900 sgd_solver.cpp:138] Iteration 2020, lr = 0.0005
I0228 12:28:23.705286 12900 solver.cpp:243] Iteration 2030, loss = 2.40474
I0228 12:28:23.705353 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.34497 (* 1 = 1.34497 loss)
I0228 12:28:23.705364 12900 sgd_solver.cpp:138] Iteration 2030, lr = 0.0005
I0228 12:29:01.947891 12900 solver.cpp:243] Iteration 2040, loss = 2.14017
I0228 12:29:01.948084 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41989 (* 1 = 2.41989 loss)
I0228 12:29:01.948118 12900 sgd_solver.cpp:138] Iteration 2040, lr = 0.0005
I0228 12:31:58.795416 12900 solver.cpp:243] Iteration 2050, loss = 2.0228
I0228 12:31:58.795567 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.20612 (* 1 = 2.20612 loss)
I0228 12:31:58.795581 12900 sgd_solver.cpp:138] Iteration 2050, lr = 0.0005
I0228 12:33:06.279850 12900 solver.cpp:243] Iteration 2060, loss = 1.93252
I0228 12:33:06.280055 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.03938 (* 1 = 2.03938 loss)
I0228 12:33:06.280068 12900 sgd_solver.cpp:138] Iteration 2060, lr = 0.0005
I0228 12:34:18.021980 12900 solver.cpp:243] Iteration 2070, loss = 2.11932
I0228 12:34:18.022179 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.01175 (* 1 = 2.01175 loss)
I0228 12:34:18.022195 12900 sgd_solver.cpp:138] Iteration 2070, lr = 0.0005
I0228 12:35:04.909945 12900 solver.cpp:243] Iteration 2080, loss = 2.2581
I0228 12:35:04.910138 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.85155 (* 1 = 1.85155 loss)
I0228 12:35:04.910154 12900 sgd_solver.cpp:138] Iteration 2080, lr = 0.0005
I0228 12:36:43.709841 12900 solver.cpp:243] Iteration 2090, loss = 2.02386
I0228 12:36:43.709955 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.35759 (* 1 = 1.35759 loss)
I0228 12:36:43.709969 12900 sgd_solver.cpp:138] Iteration 2090, lr = 0.0005
I0228 12:37:16.573740 12900 solver.cpp:243] Iteration 2100, loss = 2.24808
I0228 12:37:16.573901 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.67024 (* 1 = 2.67024 loss)
I0228 12:37:16.573915 12900 sgd_solver.cpp:138] Iteration 2100, lr = 0.0005
I0228 12:38:27.221500 12900 solver.cpp:243] Iteration 2110, loss = 2.00061
I0228 12:38:27.221740 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.5489 (* 1 = 1.5489 loss)
I0228 12:38:27.221755 12900 sgd_solver.cpp:138] Iteration 2110, lr = 0.0005
I0228 12:39:14.626505 12900 solver.cpp:243] Iteration 2120, loss = 2.06295
I0228 12:39:14.626688 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.02845 (* 1 = 2.02845 loss)
I0228 12:39:14.626701 12900 sgd_solver.cpp:138] Iteration 2120, lr = 0.0005
I0228 12:40:49.959208 12900 solver.cpp:243] Iteration 2130, loss = 2.01888
I0228 12:40:49.959396 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.2174 (* 1 = 2.2174 loss)
I0228 12:40:49.959410 12900 sgd_solver.cpp:138] Iteration 2130, lr = 0.0005
I0228 12:41:25.186120 12900 solver.cpp:243] Iteration 2140, loss = 2.11244
I0228 12:41:25.186349 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75159 (* 1 = 1.75159 loss)
I0228 12:41:25.186380 12900 sgd_solver.cpp:138] Iteration 2140, lr = 0.0005
I0228 12:42:51.139061 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 12:42:53.484580 12900 solver.cpp:243] Iteration 2150, loss = 2.23555
I0228 12:42:53.484635 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72982 (* 1 = 1.72982 loss)
I0228 12:42:53.484645 12900 sgd_solver.cpp:138] Iteration 2150, lr = 0.0005
I0228 12:43:35.789223 12900 solver.cpp:243] Iteration 2160, loss = 2.08354
I0228 12:43:35.789371 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.44048 (* 1 = 2.44048 loss)
I0228 12:43:35.789384 12900 sgd_solver.cpp:138] Iteration 2160, lr = 0.0005
I0228 12:44:11.177155 12900 solver.cpp:243] Iteration 2170, loss = 2.07603
I0228 12:44:11.177330 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.25022 (* 1 = 1.25022 loss)
I0228 12:44:11.177345 12900 sgd_solver.cpp:138] Iteration 2170, lr = 0.0005
I0228 12:44:43.440824 12900 solver.cpp:243] Iteration 2180, loss = 2.74176
I0228 12:44:43.441027 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.05275 (* 1 = 2.05275 loss)
I0228 12:44:43.441042 12900 sgd_solver.cpp:138] Iteration 2180, lr = 0.0005
I0228 12:45:11.755333 12900 solver.cpp:243] Iteration 2190, loss = 2.08349
I0228 12:45:11.755467 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.55036 (* 1 = 1.55036 loss)
I0228 12:45:11.755508 12900 sgd_solver.cpp:138] Iteration 2190, lr = 0.0005
I0228 12:45:53.222437 12900 solver.cpp:243] Iteration 2200, loss = 2.23456
I0228 12:45:53.222585 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.355 (* 1 = 2.355 loss)
I0228 12:45:53.222599 12900 sgd_solver.cpp:138] Iteration 2200, lr = 0.0005
I0228 12:46:24.929121 12900 solver.cpp:243] Iteration 2210, loss = 2.1237
I0228 12:46:24.929307 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.99035 (* 1 = 1.99035 loss)
I0228 12:46:24.929322 12900 sgd_solver.cpp:138] Iteration 2210, lr = 0.0005
I0228 12:47:51.007421 12900 solver.cpp:243] Iteration 2220, loss = 2.09849
I0228 12:47:51.007601 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.57856 (* 1 = 1.57856 loss)
I0228 12:47:51.007616 12900 sgd_solver.cpp:138] Iteration 2220, lr = 0.0005
I0228 12:49:11.818212 12900 solver.cpp:243] Iteration 2230, loss = 2.11486
I0228 12:49:11.818387 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.81369 (* 1 = 1.81369 loss)
I0228 12:49:11.818398 12900 sgd_solver.cpp:138] Iteration 2230, lr = 0.0005
I0228 12:50:13.574072 12900 solver.cpp:243] Iteration 2240, loss = 2.13873
I0228 12:50:13.574229 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.85653 (* 1 = 1.85653 loss)
I0228 12:50:13.574241 12900 sgd_solver.cpp:138] Iteration 2240, lr = 0.0005
I0228 12:52:42.125785 12900 solver.cpp:243] Iteration 2250, loss = 2.15808
I0228 12:52:42.125952 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.22628 (* 1 = 2.22628 loss)
I0228 12:52:42.125965 12900 sgd_solver.cpp:138] Iteration 2250, lr = 0.0005
I0228 12:54:05.795125 12900 solver.cpp:243] Iteration 2260, loss = 2.13741
I0228 12:54:05.795313 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47947 (* 1 = 1.47947 loss)
I0228 12:54:05.795327 12900 sgd_solver.cpp:138] Iteration 2260, lr = 0.0005
I0228 12:54:56.276290 12900 solver.cpp:243] Iteration 2270, loss = 2.08648
I0228 12:54:56.276494 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.0657 (* 1 = 2.0657 loss)
I0228 12:54:56.276510 12900 sgd_solver.cpp:138] Iteration 2270, lr = 0.0005
I0228 12:56:28.787133 12900 solver.cpp:243] Iteration 2280, loss = 2.18095
I0228 12:56:28.787308 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.24287 (* 1 = 3.24287 loss)
I0228 12:56:28.787322 12900 sgd_solver.cpp:138] Iteration 2280, lr = 0.0005
I0228 12:57:45.057538 12900 solver.cpp:243] Iteration 2290, loss = 2.21661
I0228 12:57:45.057683 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.88998 (* 1 = 1.88998 loss)
I0228 12:57:45.057698 12900 sgd_solver.cpp:138] Iteration 2290, lr = 0.0005
I0228 12:59:12.591939 12900 solver.cpp:243] Iteration 2300, loss = 2.07003
I0228 12:59:12.592110 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.93876 (* 1 = 1.93876 loss)
I0228 12:59:12.592125 12900 sgd_solver.cpp:138] Iteration 2300, lr = 0.0005
I0228 12:59:37.602903 12900 solver.cpp:243] Iteration 2310, loss = 2.17211
I0228 12:59:37.602967 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.71361 (* 1 = 1.71361 loss)
I0228 12:59:37.602978 12900 sgd_solver.cpp:138] Iteration 2310, lr = 0.0005
I0228 13:00:05.890847 12900 solver.cpp:243] Iteration 2320, loss = 2.11505
I0228 13:00:05.891023 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00154 (* 1 = 2.00154 loss)
I0228 13:00:05.891036 12900 sgd_solver.cpp:138] Iteration 2320, lr = 0.0005
I0228 13:00:33.522593 12900 solver.cpp:243] Iteration 2330, loss = 2.07417
I0228 13:00:33.522649 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.7123 (* 1 = 1.7123 loss)
I0228 13:00:33.522660 12900 sgd_solver.cpp:138] Iteration 2330, lr = 0.0005
I0228 13:01:08.589310 12900 solver.cpp:243] Iteration 2340, loss = 2.26855
I0228 13:01:08.589464 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.16361 (* 1 = 2.16361 loss)
I0228 13:01:08.589478 12900 sgd_solver.cpp:138] Iteration 2340, lr = 0.0005
I0228 13:01:37.436604 12900 solver.cpp:243] Iteration 2350, loss = 2.14859
I0228 13:01:37.436669 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96191 (* 1 = 1.96191 loss)
I0228 13:01:37.436681 12900 sgd_solver.cpp:138] Iteration 2350, lr = 0.0005
I0228 13:03:00.992916 12900 solver.cpp:243] Iteration 2360, loss = 1.88252
I0228 13:03:00.993274 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.58229 (* 1 = 1.58229 loss)
I0228 13:03:00.993343 12900 sgd_solver.cpp:138] Iteration 2360, lr = 0.0005
I0228 13:04:08.345338 12900 solver.cpp:243] Iteration 2370, loss = 2.23155
I0228 13:04:08.345522 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.25614 (* 1 = 1.25614 loss)
I0228 13:04:08.345536 12900 sgd_solver.cpp:138] Iteration 2370, lr = 0.0005
I0228 13:04:43.664829 12900 solver.cpp:243] Iteration 2380, loss = 2.03719
I0228 13:04:43.664999 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.76203 (* 1 = 1.76203 loss)
I0228 13:04:43.665012 12900 sgd_solver.cpp:138] Iteration 2380, lr = 0.0005
I0228 13:07:05.754526 12900 solver.cpp:243] Iteration 2390, loss = 2.40925
I0228 13:07:05.754688 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.32715 (* 1 = 1.32715 loss)
I0228 13:07:05.754701 12900 sgd_solver.cpp:138] Iteration 2390, lr = 0.0005
I0228 13:07:40.368942 12900 solver.cpp:243] Iteration 2400, loss = 1.84465
I0228 13:07:40.369164 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.84738 (* 1 = 1.84738 loss)
I0228 13:07:40.369207 12900 sgd_solver.cpp:138] Iteration 2400, lr = 0.0005
I0228 13:08:57.502413 12900 solver.cpp:243] Iteration 2410, loss = 2.2017
I0228 13:08:57.502583 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.15508 (* 1 = 3.15508 loss)
I0228 13:08:57.502601 12900 sgd_solver.cpp:138] Iteration 2410, lr = 0.0005
I0228 13:09:59.183105 12900 solver.cpp:243] Iteration 2420, loss = 2.22125
I0228 13:09:59.183279 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.30696 (* 1 = 2.30696 loss)
I0228 13:09:59.183291 12900 sgd_solver.cpp:138] Iteration 2420, lr = 0.0005
I0228 13:11:06.482204 12900 solver.cpp:243] Iteration 2430, loss = 1.93154
I0228 13:11:06.482394 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.61148 (* 1 = 2.61148 loss)
I0228 13:11:06.482406 12900 sgd_solver.cpp:138] Iteration 2430, lr = 0.0005
I0228 13:11:36.884649 12900 solver.cpp:243] Iteration 2440, loss = 2.29128
I0228 13:11:36.884848 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.83001 (* 1 = 1.83001 loss)
I0228 13:11:36.884861 12900 sgd_solver.cpp:138] Iteration 2440, lr = 0.0005
I0228 13:12:06.079504 12900 solver.cpp:243] Iteration 2450, loss = 1.97089
I0228 13:12:06.079562 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.84489 (* 1 = 1.84489 loss)
I0228 13:12:06.079573 12900 sgd_solver.cpp:138] Iteration 2450, lr = 0.0005
I0228 13:13:16.091045 12900 solver.cpp:243] Iteration 2460, loss = 2.03467
I0228 13:13:16.091217 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.21394 (* 1 = 3.21394 loss)
I0228 13:13:16.091228 12900 sgd_solver.cpp:138] Iteration 2460, lr = 0.0005
I0228 13:14:06.408758 12900 solver.cpp:243] Iteration 2470, loss = 2.37388
I0228 13:14:06.408910 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47606 (* 1 = 1.47606 loss)
I0228 13:14:06.408922 12900 sgd_solver.cpp:138] Iteration 2470, lr = 0.0005
I0228 13:14:42.194458 12900 solver.cpp:243] Iteration 2480, loss = 1.86129
I0228 13:14:42.194648 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.65741 (* 1 = 1.65741 loss)
I0228 13:14:42.194661 12900 sgd_solver.cpp:138] Iteration 2480, lr = 0.0005
I0228 13:15:39.556802 12900 solver.cpp:243] Iteration 2490, loss = 1.90357
I0228 13:15:39.556967 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07822 (* 1 = 2.07822 loss)
I0228 13:15:39.556982 12900 sgd_solver.cpp:138] Iteration 2490, lr = 0.0005
I0228 13:16:10.202359 12900 solver.cpp:243] Iteration 2500, loss = 2.10119
I0228 13:16:10.202548 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41711 (* 1 = 2.41711 loss)
I0228 13:16:10.202561 12900 sgd_solver.cpp:138] Iteration 2500, lr = 0.0005
I0228 13:16:38.918069 12900 solver.cpp:243] Iteration 2510, loss = 2.20326
I0228 13:16:38.918123 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.54913 (* 1 = 1.54913 loss)
I0228 13:16:38.918133 12900 sgd_solver.cpp:138] Iteration 2510, lr = 0.0005
I0228 13:17:09.060688 12900 solver.cpp:243] Iteration 2520, loss = 2.01982
I0228 13:17:09.060850 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.47917 (* 1 = 2.47917 loss)
I0228 13:17:09.060863 12900 sgd_solver.cpp:138] Iteration 2520, lr = 0.0005
I0228 13:17:39.006109 12900 solver.cpp:243] Iteration 2530, loss = 1.78369
I0228 13:17:39.006155 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74186 (* 1 = 1.74186 loss)
I0228 13:17:39.006166 12900 sgd_solver.cpp:138] Iteration 2530, lr = 0.0005
I0228 13:18:27.061204 12900 solver.cpp:243] Iteration 2540, loss = 1.84217
I0228 13:18:27.061446 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.18122 (* 1 = 2.18122 loss)
I0228 13:18:27.061517 12900 sgd_solver.cpp:138] Iteration 2540, lr = 0.0005
I0228 13:19:35.285832 12900 solver.cpp:243] Iteration 2550, loss = 1.90398
I0228 13:19:35.286088 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74697 (* 1 = 1.74697 loss)
I0228 13:19:35.286126 12900 sgd_solver.cpp:138] Iteration 2550, lr = 0.0005
I0228 13:20:23.148808 12900 solver.cpp:243] Iteration 2560, loss = 2.12865
I0228 13:20:23.148957 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94546 (* 1 = 1.94546 loss)
I0228 13:20:23.148970 12900 sgd_solver.cpp:138] Iteration 2560, lr = 0.0005
I0228 13:21:09.399806 12900 solver.cpp:243] Iteration 2570, loss = 2.27585
I0228 13:21:09.399971 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.14553 (* 1 = 2.14553 loss)
I0228 13:21:09.399986 12900 sgd_solver.cpp:138] Iteration 2570, lr = 0.0005
I0228 13:21:58.218899 12900 solver.cpp:243] Iteration 2580, loss = 2.13597
I0228 13:21:58.219041 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38265 (* 1 = 2.38265 loss)
I0228 13:21:58.219054 12900 sgd_solver.cpp:138] Iteration 2580, lr = 0.0005
I0228 13:22:49.046478 12900 solver.cpp:243] Iteration 2590, loss = 1.85728
I0228 13:22:49.046615 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.57933 (* 1 = 1.57933 loss)
I0228 13:22:49.046627 12900 sgd_solver.cpp:138] Iteration 2590, lr = 0.0005
I0228 13:23:50.465541 12900 solver.cpp:243] Iteration 2600, loss = 2.1186
I0228 13:23:50.465765 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78128 (* 1 = 1.78128 loss)
I0228 13:23:50.465792 12900 sgd_solver.cpp:138] Iteration 2600, lr = 0.0005
I0228 13:24:30.672201 12900 solver.cpp:243] Iteration 2610, loss = 2.26065
I0228 13:24:30.672477 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.10585 (* 1 = 2.10585 loss)
I0228 13:24:30.672505 12900 sgd_solver.cpp:138] Iteration 2610, lr = 0.0005
I0228 13:25:14.872419 12900 solver.cpp:243] Iteration 2620, loss = 2.05611
I0228 13:25:14.872671 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.92319 (* 1 = 1.92319 loss)
I0228 13:25:14.872702 12900 sgd_solver.cpp:138] Iteration 2620, lr = 0.0005
I0228 13:26:15.920404 12900 solver.cpp:243] Iteration 2630, loss = 2.1514
I0228 13:26:15.920573 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.82241 (* 1 = 2.82241 loss)
I0228 13:26:15.920588 12900 sgd_solver.cpp:138] Iteration 2630, lr = 0.0005
I0228 13:26:51.228483 12900 solver.cpp:243] Iteration 2640, loss = 2.01441
I0228 13:26:51.228658 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.84101 (* 1 = 1.84101 loss)
I0228 13:26:51.228672 12900 sgd_solver.cpp:138] Iteration 2640, lr = 0.0005
I0228 13:27:40.543431 12900 solver.cpp:243] Iteration 2650, loss = 2.15147
I0228 13:27:40.543591 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.70046 (* 1 = 2.70046 loss)
I0228 13:27:40.543606 12900 sgd_solver.cpp:138] Iteration 2650, lr = 0.0005
I0228 13:28:23.506913 12900 solver.cpp:243] Iteration 2660, loss = 2.11682
I0228 13:28:23.507169 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.64835 (* 1 = 2.64835 loss)
I0228 13:28:23.507215 12900 sgd_solver.cpp:138] Iteration 2660, lr = 0.0005
I0228 13:30:01.788704 12900 solver.cpp:243] Iteration 2670, loss = 2.09753
I0228 13:30:01.788830 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47153 (* 1 = 1.47153 loss)
I0228 13:30:01.788841 12900 sgd_solver.cpp:138] Iteration 2670, lr = 0.0005
I0228 13:30:34.960957 12900 solver.cpp:243] Iteration 2680, loss = 1.88454
I0228 13:30:34.961087 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72562 (* 1 = 1.72562 loss)
I0228 13:30:34.961102 12900 sgd_solver.cpp:138] Iteration 2680, lr = 0.0005
I0228 13:31:02.521787 12900 solver.cpp:243] Iteration 2690, loss = 2.05419
I0228 13:31:02.521847 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.21221 (* 1 = 2.21221 loss)
I0228 13:31:02.521858 12900 sgd_solver.cpp:138] Iteration 2690, lr = 0.0005
I0228 13:31:33.291286 12900 solver.cpp:243] Iteration 2700, loss = 1.84096
I0228 13:31:33.291445 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.98539 (* 1 = 1.98539 loss)
I0228 13:31:33.291458 12900 sgd_solver.cpp:138] Iteration 2700, lr = 0.0005
I0228 13:32:02.599558 12900 solver.cpp:243] Iteration 2710, loss = 1.86588
I0228 13:32:02.599615 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.19845 (* 1 = 1.19845 loss)
I0228 13:32:02.599627 12900 sgd_solver.cpp:138] Iteration 2710, lr = 0.0005
I0228 13:32:31.285451 12900 solver.cpp:243] Iteration 2720, loss = 2.11526
I0228 13:32:31.285635 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41493 (* 1 = 2.41493 loss)
I0228 13:32:31.285650 12900 sgd_solver.cpp:138] Iteration 2720, lr = 0.0005
I0228 13:33:05.631657 12900 solver.cpp:243] Iteration 2730, loss = 1.91259
I0228 13:33:05.631866 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.81421 (* 1 = 1.81421 loss)
I0228 13:33:05.631880 12900 sgd_solver.cpp:138] Iteration 2730, lr = 0.0005
I0228 13:33:32.919348 12900 solver.cpp:243] Iteration 2740, loss = 1.90187
I0228 13:33:32.919415 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.52124 (* 1 = 2.52124 loss)
I0228 13:33:32.919430 12900 sgd_solver.cpp:138] Iteration 2740, lr = 0.0005
I0228 13:34:02.382400 12900 solver.cpp:243] Iteration 2750, loss = 2.06719
I0228 13:34:02.382576 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.19342 (* 1 = 2.19342 loss)
I0228 13:34:02.382592 12900 sgd_solver.cpp:138] Iteration 2750, lr = 0.0005
I0228 13:34:31.820806 12900 solver.cpp:243] Iteration 2760, loss = 1.90907
I0228 13:34:31.820868 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.29603 (* 1 = 1.29603 loss)
I0228 13:34:31.820879 12900 sgd_solver.cpp:138] Iteration 2760, lr = 0.0005
I0228 13:35:04.394984 12900 solver.cpp:243] Iteration 2770, loss = 2.31788
I0228 13:35:04.395128 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9976 (* 1 = 1.9976 loss)
I0228 13:35:04.395143 12900 sgd_solver.cpp:138] Iteration 2770, lr = 0.0005
I0228 13:35:38.388902 12900 solver.cpp:243] Iteration 2780, loss = 2.17215
I0228 13:35:38.389070 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.44358 (* 1 = 2.44358 loss)
I0228 13:35:38.389082 12900 sgd_solver.cpp:138] Iteration 2780, lr = 0.0005
I0228 13:36:10.353034 12900 solver.cpp:243] Iteration 2790, loss = 1.86427
I0228 13:36:10.353169 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.81509 (* 1 = 1.81509 loss)
I0228 13:36:10.353183 12900 sgd_solver.cpp:138] Iteration 2790, lr = 0.0005
I0228 13:36:37.483089 12900 solver.cpp:243] Iteration 2800, loss = 1.94345
I0228 13:36:37.483141 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.83362 (* 1 = 1.83362 loss)
I0228 13:36:37.483151 12900 sgd_solver.cpp:138] Iteration 2800, lr = 0.0005
I0228 13:37:08.127771 12900 solver.cpp:243] Iteration 2810, loss = 1.95797
I0228 13:37:08.127918 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07348 (* 1 = 2.07348 loss)
I0228 13:37:08.127930 12900 sgd_solver.cpp:138] Iteration 2810, lr = 0.0005
I0228 13:37:35.551636 12900 solver.cpp:243] Iteration 2820, loss = 2.15886
I0228 13:37:35.551693 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80194 (* 1 = 1.80194 loss)
I0228 13:37:35.551703 12900 sgd_solver.cpp:138] Iteration 2820, lr = 0.0005
I0228 13:38:05.785737 12900 solver.cpp:243] Iteration 2830, loss = 2.01087
I0228 13:38:05.785915 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.84611 (* 1 = 1.84611 loss)
I0228 13:38:05.785933 12900 sgd_solver.cpp:138] Iteration 2830, lr = 0.0005
I0228 13:38:38.385643 12900 solver.cpp:243] Iteration 2840, loss = 1.71508
I0228 13:38:38.385823 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.22136 (* 1 = 2.22136 loss)
I0228 13:38:38.385836 12900 sgd_solver.cpp:138] Iteration 2840, lr = 0.0005
I0228 13:39:09.225944 12900 solver.cpp:243] Iteration 2850, loss = 2.48545
I0228 13:39:09.226068 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41309 (* 1 = 2.41309 loss)
I0228 13:39:09.226081 12900 sgd_solver.cpp:138] Iteration 2850, lr = 0.0005
I0228 13:39:40.186259 12900 solver.cpp:243] Iteration 2860, loss = 2.30915
I0228 13:39:40.186419 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.66388 (* 1 = 2.66388 loss)
I0228 13:39:40.186432 12900 sgd_solver.cpp:138] Iteration 2860, lr = 0.0005
I0228 13:40:11.839849 12900 solver.cpp:243] Iteration 2870, loss = 1.92096
I0228 13:40:11.840067 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.38888 (* 1 = 1.38888 loss)
I0228 13:40:11.840080 12900 sgd_solver.cpp:138] Iteration 2870, lr = 0.0005
I0228 13:40:42.679520 12900 solver.cpp:243] Iteration 2880, loss = 2.04782
I0228 13:40:42.679674 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.83225 (* 1 = 1.83225 loss)
I0228 13:40:42.679687 12900 sgd_solver.cpp:138] Iteration 2880, lr = 0.0005
I0228 13:41:16.241817 12900 solver.cpp:243] Iteration 2890, loss = 1.88831
I0228 13:41:16.241991 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.506 (* 1 = 2.506 loss)
I0228 13:41:16.242004 12900 sgd_solver.cpp:138] Iteration 2890, lr = 0.0005
I0228 13:41:50.833488 12900 solver.cpp:243] Iteration 2900, loss = 2.24219
I0228 13:41:50.833655 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.25138 (* 1 = 1.25138 loss)
I0228 13:41:50.833667 12900 sgd_solver.cpp:138] Iteration 2900, lr = 0.0005
I0228 13:42:20.756019 12900 solver.cpp:243] Iteration 2910, loss = 2.05219
I0228 13:42:20.756070 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94479 (* 1 = 1.94479 loss)
I0228 13:42:20.756081 12900 sgd_solver.cpp:138] Iteration 2910, lr = 0.0005
I0228 13:42:53.689302 12900 solver.cpp:243] Iteration 2920, loss = 1.78115
I0228 13:42:53.689450 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.13836 (* 1 = 1.13836 loss)
I0228 13:42:53.689462 12900 sgd_solver.cpp:138] Iteration 2920, lr = 0.0005
I0228 13:43:19.815282 12900 solver.cpp:243] Iteration 2930, loss = 2.04894
I0228 13:43:19.815346 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.20621 (* 1 = 2.20621 loss)
I0228 13:43:19.815356 12900 sgd_solver.cpp:138] Iteration 2930, lr = 0.0005
I0228 13:43:53.156886 12900 solver.cpp:243] Iteration 2940, loss = 1.94668
I0228 13:43:53.157097 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.70936 (* 1 = 1.70936 loss)
I0228 13:43:53.157137 12900 sgd_solver.cpp:138] Iteration 2940, lr = 0.0005
I0228 13:44:27.269549 12900 solver.cpp:243] Iteration 2950, loss = 2.35297
I0228 13:44:27.269704 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72679 (* 1 = 1.72679 loss)
I0228 13:44:27.269717 12900 sgd_solver.cpp:138] Iteration 2950, lr = 0.0005
I0228 13:44:57.085191 12900 solver.cpp:243] Iteration 2960, loss = 2.15281
I0228 13:44:57.085265 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.29079 (* 1 = 2.29079 loss)
I0228 13:44:57.085280 12900 sgd_solver.cpp:138] Iteration 2960, lr = 0.0005
I0228 13:45:25.997541 12900 solver.cpp:243] Iteration 2970, loss = 2.04483
I0228 13:45:25.997678 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.85625 (* 1 = 1.85625 loss)
I0228 13:45:25.997692 12900 sgd_solver.cpp:138] Iteration 2970, lr = 0.0005
I0228 13:45:57.727602 12900 solver.cpp:243] Iteration 2980, loss = 2.12864
I0228 13:45:57.727743 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.82425 (* 1 = 1.82425 loss)
I0228 13:45:57.727754 12900 sgd_solver.cpp:138] Iteration 2980, lr = 0.0005
I0228 13:46:29.879336 12900 solver.cpp:243] Iteration 2990, loss = 1.63944
I0228 13:46:29.879520 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.16477 (* 1 = 1.16477 loss)
I0228 13:46:29.879532 12900 sgd_solver.cpp:138] Iteration 2990, lr = 0.0005
I0228 13:46:56.238492 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_3000.caffemodel
I0228 13:46:56.308519 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_3000.solverstate
I0228 13:46:58.871285 12900 solver.cpp:243] Iteration 3000, loss = 2.29705
I0228 13:46:58.871347 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.71397 (* 1 = 2.71397 loss)
I0228 13:46:58.871358 12900 sgd_solver.cpp:138] Iteration 3000, lr = 0.0005
I0228 13:47:25.434335 12900 solver.cpp:243] Iteration 3010, loss = 2.05352
I0228 13:47:25.434509 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.39964 (* 1 = 2.39964 loss)
I0228 13:47:25.434521 12900 sgd_solver.cpp:138] Iteration 3010, lr = 0.0005
I0228 13:47:58.375226 12900 solver.cpp:243] Iteration 3020, loss = 1.78511
I0228 13:47:58.375413 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.97383 (* 1 = 1.97383 loss)
I0228 13:47:58.375427 12900 sgd_solver.cpp:138] Iteration 3020, lr = 0.0005
I0228 13:48:24.671591 12900 solver.cpp:243] Iteration 3030, loss = 1.94859
I0228 13:48:24.671648 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.77111 (* 1 = 1.77111 loss)
I0228 13:48:24.671660 12900 sgd_solver.cpp:138] Iteration 3030, lr = 0.0005
I0228 13:49:00.179270 12900 solver.cpp:243] Iteration 3040, loss = 2.00424
I0228 13:49:00.179481 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.58292 (* 1 = 2.58292 loss)
I0228 13:49:00.179504 12900 sgd_solver.cpp:138] Iteration 3040, lr = 0.0005
I0228 13:49:31.172405 12900 solver.cpp:243] Iteration 3050, loss = 2.47434
I0228 13:49:31.172598 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.42277 (* 1 = 2.42277 loss)
I0228 13:49:31.172611 12900 sgd_solver.cpp:138] Iteration 3050, lr = 0.0005
I0228 13:49:56.385210 12900 solver.cpp:243] Iteration 3060, loss = 2.06357
I0228 13:49:56.385267 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.79872 (* 1 = 1.79872 loss)
I0228 13:49:56.385277 12900 sgd_solver.cpp:138] Iteration 3060, lr = 0.0005
I0228 13:50:23.786494 12900 solver.cpp:243] Iteration 3070, loss = 2.11141
I0228 13:50:23.786635 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.6475 (* 1 = 2.6475 loss)
I0228 13:50:23.786649 12900 sgd_solver.cpp:138] Iteration 3070, lr = 0.0005
I0228 13:50:49.904634 12900 solver.cpp:243] Iteration 3080, loss = 1.96703
I0228 13:50:49.904700 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72233 (* 1 = 1.72233 loss)
I0228 13:50:49.904711 12900 sgd_solver.cpp:138] Iteration 3080, lr = 0.0005
I0228 13:51:21.976977 12900 solver.cpp:243] Iteration 3090, loss = 1.68821
I0228 13:51:21.977114 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74419 (* 1 = 1.74419 loss)
I0228 13:51:21.977128 12900 sgd_solver.cpp:138] Iteration 3090, lr = 0.0005
I0228 13:51:53.598124 12900 solver.cpp:243] Iteration 3100, loss = 1.90397
I0228 13:51:53.598371 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.56677 (* 1 = 1.56677 loss)
I0228 13:51:53.598407 12900 sgd_solver.cpp:138] Iteration 3100, lr = 0.0005
I0228 13:52:20.993033 12900 solver.cpp:243] Iteration 3110, loss = 2.0493
I0228 13:52:20.993093 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91565 (* 1 = 1.91565 loss)
I0228 13:52:20.993104 12900 sgd_solver.cpp:138] Iteration 3110, lr = 0.0005
I0228 13:52:52.235203 12900 solver.cpp:243] Iteration 3120, loss = 1.97117
I0228 13:52:52.236553 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.24847 (* 1 = 1.24847 loss)
I0228 13:52:52.236590 12900 sgd_solver.cpp:138] Iteration 3120, lr = 0.0005
I0228 13:53:24.330229 12900 solver.cpp:243] Iteration 3130, loss = 2.14241
I0228 13:53:24.330417 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.02634 (* 1 = 2.02634 loss)
I0228 13:53:24.330430 12900 sgd_solver.cpp:138] Iteration 3130, lr = 0.0005
I0228 13:53:52.860374 12900 solver.cpp:243] Iteration 3140, loss = 2.15066
I0228 13:53:52.860430 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.2999 (* 1 = 1.2999 loss)
I0228 13:53:52.860440 12900 sgd_solver.cpp:138] Iteration 3140, lr = 0.0005
I0228 13:54:28.517671 12900 solver.cpp:243] Iteration 3150, loss = 2.16322
I0228 13:54:28.517848 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.15536 (* 1 = 2.15536 loss)
I0228 13:54:28.517861 12900 sgd_solver.cpp:138] Iteration 3150, lr = 0.0005
I0228 13:54:56.638340 12900 solver.cpp:243] Iteration 3160, loss = 1.83111
I0228 13:54:56.638396 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80792 (* 1 = 1.80792 loss)
I0228 13:54:56.638406 12900 sgd_solver.cpp:138] Iteration 3160, lr = 0.0005
I0228 13:55:33.761415 12900 solver.cpp:243] Iteration 3170, loss = 2.0037
I0228 13:55:33.761571 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72215 (* 1 = 1.72215 loss)
I0228 13:55:33.761584 12900 sgd_solver.cpp:138] Iteration 3170, lr = 0.0005
I0228 13:56:06.151993 12900 solver.cpp:243] Iteration 3180, loss = 2.09884
I0228 13:56:06.152127 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00463 (* 1 = 2.00463 loss)
I0228 13:56:06.152140 12900 sgd_solver.cpp:138] Iteration 3180, lr = 0.0005
I0228 13:56:38.127096 12900 solver.cpp:243] Iteration 3190, loss = 2.1267
I0228 13:56:38.127292 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.16487 (* 1 = 2.16487 loss)
I0228 13:56:38.127305 12900 sgd_solver.cpp:138] Iteration 3190, lr = 0.0005
I0228 13:56:45.729209 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 13:57:05.047729 12900 solver.cpp:243] Iteration 3200, loss = 1.97011
I0228 13:57:05.047771 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75716 (* 1 = 1.75716 loss)
I0228 13:57:05.047783 12900 sgd_solver.cpp:138] Iteration 3200, lr = 0.0005
I0228 13:57:35.282979 12900 solver.cpp:243] Iteration 3210, loss = 2.09871
I0228 13:57:35.283165 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.7898 (* 1 = 1.7898 loss)
I0228 13:57:35.283177 12900 sgd_solver.cpp:138] Iteration 3210, lr = 0.0005
I0228 13:58:06.861021 12900 solver.cpp:243] Iteration 3220, loss = 2.00193
I0228 13:58:06.861199 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38216 (* 1 = 2.38216 loss)
I0228 13:58:06.861230 12900 sgd_solver.cpp:138] Iteration 3220, lr = 0.0005
I0228 13:58:34.836464 12900 solver.cpp:243] Iteration 3230, loss = 2.07552
I0228 13:58:34.836531 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.32501 (* 1 = 1.32501 loss)
I0228 13:58:34.836544 12900 sgd_solver.cpp:138] Iteration 3230, lr = 0.0005
I0228 13:59:02.873147 12900 solver.cpp:243] Iteration 3240, loss = 1.92411
I0228 13:59:02.873311 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.41449 (* 1 = 1.41449 loss)
I0228 13:59:02.873325 12900 sgd_solver.cpp:138] Iteration 3240, lr = 0.0005
I0228 13:59:32.793601 12900 solver.cpp:243] Iteration 3250, loss = 2.30402
I0228 13:59:32.793666 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.64579 (* 1 = 2.64579 loss)
I0228 13:59:32.793678 12900 sgd_solver.cpp:138] Iteration 3250, lr = 0.0005
I0228 13:59:59.532821 12900 solver.cpp:243] Iteration 3260, loss = 2.21074
I0228 13:59:59.532959 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.22176 (* 1 = 2.22176 loss)
I0228 13:59:59.532972 12900 sgd_solver.cpp:138] Iteration 3260, lr = 0.0005
I0228 14:00:34.930070 12900 solver.cpp:243] Iteration 3270, loss = 2.06508
I0228 14:00:34.930197 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.71952 (* 1 = 1.71952 loss)
I0228 14:00:34.930209 12900 sgd_solver.cpp:138] Iteration 3270, lr = 0.0005
I0228 14:01:07.706811 12900 solver.cpp:243] Iteration 3280, loss = 1.94039
I0228 14:01:07.706965 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91952 (* 1 = 1.91952 loss)
I0228 14:01:07.706979 12900 sgd_solver.cpp:138] Iteration 3280, lr = 0.0005
I0228 14:01:39.460064 12900 solver.cpp:243] Iteration 3290, loss = 1.79277
I0228 14:01:39.460232 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.83718 (* 1 = 1.83718 loss)
I0228 14:01:39.460264 12900 sgd_solver.cpp:138] Iteration 3290, lr = 0.0005
I0228 14:02:06.578382 12900 solver.cpp:243] Iteration 3300, loss = 2.03684
I0228 14:02:06.578441 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.90279 (* 1 = 1.90279 loss)
I0228 14:02:06.578452 12900 sgd_solver.cpp:138] Iteration 3300, lr = 0.0005
I0228 14:02:38.530203 12900 solver.cpp:243] Iteration 3310, loss = 2.00125
I0228 14:02:38.530354 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.12154 (* 1 = 2.12154 loss)
I0228 14:02:38.530366 12900 sgd_solver.cpp:138] Iteration 3310, lr = 0.0005
I0228 14:03:09.648155 12900 solver.cpp:243] Iteration 3320, loss = 1.87737
I0228 14:03:09.648298 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72108 (* 1 = 1.72108 loss)
I0228 14:03:09.648313 12900 sgd_solver.cpp:138] Iteration 3320, lr = 0.0005
I0228 14:03:38.739547 12900 solver.cpp:243] Iteration 3330, loss = 1.92373
I0228 14:03:38.739589 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.54384 (* 1 = 1.54384 loss)
I0228 14:03:38.739599 12900 sgd_solver.cpp:138] Iteration 3330, lr = 0.0005
I0228 14:04:12.638376 12900 solver.cpp:243] Iteration 3340, loss = 2.11129
I0228 14:04:12.638545 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.07238 (* 1 = 3.07238 loss)
I0228 14:04:12.638558 12900 sgd_solver.cpp:138] Iteration 3340, lr = 0.0005
I0228 14:04:41.670703 12900 solver.cpp:243] Iteration 3350, loss = 2.26817
I0228 14:04:41.670747 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.76692 (* 1 = 2.76692 loss)
I0228 14:04:41.670758 12900 sgd_solver.cpp:138] Iteration 3350, lr = 0.0005
I0228 14:05:16.167227 12900 solver.cpp:243] Iteration 3360, loss = 2.12962
I0228 14:05:16.167417 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.82386 (* 1 = 1.82386 loss)
I0228 14:05:16.167431 12900 sgd_solver.cpp:138] Iteration 3360, lr = 0.0005
I0228 14:05:43.564105 12900 solver.cpp:243] Iteration 3370, loss = 2.14287
I0228 14:05:43.564146 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78655 (* 1 = 1.78655 loss)
I0228 14:05:43.564162 12900 sgd_solver.cpp:138] Iteration 3370, lr = 0.0005
I0228 14:06:12.118345 12900 solver.cpp:243] Iteration 3380, loss = 2.01445
I0228 14:06:12.118511 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.54307 (* 1 = 2.54307 loss)
I0228 14:06:12.118525 12900 sgd_solver.cpp:138] Iteration 3380, lr = 0.0005
I0228 14:06:38.131563 12900 solver.cpp:243] Iteration 3390, loss = 2.19812
I0228 14:06:38.131603 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78841 (* 1 = 1.78841 loss)
I0228 14:06:38.131613 12900 sgd_solver.cpp:138] Iteration 3390, lr = 0.0005
I0228 14:07:08.472136 12900 solver.cpp:243] Iteration 3400, loss = 1.7755
I0228 14:07:08.472283 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.32702 (* 1 = 1.32702 loss)
I0228 14:07:08.472296 12900 sgd_solver.cpp:138] Iteration 3400, lr = 0.0005
I0228 14:07:42.513270 12900 solver.cpp:243] Iteration 3410, loss = 2.04323
I0228 14:07:42.513375 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61174 (* 1 = 1.61174 loss)
I0228 14:07:42.513391 12900 sgd_solver.cpp:138] Iteration 3410, lr = 0.0005
I0228 14:08:16.297734 12900 solver.cpp:243] Iteration 3420, loss = 1.94527
I0228 14:08:16.297899 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.11956 (* 1 = 2.11956 loss)
I0228 14:08:16.297911 12900 sgd_solver.cpp:138] Iteration 3420, lr = 0.0005
I0228 14:08:52.305317 12900 solver.cpp:243] Iteration 3430, loss = 2.01421
I0228 14:08:52.305475 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.8146 (* 1 = 1.8146 loss)
I0228 14:08:52.305490 12900 sgd_solver.cpp:138] Iteration 3430, lr = 0.0005
I0228 14:09:31.598649 12900 solver.cpp:243] Iteration 3440, loss = 1.75623
I0228 14:09:31.598759 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78453 (* 1 = 1.78453 loss)
I0228 14:09:31.598791 12900 sgd_solver.cpp:138] Iteration 3440, lr = 0.0005
I0228 14:10:03.025121 12900 solver.cpp:243] Iteration 3450, loss = 1.87239
I0228 14:10:03.025303 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.39283 (* 1 = 1.39283 loss)
I0228 14:10:03.025316 12900 sgd_solver.cpp:138] Iteration 3450, lr = 0.0005
I0228 14:10:33.257513 12900 solver.cpp:243] Iteration 3460, loss = 2.08039
I0228 14:10:33.257660 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38995 (* 1 = 2.38995 loss)
I0228 14:10:33.257678 12900 sgd_solver.cpp:138] Iteration 3460, lr = 0.0005
I0228 14:11:09.940724 12900 solver.cpp:243] Iteration 3470, loss = 2.0417
I0228 14:11:09.940856 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.19276 (* 1 = 1.19276 loss)
I0228 14:11:09.940870 12900 sgd_solver.cpp:138] Iteration 3470, lr = 0.0005
I0228 14:11:45.269006 12900 solver.cpp:243] Iteration 3480, loss = 1.93971
I0228 14:11:45.269124 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.99823 (* 1 = 1.99823 loss)
I0228 14:11:45.269142 12900 sgd_solver.cpp:138] Iteration 3480, lr = 0.0005
I0228 14:12:22.106173 12900 solver.cpp:243] Iteration 3490, loss = 2.15588
I0228 14:12:22.106314 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.86721 (* 1 = 1.86721 loss)
I0228 14:12:22.106326 12900 sgd_solver.cpp:138] Iteration 3490, lr = 0.0005
I0228 14:12:52.028878 12900 solver.cpp:243] Iteration 3500, loss = 2.20143
I0228 14:12:52.028945 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.11412 (* 1 = 2.11412 loss)
I0228 14:12:52.028957 12900 sgd_solver.cpp:138] Iteration 3500, lr = 0.0005
I0228 14:13:27.532559 12900 solver.cpp:243] Iteration 3510, loss = 1.9474
I0228 14:13:27.532763 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.27911 (* 1 = 2.27911 loss)
I0228 14:13:27.532776 12900 sgd_solver.cpp:138] Iteration 3510, lr = 0.0005
I0228 14:14:01.114835 12900 solver.cpp:243] Iteration 3520, loss = 1.85321
I0228 14:14:01.115031 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74848 (* 1 = 1.74848 loss)
I0228 14:14:01.115046 12900 sgd_solver.cpp:138] Iteration 3520, lr = 0.0005
I0228 14:14:30.379614 12900 solver.cpp:243] Iteration 3530, loss = 1.78847
I0228 14:14:30.379675 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.43112 (* 1 = 1.43112 loss)
I0228 14:14:30.379686 12900 sgd_solver.cpp:138] Iteration 3530, lr = 0.0005
I0228 14:15:02.254892 12900 solver.cpp:243] Iteration 3540, loss = 2.11523
I0228 14:15:02.255054 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.90943 (* 1 = 1.90943 loss)
I0228 14:15:02.255065 12900 sgd_solver.cpp:138] Iteration 3540, lr = 0.0005
I0228 14:15:31.396037 12900 solver.cpp:243] Iteration 3550, loss = 2.2343
I0228 14:15:31.396097 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.30338 (* 1 = 2.30338 loss)
I0228 14:15:31.396108 12900 sgd_solver.cpp:138] Iteration 3550, lr = 0.0005
I0228 14:16:05.022435 12900 solver.cpp:243] Iteration 3560, loss = 2.21586
I0228 14:16:05.022527 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.37285 (* 1 = 1.37285 loss)
I0228 14:16:05.022541 12900 sgd_solver.cpp:138] Iteration 3560, lr = 0.0005
I0228 14:16:31.165583 12900 solver.cpp:243] Iteration 3570, loss = 1.9531
I0228 14:16:31.165647 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.87298 (* 1 = 1.87298 loss)
I0228 14:16:31.165657 12900 sgd_solver.cpp:138] Iteration 3570, lr = 0.0005
I0228 14:17:07.759949 12900 solver.cpp:243] Iteration 3580, loss = 2.15624
I0228 14:17:07.760105 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.88254 (* 1 = 2.88254 loss)
I0228 14:17:07.760118 12900 sgd_solver.cpp:138] Iteration 3580, lr = 0.0005
I0228 14:17:35.859498 12900 solver.cpp:243] Iteration 3590, loss = 2.31795
I0228 14:17:35.859545 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.45474 (* 1 = 2.45474 loss)
I0228 14:17:35.859560 12900 sgd_solver.cpp:138] Iteration 3590, lr = 0.0005
I0228 14:18:10.932610 12900 solver.cpp:243] Iteration 3600, loss = 2.18671
I0228 14:18:10.932760 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.35909 (* 1 = 2.35909 loss)
I0228 14:18:10.932775 12900 sgd_solver.cpp:138] Iteration 3600, lr = 0.0005
I0228 14:18:44.047087 12900 solver.cpp:243] Iteration 3610, loss = 1.78544
I0228 14:18:44.047235 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.37098 (* 1 = 3.37098 loss)
I0228 14:18:44.047250 12900 sgd_solver.cpp:138] Iteration 3610, lr = 0.0005
I0228 14:19:14.435520 12900 solver.cpp:243] Iteration 3620, loss = 1.95677
I0228 14:19:14.435680 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94383 (* 1 = 1.94383 loss)
I0228 14:19:14.435693 12900 sgd_solver.cpp:138] Iteration 3620, lr = 0.0005
I0228 14:19:46.455734 12900 solver.cpp:243] Iteration 3630, loss = 1.88953
I0228 14:19:46.455862 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.33909 (* 1 = 2.33909 loss)
I0228 14:19:46.455875 12900 sgd_solver.cpp:138] Iteration 3630, lr = 0.0005
I0228 14:20:18.864326 12900 solver.cpp:243] Iteration 3640, loss = 1.80076
I0228 14:20:18.864490 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.79078 (* 1 = 1.79078 loss)
I0228 14:20:18.864503 12900 sgd_solver.cpp:138] Iteration 3640, lr = 0.0005
I0228 14:20:51.578436 12900 solver.cpp:243] Iteration 3650, loss = 2.1254
I0228 14:20:51.578579 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.69379 (* 1 = 1.69379 loss)
I0228 14:20:51.578596 12900 sgd_solver.cpp:138] Iteration 3650, lr = 0.0005
I0228 14:21:22.554425 12900 solver.cpp:243] Iteration 3660, loss = 2.08394
I0228 14:21:22.554610 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94995 (* 1 = 1.94995 loss)
I0228 14:21:22.554623 12900 sgd_solver.cpp:138] Iteration 3660, lr = 0.0005
I0228 14:21:53.944430 12900 solver.cpp:243] Iteration 3670, loss = 2.11935
I0228 14:21:53.944593 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.44236 (* 1 = 1.44236 loss)
I0228 14:21:53.944605 12900 sgd_solver.cpp:138] Iteration 3670, lr = 0.0005
I0228 14:22:26.962141 12900 solver.cpp:243] Iteration 3680, loss = 2.12027
I0228 14:22:26.962311 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.8474 (* 1 = 1.8474 loss)
I0228 14:22:26.962328 12900 sgd_solver.cpp:138] Iteration 3680, lr = 0.0005
I0228 14:22:54.792462 12900 solver.cpp:243] Iteration 3690, loss = 1.94286
I0228 14:22:54.792524 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38589 (* 1 = 2.38589 loss)
I0228 14:22:54.792536 12900 sgd_solver.cpp:138] Iteration 3690, lr = 0.0005
I0228 14:23:29.808626 12900 solver.cpp:243] Iteration 3700, loss = 2.31838
I0228 14:23:29.808804 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.69857 (* 1 = 1.69857 loss)
I0228 14:23:29.808817 12900 sgd_solver.cpp:138] Iteration 3700, lr = 0.0005
I0228 14:23:58.973279 12900 solver.cpp:243] Iteration 3710, loss = 2.03676
I0228 14:23:58.973337 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.90493 (* 1 = 1.90493 loss)
I0228 14:23:58.973347 12900 sgd_solver.cpp:138] Iteration 3710, lr = 0.0005
I0228 14:24:31.449592 12900 solver.cpp:243] Iteration 3720, loss = 1.88501
I0228 14:24:31.449779 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.51992 (* 1 = 1.51992 loss)
I0228 14:24:31.449793 12900 sgd_solver.cpp:138] Iteration 3720, lr = 0.0005
I0228 14:24:57.965338 12900 solver.cpp:243] Iteration 3730, loss = 1.91655
I0228 14:24:57.965394 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.67243 (* 1 = 1.67243 loss)
I0228 14:24:57.965405 12900 sgd_solver.cpp:138] Iteration 3730, lr = 0.0005
I0228 14:25:24.389207 12900 solver.cpp:243] Iteration 3740, loss = 1.91318
I0228 14:25:24.389370 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72218 (* 1 = 1.72218 loss)
I0228 14:25:24.389382 12900 sgd_solver.cpp:138] Iteration 3740, lr = 0.0005
I0228 14:25:52.382243 12900 solver.cpp:243] Iteration 3750, loss = 2.16488
I0228 14:25:52.382302 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.02632 (* 1 = 3.02632 loss)
I0228 14:25:52.382313 12900 sgd_solver.cpp:138] Iteration 3750, lr = 0.0005
I0228 14:26:20.519409 12900 solver.cpp:243] Iteration 3760, loss = 1.88888
I0228 14:26:20.519598 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.01311 (* 1 = 2.01311 loss)
I0228 14:26:20.519611 12900 sgd_solver.cpp:138] Iteration 3760, lr = 0.0005
I0228 14:26:49.234148 12900 solver.cpp:243] Iteration 3770, loss = 1.90398
I0228 14:26:49.234203 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.2702 (* 1 = 1.2702 loss)
I0228 14:26:49.234215 12900 sgd_solver.cpp:138] Iteration 3770, lr = 0.0005
I0228 14:27:19.884603 12900 solver.cpp:243] Iteration 3780, loss = 1.77394
I0228 14:27:19.884771 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.08066 (* 1 = 2.08066 loss)
I0228 14:27:19.884784 12900 sgd_solver.cpp:138] Iteration 3780, lr = 0.0005
I0228 14:27:50.501565 12900 solver.cpp:243] Iteration 3790, loss = 1.96653
I0228 14:27:50.501725 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.30433 (* 1 = 2.30433 loss)
I0228 14:27:50.501741 12900 sgd_solver.cpp:138] Iteration 3790, lr = 0.0005
I0228 14:28:22.794950 12900 solver.cpp:243] Iteration 3800, loss = 1.75542
I0228 14:28:22.795110 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.99045 (* 1 = 1.99045 loss)
I0228 14:28:22.795125 12900 sgd_solver.cpp:138] Iteration 3800, lr = 0.0005
I0228 14:28:54.768163 12900 solver.cpp:243] Iteration 3810, loss = 2.19738
I0228 14:28:54.768266 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.4811 (* 1 = 3.4811 loss)
I0228 14:28:54.768282 12900 sgd_solver.cpp:138] Iteration 3810, lr = 0.0005
I0228 14:29:26.030458 12900 solver.cpp:243] Iteration 3820, loss = 2.21959
I0228 14:29:26.030616 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.49759 (* 1 = 1.49759 loss)
I0228 14:29:26.030628 12900 sgd_solver.cpp:138] Iteration 3820, lr = 0.0005
I0228 14:30:32.406270 12900 solver.cpp:243] Iteration 3830, loss = 2.03471
I0228 14:30:32.406456 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.3304 (* 1 = 2.3304 loss)
I0228 14:30:32.406491 12900 sgd_solver.cpp:138] Iteration 3830, lr = 0.0005
I0228 14:31:35.904089 12900 solver.cpp:243] Iteration 3840, loss = 1.73808
I0228 14:31:35.904603 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9592 (* 1 = 1.9592 loss)
I0228 14:31:35.904626 12900 sgd_solver.cpp:138] Iteration 3840, lr = 0.0005
I0228 14:32:30.400022 12900 solver.cpp:243] Iteration 3850, loss = 1.92998
I0228 14:32:30.400164 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94153 (* 1 = 1.94153 loss)
I0228 14:32:30.400178 12900 sgd_solver.cpp:138] Iteration 3850, lr = 0.0005
I0228 14:33:02.752236 12900 solver.cpp:243] Iteration 3860, loss = 1.69532
I0228 14:33:02.752454 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.48967 (* 1 = 1.48967 loss)
I0228 14:33:02.752467 12900 sgd_solver.cpp:138] Iteration 3860, lr = 0.0005
I0228 14:33:35.516680 12900 solver.cpp:243] Iteration 3870, loss = 2.26935
I0228 14:33:35.516844 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.97394 (* 1 = 1.97394 loss)
I0228 14:33:35.516856 12900 sgd_solver.cpp:138] Iteration 3870, lr = 0.0005
I0228 14:34:07.094305 12900 solver.cpp:243] Iteration 3880, loss = 2.02746
I0228 14:34:07.094440 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.38306 (* 1 = 1.38306 loss)
I0228 14:34:07.094454 12900 sgd_solver.cpp:138] Iteration 3880, lr = 0.0005
I0228 14:34:38.206112 12900 solver.cpp:243] Iteration 3890, loss = 1.98039
I0228 14:34:38.206311 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.80624 (* 1 = 2.80624 loss)
I0228 14:34:38.206324 12900 sgd_solver.cpp:138] Iteration 3890, lr = 0.0005
I0228 14:35:08.484139 12900 solver.cpp:243] Iteration 3900, loss = 1.8821
I0228 14:35:08.484319 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94691 (* 1 = 1.94691 loss)
I0228 14:35:08.484333 12900 sgd_solver.cpp:138] Iteration 3900, lr = 0.0005
I0228 14:35:44.461284 12900 solver.cpp:243] Iteration 3910, loss = 1.81081
I0228 14:35:44.461391 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.3029 (* 1 = 1.3029 loss)
I0228 14:35:44.461405 12900 sgd_solver.cpp:138] Iteration 3910, lr = 0.0005
I0228 14:36:15.326459 12900 solver.cpp:243] Iteration 3920, loss = 1.81804
I0228 14:36:15.326596 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.18639 (* 1 = 2.18639 loss)
I0228 14:36:15.326609 12900 sgd_solver.cpp:138] Iteration 3920, lr = 0.0005
I0228 14:36:45.323097 12900 solver.cpp:243] Iteration 3930, loss = 1.96716
I0228 14:36:45.323158 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.01312 (* 1 = 2.01312 loss)
I0228 14:36:45.323169 12900 sgd_solver.cpp:138] Iteration 3930, lr = 0.0005
I0228 14:37:12.502466 12900 solver.cpp:243] Iteration 3940, loss = 2.02265
I0228 14:37:12.502586 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.02625 (* 1 = 2.02625 loss)
I0228 14:37:12.502599 12900 sgd_solver.cpp:138] Iteration 3940, lr = 0.0005
I0228 14:37:43.351918 12900 solver.cpp:243] Iteration 3950, loss = 2.17147
I0228 14:37:43.352047 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41597 (* 1 = 2.41597 loss)
I0228 14:37:43.352059 12900 sgd_solver.cpp:138] Iteration 3950, lr = 0.0005
I0228 14:38:11.061918 12900 solver.cpp:243] Iteration 3960, loss = 1.89956
I0228 14:38:11.061976 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.49915 (* 1 = 1.49915 loss)
I0228 14:38:11.061987 12900 sgd_solver.cpp:138] Iteration 3960, lr = 0.0005
I0228 14:38:43.179548 12900 solver.cpp:243] Iteration 3970, loss = 1.94903
I0228 14:38:43.179697 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.23174 (* 1 = 2.23174 loss)
I0228 14:38:43.179710 12900 sgd_solver.cpp:138] Iteration 3970, lr = 0.0005
I0228 14:39:16.232841 12900 solver.cpp:243] Iteration 3980, loss = 2.05532
I0228 14:39:16.233032 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.50914 (* 1 = 1.50914 loss)
I0228 14:39:16.233045 12900 sgd_solver.cpp:138] Iteration 3980, lr = 0.0005
I0228 14:39:49.462430 12900 solver.cpp:243] Iteration 3990, loss = 2.06072
I0228 14:39:49.462589 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.68996 (* 1 = 2.68996 loss)
I0228 14:39:49.462601 12900 sgd_solver.cpp:138] Iteration 3990, lr = 0.0005
I0228 14:40:16.358844 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_4000.caffemodel
I0228 14:40:16.428309 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_4000.solverstate
I0228 14:40:18.590762 12900 solver.cpp:243] Iteration 4000, loss = 1.83936
I0228 14:40:18.590807 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00248 (* 1 = 2.00248 loss)
I0228 14:40:18.590817 12900 sgd_solver.cpp:138] Iteration 4000, lr = 0.0005
I0228 14:40:49.035665 12900 solver.cpp:243] Iteration 4010, loss = 1.99158
I0228 14:40:49.035842 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.08063 (* 1 = 1.08063 loss)
I0228 14:40:49.035856 12900 sgd_solver.cpp:138] Iteration 4010, lr = 0.0005
I0228 14:41:22.831125 12900 solver.cpp:243] Iteration 4020, loss = 1.72554
I0228 14:41:22.831274 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61879 (* 1 = 1.61879 loss)
I0228 14:41:22.831287 12900 sgd_solver.cpp:138] Iteration 4020, lr = 0.0005
I0228 14:41:52.789201 12900 solver.cpp:243] Iteration 4030, loss = 2.14312
I0228 14:41:52.789268 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.01164 (* 1 = 2.01164 loss)
I0228 14:41:52.789279 12900 sgd_solver.cpp:138] Iteration 4030, lr = 0.0005
I0228 14:42:27.876463 12900 solver.cpp:243] Iteration 4040, loss = 2.13667
I0228 14:42:27.876605 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07572 (* 1 = 2.07572 loss)
I0228 14:42:27.876616 12900 sgd_solver.cpp:138] Iteration 4040, lr = 0.0005
I0228 14:42:56.450099 12900 solver.cpp:243] Iteration 4050, loss = 1.83102
I0228 14:42:56.450165 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.62013 (* 1 = 1.62013 loss)
I0228 14:42:56.450177 12900 sgd_solver.cpp:138] Iteration 4050, lr = 0.0005
I0228 14:43:30.344983 12900 solver.cpp:243] Iteration 4060, loss = 2.2534
I0228 14:43:30.345161 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.31757 (* 1 = 2.31757 loss)
I0228 14:43:30.345175 12900 sgd_solver.cpp:138] Iteration 4060, lr = 0.0005
I0228 14:44:06.970309 12900 solver.cpp:243] Iteration 4070, loss = 1.83831
I0228 14:44:06.970427 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.41302 (* 1 = 3.41302 loss)
I0228 14:44:06.970438 12900 sgd_solver.cpp:138] Iteration 4070, lr = 0.0005
I0228 14:44:41.295855 12900 solver.cpp:243] Iteration 4080, loss = 1.87037
I0228 14:44:41.296053 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.15009 (* 1 = 1.15009 loss)
I0228 14:44:41.296067 12900 sgd_solver.cpp:138] Iteration 4080, lr = 0.0005
I0228 14:45:15.293289 12900 solver.cpp:243] Iteration 4090, loss = 1.77554
I0228 14:45:15.293429 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.54975 (* 1 = 1.54975 loss)
I0228 14:45:15.293442 12900 sgd_solver.cpp:138] Iteration 4090, lr = 0.0005
I0228 14:45:46.804980 12900 solver.cpp:243] Iteration 4100, loss = 1.65252
I0228 14:45:46.805140 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.42906 (* 1 = 2.42906 loss)
I0228 14:45:46.805153 12900 sgd_solver.cpp:138] Iteration 4100, lr = 0.0005
I0228 14:46:20.370801 12900 solver.cpp:243] Iteration 4110, loss = 2.36365
I0228 14:46:20.370954 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.97994 (* 1 = 1.97994 loss)
I0228 14:46:20.370966 12900 sgd_solver.cpp:138] Iteration 4110, lr = 0.0005
I0228 14:46:57.461159 12900 solver.cpp:243] Iteration 4120, loss = 2.12442
I0228 14:46:57.461549 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.1014 (* 1 = 2.1014 loss)
I0228 14:46:57.461567 12900 sgd_solver.cpp:138] Iteration 4120, lr = 0.0005
I0228 14:48:13.613131 12900 solver.cpp:243] Iteration 4130, loss = 2.0281
I0228 14:48:13.628450 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61034 (* 1 = 1.61034 loss)
I0228 14:48:13.628485 12900 sgd_solver.cpp:138] Iteration 4130, lr = 0.0005
I0228 14:49:38.915012 12900 solver.cpp:243] Iteration 4140, loss = 1.97676
I0228 14:49:38.915166 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.53925 (* 1 = 2.53925 loss)
I0228 14:49:38.915189 12900 sgd_solver.cpp:138] Iteration 4140, lr = 0.0005
I0228 14:50:33.995424 12900 solver.cpp:243] Iteration 4150, loss = 1.75452
I0228 14:50:33.995625 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.46206 (* 1 = 1.46206 loss)
I0228 14:50:33.995640 12900 sgd_solver.cpp:138] Iteration 4150, lr = 0.0005
I0228 14:51:13.549881 12900 solver.cpp:243] Iteration 4160, loss = 1.91699
I0228 14:51:13.550055 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.36396 (* 1 = 1.36396 loss)
I0228 14:51:13.550072 12900 sgd_solver.cpp:138] Iteration 4160, lr = 0.0005
I0228 14:51:45.502045 12900 solver.cpp:243] Iteration 4170, loss = 1.93562
I0228 14:51:45.502180 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94247 (* 1 = 1.94247 loss)
I0228 14:51:45.502194 12900 sgd_solver.cpp:138] Iteration 4170, lr = 0.0005
I0228 14:52:48.256132 12900 solver.cpp:243] Iteration 4180, loss = 1.67542
I0228 14:52:48.268551 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.13657 (* 1 = 2.13657 loss)
I0228 14:52:48.268625 12900 sgd_solver.cpp:138] Iteration 4180, lr = 0.0005
I0228 14:53:49.631681 12900 solver.cpp:243] Iteration 4190, loss = 2.13206
I0228 14:53:49.631863 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.04965 (* 1 = 3.04965 loss)
I0228 14:53:49.631897 12900 sgd_solver.cpp:138] Iteration 4190, lr = 0.0005
I0228 14:54:53.464594 12900 solver.cpp:243] Iteration 4200, loss = 2.24755
I0228 14:54:53.464730 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.07989 (* 1 = 3.07989 loss)
I0228 14:54:53.464747 12900 sgd_solver.cpp:138] Iteration 4200, lr = 0.0005
I0228 14:55:38.814503 12900 solver.cpp:243] Iteration 4210, loss = 2.06526
I0228 14:55:38.814658 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.60708 (* 1 = 1.60708 loss)
I0228 14:55:38.814674 12900 sgd_solver.cpp:138] Iteration 4210, lr = 0.0005
I0228 14:56:13.511955 12900 solver.cpp:243] Iteration 4220, loss = 1.7491
I0228 14:56:13.512159 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.08364 (* 1 = 1.08364 loss)
I0228 14:56:13.512178 12900 sgd_solver.cpp:138] Iteration 4220, lr = 0.0005
I0228 14:56:54.991466 12900 solver.cpp:243] Iteration 4230, loss = 1.86196
I0228 14:56:54.991597 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74309 (* 1 = 1.74309 loss)
I0228 14:56:54.991611 12900 sgd_solver.cpp:138] Iteration 4230, lr = 0.0005
I0228 14:56:58.946758 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 14:57:29.500114 12900 solver.cpp:243] Iteration 4240, loss = 1.82275
I0228 14:57:29.500277 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.49841 (* 1 = 2.49841 loss)
I0228 14:57:29.500290 12900 sgd_solver.cpp:138] Iteration 4240, lr = 0.0005
I0228 14:58:05.877883 12900 solver.cpp:243] Iteration 4250, loss = 1.96944
I0228 14:58:05.878036 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91535 (* 1 = 1.91535 loss)
I0228 14:58:05.878048 12900 sgd_solver.cpp:138] Iteration 4250, lr = 0.0005
I0228 14:58:41.505112 12900 solver.cpp:243] Iteration 4260, loss = 1.92451
I0228 14:58:41.505250 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.292 (* 1 = 3.292 loss)
I0228 14:58:41.505264 12900 sgd_solver.cpp:138] Iteration 4260, lr = 0.0005
I0228 14:59:17.485313 12900 solver.cpp:243] Iteration 4270, loss = 1.79633
I0228 14:59:17.485448 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.93133 (* 1 = 1.93133 loss)
I0228 14:59:17.485463 12900 sgd_solver.cpp:138] Iteration 4270, lr = 0.0005
I0228 14:59:53.150202 12900 solver.cpp:243] Iteration 4280, loss = 1.99656
I0228 14:59:53.150388 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.90991 (* 1 = 1.90991 loss)
I0228 14:59:53.150403 12900 sgd_solver.cpp:138] Iteration 4280, lr = 0.0005
I0228 15:00:41.429834 12900 solver.cpp:243] Iteration 4290, loss = 2.03141
I0228 15:00:41.430003 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.67776 (* 1 = 2.67776 loss)
I0228 15:00:41.430017 12900 sgd_solver.cpp:138] Iteration 4290, lr = 0.0005
I0228 15:01:11.351824 12900 solver.cpp:243] Iteration 4300, loss = 2.14905
I0228 15:01:11.351886 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.83124 (* 1 = 1.83124 loss)
I0228 15:01:11.351897 12900 sgd_solver.cpp:138] Iteration 4300, lr = 0.0005
I0228 15:01:45.547559 12900 solver.cpp:243] Iteration 4310, loss = 1.37444
I0228 15:01:45.547708 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.08562 (* 1 = 2.08562 loss)
I0228 15:01:45.547725 12900 sgd_solver.cpp:138] Iteration 4310, lr = 0.0005
I0228 15:02:21.000182 12900 solver.cpp:243] Iteration 4320, loss = 1.95097
I0228 15:02:21.000341 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.34659 (* 1 = 1.34659 loss)
I0228 15:02:21.000371 12900 sgd_solver.cpp:138] Iteration 4320, lr = 0.0005
I0228 15:02:50.683415 12900 solver.cpp:243] Iteration 4330, loss = 1.88825
I0228 15:02:50.683473 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.76465 (* 1 = 1.76465 loss)
I0228 15:02:50.683487 12900 sgd_solver.cpp:138] Iteration 4330, lr = 0.0005
I0228 15:03:32.672870 12900 solver.cpp:243] Iteration 4340, loss = 1.87295
I0228 15:03:32.672993 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.06896 (* 1 = 2.06896 loss)
I0228 15:03:32.673007 12900 sgd_solver.cpp:138] Iteration 4340, lr = 0.0005
I0228 15:04:14.552776 12900 solver.cpp:243] Iteration 4350, loss = 1.74657
I0228 15:04:14.552980 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75287 (* 1 = 1.75287 loss)
I0228 15:04:14.553004 12900 sgd_solver.cpp:138] Iteration 4350, lr = 0.0005
I0228 15:04:48.248311 12900 solver.cpp:243] Iteration 4360, loss = 2.03412
I0228 15:04:48.248459 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.34687 (* 1 = 2.34687 loss)
I0228 15:04:48.248478 12900 sgd_solver.cpp:138] Iteration 4360, lr = 0.0005
I0228 15:05:23.953574 12900 solver.cpp:243] Iteration 4370, loss = 2.09201
I0228 15:05:23.953711 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.46561 (* 1 = 2.46561 loss)
I0228 15:05:23.953724 12900 sgd_solver.cpp:138] Iteration 4370, lr = 0.0005
I0228 15:05:52.743978 12900 solver.cpp:243] Iteration 4380, loss = 1.56134
I0228 15:05:52.744029 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42905 (* 1 = 1.42905 loss)
I0228 15:05:52.744040 12900 sgd_solver.cpp:138] Iteration 4380, lr = 0.0005
I0228 15:06:24.826848 12900 solver.cpp:243] Iteration 4390, loss = 1.96667
I0228 15:06:24.827003 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.87811 (* 1 = 1.87811 loss)
I0228 15:06:24.827018 12900 sgd_solver.cpp:138] Iteration 4390, lr = 0.0005
I0228 15:06:53.124208 12900 solver.cpp:243] Iteration 4400, loss = 2.30258
I0228 15:06:53.124253 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.26204 (* 1 = 2.26204 loss)
I0228 15:06:53.124264 12900 sgd_solver.cpp:138] Iteration 4400, lr = 0.0005
I0228 15:07:34.836133 12900 solver.cpp:243] Iteration 4410, loss = 1.91295
I0228 15:07:34.836262 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.16861 (* 1 = 2.16861 loss)
I0228 15:07:34.836275 12900 sgd_solver.cpp:138] Iteration 4410, lr = 0.0005
I0228 15:08:07.956091 12900 solver.cpp:243] Iteration 4420, loss = 1.81088
I0228 15:08:07.956240 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42543 (* 1 = 1.42543 loss)
I0228 15:08:07.956254 12900 sgd_solver.cpp:138] Iteration 4420, lr = 0.0005
I0228 15:08:47.101176 12900 solver.cpp:243] Iteration 4430, loss = 2.08554
I0228 15:08:47.101354 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41145 (* 1 = 2.41145 loss)
I0228 15:08:47.101374 12900 sgd_solver.cpp:138] Iteration 4430, lr = 0.0005
I0228 15:09:58.915217 12900 solver.cpp:243] Iteration 4440, loss = 1.88502
I0228 15:09:58.915383 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.16695 (* 1 = 2.16695 loss)
I0228 15:09:58.915400 12900 sgd_solver.cpp:138] Iteration 4440, lr = 0.0005
I0228 15:10:28.759455 12900 solver.cpp:243] Iteration 4450, loss = 1.94303
I0228 15:10:28.759521 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.79503 (* 1 = 2.79503 loss)
I0228 15:10:28.759531 12900 sgd_solver.cpp:138] Iteration 4450, lr = 0.0005
I0228 15:11:03.697264 12900 solver.cpp:243] Iteration 4460, loss = 1.91016
I0228 15:11:03.697420 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80073 (* 1 = 1.80073 loss)
I0228 15:11:03.697433 12900 sgd_solver.cpp:138] Iteration 4460, lr = 0.0005
I0228 15:11:52.270604 12900 solver.cpp:243] Iteration 4470, loss = 1.81239
I0228 15:11:52.270750 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.45106 (* 1 = 1.45106 loss)
I0228 15:11:52.270766 12900 sgd_solver.cpp:138] Iteration 4470, lr = 0.0005
I0228 15:12:23.912272 12900 solver.cpp:243] Iteration 4480, loss = 1.92303
I0228 15:12:23.912439 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.69113 (* 1 = 1.69113 loss)
I0228 15:12:23.912451 12900 sgd_solver.cpp:138] Iteration 4480, lr = 0.0005
I0228 15:13:07.437000 12900 solver.cpp:243] Iteration 4490, loss = 1.92005
I0228 15:13:07.437212 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.4764 (* 1 = 2.4764 loss)
I0228 15:13:07.437227 12900 sgd_solver.cpp:138] Iteration 4490, lr = 0.0005
I0228 15:13:47.694579 12900 solver.cpp:243] Iteration 4500, loss = 1.72372
I0228 15:13:47.694738 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.93516 (* 1 = 1.93516 loss)
I0228 15:13:47.694751 12900 sgd_solver.cpp:138] Iteration 4500, lr = 0.0005
I0228 15:14:19.048712 12900 solver.cpp:243] Iteration 4510, loss = 1.76268
I0228 15:14:19.048868 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.85502 (* 1 = 1.85502 loss)
I0228 15:14:19.048882 12900 sgd_solver.cpp:138] Iteration 4510, lr = 0.0005
I0228 15:14:52.106989 12900 solver.cpp:243] Iteration 4520, loss = 1.95915
I0228 15:14:52.107172 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.84995 (* 1 = 1.84995 loss)
I0228 15:14:52.107185 12900 sgd_solver.cpp:138] Iteration 4520, lr = 0.0005
I0228 15:15:23.598872 12900 solver.cpp:243] Iteration 4530, loss = 1.764
I0228 15:15:23.599047 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.17015 (* 1 = 1.17015 loss)
I0228 15:15:23.599061 12900 sgd_solver.cpp:138] Iteration 4530, lr = 0.0005
I0228 15:15:54.660564 12900 solver.cpp:243] Iteration 4540, loss = 1.679
I0228 15:15:54.660733 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.32016 (* 1 = 1.32016 loss)
I0228 15:15:54.660756 12900 sgd_solver.cpp:138] Iteration 4540, lr = 0.0005
I0228 15:16:39.702409 12900 solver.cpp:243] Iteration 4550, loss = 1.91569
I0228 15:16:39.702603 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.22325 (* 1 = 2.22325 loss)
I0228 15:16:39.702623 12900 sgd_solver.cpp:138] Iteration 4550, lr = 0.0005
I0228 15:17:16.253753 12900 solver.cpp:243] Iteration 4560, loss = 2.42196
I0228 15:17:16.253890 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.15488 (* 1 = 2.15488 loss)
I0228 15:17:16.253903 12900 sgd_solver.cpp:138] Iteration 4560, lr = 0.0005
I0228 15:17:44.921914 12900 solver.cpp:243] Iteration 4570, loss = 1.81461
I0228 15:17:44.921979 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.10162 (* 1 = 3.10162 loss)
I0228 15:17:44.921994 12900 sgd_solver.cpp:138] Iteration 4570, lr = 0.0005
I0228 15:18:39.621843 12900 solver.cpp:243] Iteration 4580, loss = 1.84938
I0228 15:18:39.622016 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.62114 (* 1 = 1.62114 loss)
I0228 15:18:39.622035 12900 sgd_solver.cpp:138] Iteration 4580, lr = 0.0005
I0228 15:19:15.305758 12900 solver.cpp:243] Iteration 4590, loss = 1.96407
I0228 15:19:15.305969 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.89643 (* 1 = 1.89643 loss)
I0228 15:19:15.305984 12900 sgd_solver.cpp:138] Iteration 4590, lr = 0.0005
I0228 15:19:57.959250 12900 solver.cpp:243] Iteration 4600, loss = 1.89177
I0228 15:19:57.959437 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.50292 (* 1 = 1.50292 loss)
I0228 15:19:57.959455 12900 sgd_solver.cpp:138] Iteration 4600, lr = 0.0005
I0228 15:20:29.668715 12900 solver.cpp:243] Iteration 4610, loss = 1.65531
I0228 15:20:29.668916 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.24618 (* 1 = 1.24618 loss)
I0228 15:20:29.668929 12900 sgd_solver.cpp:138] Iteration 4610, lr = 0.0005
I0228 15:21:04.778365 12900 solver.cpp:243] Iteration 4620, loss = 1.97532
I0228 15:21:04.778559 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.98623 (* 1 = 2.98623 loss)
I0228 15:21:04.778573 12900 sgd_solver.cpp:138] Iteration 4620, lr = 0.0005
I0228 15:21:45.031013 12900 solver.cpp:243] Iteration 4630, loss = 1.93299
I0228 15:21:45.031214 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.70552 (* 1 = 1.70552 loss)
I0228 15:21:45.031232 12900 sgd_solver.cpp:138] Iteration 4630, lr = 0.0005
I0228 15:22:17.278152 12900 solver.cpp:243] Iteration 4640, loss = 1.74957
I0228 15:22:17.278329 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.25437 (* 1 = 2.25437 loss)
I0228 15:22:17.278342 12900 sgd_solver.cpp:138] Iteration 4640, lr = 0.0005
I0228 15:22:54.100733 12900 solver.cpp:243] Iteration 4650, loss = 2.00392
I0228 15:22:54.100945 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.92866 (* 1 = 1.92866 loss)
I0228 15:22:54.100991 12900 sgd_solver.cpp:138] Iteration 4650, lr = 0.0005
I0228 15:23:29.333127 12900 solver.cpp:243] Iteration 4660, loss = 1.629
I0228 15:23:29.333313 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.16963 (* 1 = 1.16963 loss)
I0228 15:23:29.333326 12900 sgd_solver.cpp:138] Iteration 4660, lr = 0.0005
I0228 15:24:01.708989 12900 solver.cpp:243] Iteration 4670, loss = 1.83284
I0228 15:24:01.709182 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.48685 (* 1 = 2.48685 loss)
I0228 15:24:01.709195 12900 sgd_solver.cpp:138] Iteration 4670, lr = 0.0005
I0228 15:24:32.879835 12900 solver.cpp:243] Iteration 4680, loss = 2.11553
I0228 15:24:32.879998 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.02911 (* 1 = 2.02911 loss)
I0228 15:24:32.880012 12900 sgd_solver.cpp:138] Iteration 4680, lr = 0.0005
I0228 15:25:08.067898 12900 solver.cpp:243] Iteration 4690, loss = 1.85318
I0228 15:25:08.068126 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.3141 (* 1 = 1.3141 loss)
I0228 15:25:08.068140 12900 sgd_solver.cpp:138] Iteration 4690, lr = 0.0005
I0228 15:25:41.298355 12900 solver.cpp:243] Iteration 4700, loss = 1.89993
I0228 15:25:41.298532 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.99268 (* 1 = 2.99268 loss)
I0228 15:25:41.298545 12900 sgd_solver.cpp:138] Iteration 4700, lr = 0.0005
I0228 15:26:16.401960 12900 solver.cpp:243] Iteration 4710, loss = 1.75705
I0228 15:26:16.402127 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.25965 (* 1 = 1.25965 loss)
I0228 15:26:16.402140 12900 sgd_solver.cpp:138] Iteration 4710, lr = 0.0005
I0228 15:26:49.353720 12900 solver.cpp:243] Iteration 4720, loss = 2.09083
I0228 15:26:49.353852 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.40809 (* 1 = 2.40809 loss)
I0228 15:26:49.353863 12900 sgd_solver.cpp:138] Iteration 4720, lr = 0.0005
I0228 15:27:30.400812 12900 solver.cpp:243] Iteration 4730, loss = 1.96471
I0228 15:27:30.400997 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78322 (* 1 = 1.78322 loss)
I0228 15:27:30.401010 12900 sgd_solver.cpp:138] Iteration 4730, lr = 0.0005
I0228 15:28:14.321808 12900 solver.cpp:243] Iteration 4740, loss = 2.14596
I0228 15:28:14.321996 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.84327 (* 1 = 1.84327 loss)
I0228 15:28:14.322012 12900 sgd_solver.cpp:138] Iteration 4740, lr = 0.0005
I0228 15:28:46.066025 12900 solver.cpp:243] Iteration 4750, loss = 1.8434
I0228 15:28:46.066227 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72463 (* 1 = 1.72463 loss)
I0228 15:28:46.066242 12900 sgd_solver.cpp:138] Iteration 4750, lr = 0.0005
I0228 15:29:24.565585 12900 solver.cpp:243] Iteration 4760, loss = 2.2483
I0228 15:29:24.565821 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.2989 (* 1 = 2.2989 loss)
I0228 15:29:24.565840 12900 sgd_solver.cpp:138] Iteration 4760, lr = 0.0005
I0228 15:29:56.963991 12900 solver.cpp:243] Iteration 4770, loss = 1.80633
I0228 15:29:56.964229 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.89242 (* 1 = 1.89242 loss)
I0228 15:29:56.964262 12900 sgd_solver.cpp:138] Iteration 4770, lr = 0.0005
I0228 15:30:30.248292 12900 solver.cpp:243] Iteration 4780, loss = 2.09051
I0228 15:30:30.248486 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75576 (* 1 = 1.75576 loss)
I0228 15:30:30.248498 12900 sgd_solver.cpp:138] Iteration 4780, lr = 0.0005
I0228 15:31:13.164990 12900 solver.cpp:243] Iteration 4790, loss = 1.86886
I0228 15:31:13.165200 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.5427 (* 1 = 1.5427 loss)
I0228 15:31:13.165218 12900 sgd_solver.cpp:138] Iteration 4790, lr = 0.0005
I0228 15:31:46.977556 12900 solver.cpp:243] Iteration 4800, loss = 2.07383
I0228 15:31:46.977730 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.53534 (* 1 = 2.53534 loss)
I0228 15:31:46.977742 12900 sgd_solver.cpp:138] Iteration 4800, lr = 0.0005
I0228 15:32:26.274582 12900 solver.cpp:243] Iteration 4810, loss = 1.71389
I0228 15:32:26.274761 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.54031 (* 1 = 3.54031 loss)
I0228 15:32:26.274775 12900 sgd_solver.cpp:138] Iteration 4810, lr = 0.0005
I0228 15:33:02.513270 12900 solver.cpp:243] Iteration 4820, loss = 1.74878
I0228 15:33:02.513458 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.3637 (* 1 = 1.3637 loss)
I0228 15:33:02.513473 12900 sgd_solver.cpp:138] Iteration 4820, lr = 0.0005
I0228 15:33:40.211024 12900 solver.cpp:243] Iteration 4830, loss = 1.78983
I0228 15:33:40.211169 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.06419 (* 1 = 1.06419 loss)
I0228 15:33:40.211182 12900 sgd_solver.cpp:138] Iteration 4830, lr = 0.0005
I0228 15:34:33.181609 12900 solver.cpp:243] Iteration 4840, loss = 1.83968
I0228 15:34:33.181798 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.35111 (* 1 = 1.35111 loss)
I0228 15:34:33.181812 12900 sgd_solver.cpp:138] Iteration 4840, lr = 0.0005
I0228 15:35:11.377760 12900 solver.cpp:243] Iteration 4850, loss = 1.52183
I0228 15:35:11.377948 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.68553 (* 1 = 1.68553 loss)
I0228 15:35:11.377960 12900 sgd_solver.cpp:138] Iteration 4850, lr = 0.0005
I0228 15:35:44.184938 12900 solver.cpp:243] Iteration 4860, loss = 2.13397
I0228 15:35:44.185096 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.59014 (* 1 = 1.59014 loss)
I0228 15:35:44.185108 12900 sgd_solver.cpp:138] Iteration 4860, lr = 0.0005
I0228 15:36:17.105372 12900 solver.cpp:243] Iteration 4870, loss = 1.79035
I0228 15:36:17.105564 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.7325 (* 1 = 1.7325 loss)
I0228 15:36:17.105579 12900 sgd_solver.cpp:138] Iteration 4870, lr = 0.0005
I0228 15:36:55.624897 12900 solver.cpp:243] Iteration 4880, loss = 1.91886
I0228 15:36:55.625097 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.87888 (* 1 = 1.87888 loss)
I0228 15:36:55.625109 12900 sgd_solver.cpp:138] Iteration 4880, lr = 0.0005
I0228 15:37:25.203570 12900 solver.cpp:243] Iteration 4890, loss = 1.8038
I0228 15:37:25.203629 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.28508 (* 1 = 1.28508 loss)
I0228 15:37:25.203640 12900 sgd_solver.cpp:138] Iteration 4890, lr = 0.0005
I0228 15:38:06.939666 12900 solver.cpp:243] Iteration 4900, loss = 1.73242
I0228 15:38:06.939868 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72337 (* 1 = 1.72337 loss)
I0228 15:38:06.939884 12900 sgd_solver.cpp:138] Iteration 4900, lr = 0.0005
I0228 15:38:38.135895 12900 solver.cpp:243] Iteration 4910, loss = 2.10238
I0228 15:38:38.136108 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.17363 (* 1 = 2.17363 loss)
I0228 15:38:38.136123 12900 sgd_solver.cpp:138] Iteration 4910, lr = 0.0005
I0228 15:39:14.062947 12900 solver.cpp:243] Iteration 4920, loss = 1.87228
I0228 15:39:14.063122 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.32631 (* 1 = 1.32631 loss)
I0228 15:39:14.063133 12900 sgd_solver.cpp:138] Iteration 4920, lr = 0.0005
I0228 15:39:44.178241 12900 solver.cpp:243] Iteration 4930, loss = 1.74776
I0228 15:39:44.178411 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.92754 (* 1 = 1.92754 loss)
I0228 15:39:44.178424 12900 sgd_solver.cpp:138] Iteration 4930, lr = 0.0005
I0228 15:40:14.758364 12900 solver.cpp:243] Iteration 4940, loss = 1.99189
I0228 15:40:14.758561 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.41195 (* 1 = 1.41195 loss)
I0228 15:40:14.758575 12900 sgd_solver.cpp:138] Iteration 4940, lr = 0.0005
I0228 15:40:57.315506 12900 solver.cpp:243] Iteration 4950, loss = 1.94678
I0228 15:40:57.315688 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.3706 (* 1 = 1.3706 loss)
I0228 15:40:57.315703 12900 sgd_solver.cpp:138] Iteration 4950, lr = 0.0005
I0228 15:41:31.209370 12900 solver.cpp:243] Iteration 4960, loss = 2.03589
I0228 15:41:31.209528 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.67492 (* 1 = 2.67492 loss)
I0228 15:41:31.209542 12900 sgd_solver.cpp:138] Iteration 4960, lr = 0.0005
I0228 15:42:03.274472 12900 solver.cpp:243] Iteration 4970, loss = 1.88615
I0228 15:42:03.274667 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.462 (* 1 = 1.462 loss)
I0228 15:42:03.274679 12900 sgd_solver.cpp:138] Iteration 4970, lr = 0.0005
I0228 15:42:47.924084 12900 solver.cpp:243] Iteration 4980, loss = 1.90737
I0228 15:42:47.924275 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.50656 (* 1 = 1.50656 loss)
I0228 15:42:47.924288 12900 sgd_solver.cpp:138] Iteration 4980, lr = 0.0005
I0228 15:43:34.809010 12900 solver.cpp:243] Iteration 4990, loss = 2.14961
I0228 15:43:34.809206 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.67194 (* 1 = 1.67194 loss)
I0228 15:43:34.809221 12900 sgd_solver.cpp:138] Iteration 4990, lr = 0.0005
I0228 15:44:08.104038 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_5000.caffemodel
I0228 15:44:08.177243 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_5000.solverstate
I0228 15:44:11.951695 12900 solver.cpp:243] Iteration 5000, loss = 2.24967
I0228 15:44:11.951756 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.32424 (* 1 = 2.32424 loss)
I0228 15:44:11.951767 12900 sgd_solver.cpp:138] Iteration 5000, lr = 0.0005
I0228 15:44:44.209429 12900 solver.cpp:243] Iteration 5010, loss = 2.09201
I0228 15:44:44.209621 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.23089 (* 1 = 3.23089 loss)
I0228 15:44:44.209635 12900 sgd_solver.cpp:138] Iteration 5010, lr = 0.0005
I0228 15:45:17.987949 12900 solver.cpp:243] Iteration 5020, loss = 2.24789
I0228 15:45:17.988135 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.44857 (* 1 = 1.44857 loss)
I0228 15:45:17.988148 12900 sgd_solver.cpp:138] Iteration 5020, lr = 0.0005
I0228 15:45:59.984064 12900 solver.cpp:243] Iteration 5030, loss = 1.77056
I0228 15:45:59.984237 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.08088 (* 1 = 1.08088 loss)
I0228 15:45:59.984249 12900 sgd_solver.cpp:138] Iteration 5030, lr = 0.0005
I0228 15:46:32.012518 12900 solver.cpp:243] Iteration 5040, loss = 2.01013
I0228 15:46:32.012682 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.2702 (* 1 = 2.2702 loss)
I0228 15:46:32.012706 12900 sgd_solver.cpp:138] Iteration 5040, lr = 0.0005
I0228 15:47:15.938835 12900 solver.cpp:243] Iteration 5050, loss = 1.83593
I0228 15:47:15.939013 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.33984 (* 1 = 2.33984 loss)
I0228 15:47:15.939029 12900 sgd_solver.cpp:138] Iteration 5050, lr = 0.0005
I0228 15:47:58.084843 12900 solver.cpp:243] Iteration 5060, loss = 1.89626
I0228 15:47:58.085083 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.33057 (* 1 = 2.33057 loss)
I0228 15:47:58.085098 12900 sgd_solver.cpp:138] Iteration 5060, lr = 0.0005
I0228 15:48:35.848783 12900 solver.cpp:243] Iteration 5070, loss = 2.00012
I0228 15:48:35.848968 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.79128 (* 1 = 1.79128 loss)
I0228 15:48:35.848984 12900 sgd_solver.cpp:138] Iteration 5070, lr = 0.0005
I0228 15:49:06.257414 12900 solver.cpp:243] Iteration 5080, loss = 1.63409
I0228 15:49:06.257591 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.25276 (* 1 = 1.25276 loss)
I0228 15:49:06.257603 12900 sgd_solver.cpp:138] Iteration 5080, lr = 0.0005
I0228 15:49:41.300611 12900 solver.cpp:243] Iteration 5090, loss = 1.62969
I0228 15:49:41.300787 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.70754 (* 1 = 1.70754 loss)
I0228 15:49:41.300801 12900 sgd_solver.cpp:138] Iteration 5090, lr = 0.0005
I0228 15:50:13.542778 12900 solver.cpp:243] Iteration 5100, loss = 1.92229
I0228 15:50:13.542914 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.68019 (* 1 = 1.68019 loss)
I0228 15:50:13.542927 12900 sgd_solver.cpp:138] Iteration 5100, lr = 0.0005
I0228 15:50:45.194236 12900 solver.cpp:243] Iteration 5110, loss = 1.99459
I0228 15:50:45.194422 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.28298 (* 1 = 2.28298 loss)
I0228 15:50:45.194434 12900 sgd_solver.cpp:138] Iteration 5110, lr = 0.0005
I0228 15:51:22.559218 12900 solver.cpp:243] Iteration 5120, loss = 1.8296
I0228 15:51:22.559403 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.6808 (* 1 = 1.6808 loss)
I0228 15:51:22.559417 12900 sgd_solver.cpp:138] Iteration 5120, lr = 0.0005
I0228 15:51:56.696717 12900 solver.cpp:243] Iteration 5130, loss = 1.8667
I0228 15:51:56.696869 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61819 (* 1 = 1.61819 loss)
I0228 15:51:56.696884 12900 sgd_solver.cpp:138] Iteration 5130, lr = 0.0005
I0228 15:52:33.786058 12900 solver.cpp:243] Iteration 5140, loss = 2.45654
I0228 15:52:33.786213 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91578 (* 1 = 1.91578 loss)
I0228 15:52:33.786229 12900 sgd_solver.cpp:138] Iteration 5140, lr = 0.0005
I0228 15:53:15.466284 12900 solver.cpp:243] Iteration 5150, loss = 2.26639
I0228 15:53:15.466475 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.10441 (* 1 = 2.10441 loss)
I0228 15:53:15.466490 12900 sgd_solver.cpp:138] Iteration 5150, lr = 0.0005
I0228 15:53:49.345099 12900 solver.cpp:243] Iteration 5160, loss = 2.11852
I0228 15:53:49.345281 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.20939 (* 1 = 2.20939 loss)
I0228 15:53:49.345293 12900 sgd_solver.cpp:138] Iteration 5160, lr = 0.0005
I0228 15:54:21.698992 12900 solver.cpp:243] Iteration 5170, loss = 2.11067
I0228 15:54:21.699173 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.01297 (* 1 = 2.01297 loss)
I0228 15:54:21.699198 12900 sgd_solver.cpp:138] Iteration 5170, lr = 0.0005
I0228 15:54:48.673094 12900 solver.cpp:243] Iteration 5180, loss = 1.94199
I0228 15:54:48.673137 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.92111 (* 1 = 1.92111 loss)
I0228 15:54:48.673148 12900 sgd_solver.cpp:138] Iteration 5180, lr = 0.0005
I0228 15:55:25.567559 12900 solver.cpp:243] Iteration 5190, loss = 1.92029
I0228 15:55:25.567711 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.68629 (* 1 = 1.68629 loss)
I0228 15:55:25.567724 12900 sgd_solver.cpp:138] Iteration 5190, lr = 0.0005
I0228 15:56:02.435048 12900 solver.cpp:243] Iteration 5200, loss = 1.94641
I0228 15:56:02.435228 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.26546 (* 1 = 2.26546 loss)
I0228 15:56:02.435241 12900 sgd_solver.cpp:138] Iteration 5200, lr = 0.0005
I0228 15:56:32.756073 12900 solver.cpp:243] Iteration 5210, loss = 1.73194
I0228 15:56:32.756314 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.43226 (* 1 = 2.43226 loss)
I0228 15:56:32.756327 12900 sgd_solver.cpp:138] Iteration 5210, lr = 0.0005
I0228 15:57:07.868772 12900 solver.cpp:243] Iteration 5220, loss = 1.8832
I0228 15:57:07.868973 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.01106 (* 1 = 3.01106 loss)
I0228 15:57:07.868986 12900 sgd_solver.cpp:138] Iteration 5220, lr = 0.0005
I0228 15:57:41.399008 12900 solver.cpp:243] Iteration 5230, loss = 1.58905
I0228 15:57:41.399191 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.71333 (* 1 = 1.71333 loss)
I0228 15:57:41.399204 12900 sgd_solver.cpp:138] Iteration 5230, lr = 0.0005
I0228 15:58:17.388389 12900 solver.cpp:243] Iteration 5240, loss = 1.92165
I0228 15:58:17.388649 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91506 (* 1 = 1.91506 loss)
I0228 15:58:17.388695 12900 sgd_solver.cpp:138] Iteration 5240, lr = 0.0005
I0228 15:58:49.012382 12900 solver.cpp:243] Iteration 5250, loss = 1.73908
I0228 15:58:49.012506 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.93391 (* 1 = 1.93391 loss)
I0228 15:58:49.012521 12900 sgd_solver.cpp:138] Iteration 5250, lr = 0.0005
I0228 15:59:19.933228 12900 solver.cpp:243] Iteration 5260, loss = 1.892
I0228 15:59:19.933418 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61122 (* 1 = 1.61122 loss)
I0228 15:59:19.933432 12900 sgd_solver.cpp:138] Iteration 5260, lr = 0.0005
I0228 15:59:53.878753 12900 solver.cpp:243] Iteration 5270, loss = 1.91358
I0228 15:59:53.878927 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.48833 (* 1 = 2.48833 loss)
I0228 15:59:53.878939 12900 sgd_solver.cpp:138] Iteration 5270, lr = 0.0005
I0228 16:00:32.972111 12900 solver.cpp:243] Iteration 5280, loss = 1.96048
I0228 16:00:32.972281 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.977443 (* 1 = 0.977443 loss)
I0228 16:00:32.972295 12900 sgd_solver.cpp:138] Iteration 5280, lr = 0.0005
I0228 16:01:05.203402 12900 solver.cpp:243] Iteration 5290, loss = 1.82191
I0228 16:01:05.203586 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.19638 (* 1 = 2.19638 loss)
I0228 16:01:05.203601 12900 sgd_solver.cpp:138] Iteration 5290, lr = 0.0005
I0228 16:02:06.233466 12900 solver.cpp:243] Iteration 5300, loss = 2.14936
I0228 16:02:06.233649 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.67822 (* 1 = 2.67822 loss)
I0228 16:02:06.233660 12900 sgd_solver.cpp:138] Iteration 5300, lr = 0.0005
I0228 16:02:44.137631 12900 solver.cpp:243] Iteration 5310, loss = 1.78427
I0228 16:02:44.137790 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.82525 (* 1 = 1.82525 loss)
I0228 16:02:44.137804 12900 sgd_solver.cpp:138] Iteration 5310, lr = 0.0005
I0228 16:03:20.165899 12900 solver.cpp:243] Iteration 5320, loss = 1.97744
I0228 16:03:20.166085 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.34032 (* 1 = 2.34032 loss)
I0228 16:03:20.166100 12900 sgd_solver.cpp:138] Iteration 5320, lr = 0.0005
I0228 16:04:09.992856 12900 solver.cpp:243] Iteration 5330, loss = 1.55237
I0228 16:04:09.993006 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.7985 (* 1 = 1.7985 loss)
I0228 16:04:09.993028 12900 sgd_solver.cpp:138] Iteration 5330, lr = 0.0005
I0228 16:04:37.761027 12900 solver.cpp:243] Iteration 5340, loss = 2.01571
I0228 16:04:37.761078 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.31438 (* 1 = 1.31438 loss)
I0228 16:04:37.761092 12900 sgd_solver.cpp:138] Iteration 5340, lr = 0.0005
I0228 16:05:17.748412 12900 solver.cpp:243] Iteration 5350, loss = 1.70009
I0228 16:05:17.748584 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47997 (* 1 = 1.47997 loss)
I0228 16:05:17.748601 12900 sgd_solver.cpp:138] Iteration 5350, lr = 0.0005
I0228 16:06:00.735271 12900 solver.cpp:243] Iteration 5360, loss = 2.02233
I0228 16:06:00.735430 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.50695 (* 1 = 1.50695 loss)
I0228 16:06:00.735441 12900 sgd_solver.cpp:138] Iteration 5360, lr = 0.0005
I0228 16:06:45.021854 12900 solver.cpp:243] Iteration 5370, loss = 1.94932
I0228 16:06:45.022168 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.52808 (* 1 = 2.52808 loss)
I0228 16:06:45.022197 12900 sgd_solver.cpp:138] Iteration 5370, lr = 0.0005
I0228 16:07:19.557281 12900 solver.cpp:243] Iteration 5380, loss = 1.83724
I0228 16:07:19.557454 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.62196 (* 1 = 1.62196 loss)
I0228 16:07:19.557467 12900 sgd_solver.cpp:138] Iteration 5380, lr = 0.0005
I0228 16:07:49.514962 12900 solver.cpp:243] Iteration 5390, loss = 1.55423
I0228 16:07:49.515020 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.3843 (* 1 = 1.3843 loss)
I0228 16:07:49.515031 12900 sgd_solver.cpp:138] Iteration 5390, lr = 0.0005
I0228 16:08:19.569301 12900 solver.cpp:243] Iteration 5400, loss = 2.08404
I0228 16:08:19.569525 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96957 (* 1 = 1.96957 loss)
I0228 16:08:19.569537 12900 sgd_solver.cpp:138] Iteration 5400, lr = 0.0005
I0228 16:08:50.162541 12900 solver.cpp:243] Iteration 5410, loss = 1.83317
I0228 16:08:50.162741 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.51486 (* 1 = 1.51486 loss)
I0228 16:08:50.162756 12900 sgd_solver.cpp:138] Iteration 5410, lr = 0.0005
I0228 16:09:23.171491 12900 solver.cpp:243] Iteration 5420, loss = 1.87082
I0228 16:09:23.171653 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.93185 (* 1 = 1.93185 loss)
I0228 16:09:23.171666 12900 sgd_solver.cpp:138] Iteration 5420, lr = 0.0005
I0228 16:09:56.495327 12900 solver.cpp:243] Iteration 5430, loss = 1.87375
I0228 16:09:56.495504 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.95819 (* 1 = 1.95819 loss)
I0228 16:09:56.495517 12900 sgd_solver.cpp:138] Iteration 5430, lr = 0.0005
I0228 16:10:34.009522 12900 solver.cpp:243] Iteration 5440, loss = 1.89127
I0228 16:10:34.009686 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.98521 (* 1 = 1.98521 loss)
I0228 16:10:34.009699 12900 sgd_solver.cpp:138] Iteration 5440, lr = 0.0005
I0228 16:11:08.585736 12900 solver.cpp:243] Iteration 5450, loss = 1.88455
I0228 16:11:08.585954 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.82118 (* 1 = 1.82118 loss)
I0228 16:11:08.585985 12900 sgd_solver.cpp:138] Iteration 5450, lr = 0.0005
I0228 16:11:46.038864 12900 solver.cpp:243] Iteration 5460, loss = 2.03004
I0228 16:11:46.039070 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.95569 (* 1 = 1.95569 loss)
I0228 16:11:46.039093 12900 sgd_solver.cpp:138] Iteration 5460, lr = 0.0005
I0228 16:12:25.279012 12900 solver.cpp:243] Iteration 5470, loss = 1.74083
I0228 16:12:25.279223 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.0138 (* 1 = 2.0138 loss)
I0228 16:12:25.279242 12900 sgd_solver.cpp:138] Iteration 5470, lr = 0.0005
I0228 16:13:03.943838 12900 solver.cpp:243] Iteration 5480, loss = 1.83297
I0228 16:13:03.944070 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.6743 (* 1 = 1.6743 loss)
I0228 16:13:03.944092 12900 sgd_solver.cpp:138] Iteration 5480, lr = 0.0005
I0228 16:13:50.101781 12900 solver.cpp:243] Iteration 5490, loss = 1.85688
I0228 16:13:50.102082 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.6037 (* 1 = 1.6037 loss)
I0228 16:13:50.102129 12900 sgd_solver.cpp:138] Iteration 5490, lr = 0.0005
I0228 16:14:35.557718 12900 solver.cpp:243] Iteration 5500, loss = 1.93536
I0228 16:14:35.558075 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42897 (* 1 = 1.42897 loss)
I0228 16:14:35.558118 12900 sgd_solver.cpp:138] Iteration 5500, lr = 0.0005
I0228 16:15:16.552744 12900 solver.cpp:243] Iteration 5510, loss = 1.66552
I0228 16:15:16.552912 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9335 (* 1 = 1.9335 loss)
I0228 16:15:16.552925 12900 sgd_solver.cpp:138] Iteration 5510, lr = 0.0005
I0228 16:15:53.383472 12900 solver.cpp:243] Iteration 5520, loss = 1.7603
I0228 16:15:53.383652 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80605 (* 1 = 1.80605 loss)
I0228 16:15:53.383666 12900 sgd_solver.cpp:138] Iteration 5520, lr = 0.0005
I0228 16:16:45.438968 12900 solver.cpp:243] Iteration 5530, loss = 1.9064
I0228 16:16:45.439157 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.14281 (* 1 = 2.14281 loss)
I0228 16:16:45.439172 12900 sgd_solver.cpp:138] Iteration 5530, lr = 0.0005
I0228 16:17:22.159183 12900 solver.cpp:243] Iteration 5540, loss = 1.90486
I0228 16:17:22.159322 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.31533 (* 1 = 1.31533 loss)
I0228 16:17:22.159335 12900 sgd_solver.cpp:138] Iteration 5540, lr = 0.0005
I0228 16:18:04.904422 12900 solver.cpp:243] Iteration 5550, loss = 1.84932
I0228 16:18:04.904553 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.29914 (* 1 = 2.29914 loss)
I0228 16:18:04.904567 12900 sgd_solver.cpp:138] Iteration 5550, lr = 0.0005
I0228 16:18:41.718526 12900 solver.cpp:243] Iteration 5560, loss = 1.95143
I0228 16:18:41.718675 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.28517 (* 1 = 2.28517 loss)
I0228 16:18:41.718688 12900 sgd_solver.cpp:138] Iteration 5560, lr = 0.0005
I0228 16:19:16.787236 12900 solver.cpp:243] Iteration 5570, loss = 1.73635
I0228 16:19:16.787489 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.24848 (* 1 = 1.24848 loss)
I0228 16:19:16.787509 12900 sgd_solver.cpp:138] Iteration 5570, lr = 0.0005
I0228 16:19:50.893455 12900 solver.cpp:243] Iteration 5580, loss = 1.95688
I0228 16:19:50.893626 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.15845 (* 1 = 2.15845 loss)
I0228 16:19:50.893640 12900 sgd_solver.cpp:138] Iteration 5580, lr = 0.0005
I0228 16:20:20.313834 12900 solver.cpp:243] Iteration 5590, loss = 1.85212
I0228 16:20:20.313894 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.6274 (* 1 = 1.6274 loss)
I0228 16:20:20.313904 12900 sgd_solver.cpp:138] Iteration 5590, lr = 0.0005
I0228 16:20:29.099216 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 16:21:07.589179 12900 solver.cpp:243] Iteration 5600, loss = 1.89627
I0228 16:21:07.589344 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.62948 (* 1 = 2.62948 loss)
I0228 16:21:07.589359 12900 sgd_solver.cpp:138] Iteration 5600, lr = 0.0005
I0228 16:21:37.576175 12900 solver.cpp:243] Iteration 5610, loss = 1.85268
I0228 16:21:37.576237 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.89197 (* 1 = 1.89197 loss)
I0228 16:21:37.576247 12900 sgd_solver.cpp:138] Iteration 5610, lr = 0.0005
I0228 16:22:23.891607 12900 solver.cpp:243] Iteration 5620, loss = 1.84155
I0228 16:22:23.891778 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.64902 (* 1 = 1.64902 loss)
I0228 16:22:23.891793 12900 sgd_solver.cpp:138] Iteration 5620, lr = 0.0005
I0228 16:22:59.501933 12900 solver.cpp:243] Iteration 5630, loss = 1.78393
I0228 16:22:59.502120 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00895 (* 1 = 2.00895 loss)
I0228 16:22:59.502136 12900 sgd_solver.cpp:138] Iteration 5630, lr = 0.0005
I0228 16:23:35.080425 12900 solver.cpp:243] Iteration 5640, loss = 2.10121
I0228 16:23:35.080610 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.63823 (* 1 = 1.63823 loss)
I0228 16:23:35.080622 12900 sgd_solver.cpp:138] Iteration 5640, lr = 0.0005
I0228 16:24:10.268112 12900 solver.cpp:243] Iteration 5650, loss = 1.90476
I0228 16:24:10.268291 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.17939 (* 1 = 1.17939 loss)
I0228 16:24:10.268306 12900 sgd_solver.cpp:138] Iteration 5650, lr = 0.0005
I0228 16:24:40.731130 12900 solver.cpp:243] Iteration 5660, loss = 1.8136
I0228 16:24:40.731313 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.8415 (* 1 = 1.8415 loss)
I0228 16:24:40.731326 12900 sgd_solver.cpp:138] Iteration 5660, lr = 0.0005
I0228 16:25:12.010017 12900 solver.cpp:243] Iteration 5670, loss = 2.00533
I0228 16:25:12.010179 12900 solver.cpp:259]     Train net output #0: mbox_loss = 4.35542 (* 1 = 4.35542 loss)
I0228 16:25:12.010201 12900 sgd_solver.cpp:138] Iteration 5670, lr = 0.0005
I0228 16:25:49.687891 12900 solver.cpp:243] Iteration 5680, loss = 1.78918
I0228 16:25:49.688107 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.36878 (* 1 = 2.36878 loss)
I0228 16:25:49.688122 12900 sgd_solver.cpp:138] Iteration 5680, lr = 0.0005
I0228 16:26:20.810582 12900 solver.cpp:243] Iteration 5690, loss = 2.03878
I0228 16:26:20.810741 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.51366 (* 1 = 2.51366 loss)
I0228 16:26:20.810755 12900 sgd_solver.cpp:138] Iteration 5690, lr = 0.0005
I0228 16:27:01.033396 12900 solver.cpp:243] Iteration 5700, loss = 1.74565
I0228 16:27:01.033548 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.39216 (* 1 = 1.39216 loss)
I0228 16:27:01.033562 12900 sgd_solver.cpp:138] Iteration 5700, lr = 0.0005
I0228 16:27:32.014482 12900 solver.cpp:243] Iteration 5710, loss = 1.97204
I0228 16:27:32.014672 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80574 (* 1 = 1.80574 loss)
I0228 16:27:32.014690 12900 sgd_solver.cpp:138] Iteration 5710, lr = 0.0005
I0228 16:28:12.560312 12900 solver.cpp:243] Iteration 5720, loss = 1.91005
I0228 16:28:12.560477 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.19139 (* 1 = 2.19139 loss)
I0228 16:28:12.560490 12900 sgd_solver.cpp:138] Iteration 5720, lr = 0.0005
I0228 16:28:47.054538 12900 solver.cpp:243] Iteration 5730, loss = 2.14066
I0228 16:28:47.054734 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.62237 (* 1 = 2.62237 loss)
I0228 16:28:47.054746 12900 sgd_solver.cpp:138] Iteration 5730, lr = 0.0005
I0228 16:29:21.652637 12900 solver.cpp:243] Iteration 5740, loss = 1.53245
I0228 16:29:21.652797 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.90127 (* 1 = 1.90127 loss)
I0228 16:29:21.652812 12900 sgd_solver.cpp:138] Iteration 5740, lr = 0.0005
I0228 16:30:01.364679 12900 solver.cpp:243] Iteration 5750, loss = 2.00598
I0228 16:30:01.364840 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.20842 (* 1 = 1.20842 loss)
I0228 16:30:01.364852 12900 sgd_solver.cpp:138] Iteration 5750, lr = 0.0005
I0228 16:30:38.361044 12900 solver.cpp:243] Iteration 5760, loss = 1.71407
I0228 16:30:38.361237 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.10225 (* 1 = 2.10225 loss)
I0228 16:30:38.361253 12900 sgd_solver.cpp:138] Iteration 5760, lr = 0.0005
I0228 16:31:11.819841 12900 solver.cpp:243] Iteration 5770, loss = 1.77326
I0228 16:31:11.819989 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.39152 (* 1 = 2.39152 loss)
I0228 16:31:11.820003 12900 sgd_solver.cpp:138] Iteration 5770, lr = 0.0005
I0228 16:31:46.001852 12900 solver.cpp:243] Iteration 5780, loss = 1.93707
I0228 16:31:46.002004 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.16823 (* 1 = 2.16823 loss)
I0228 16:31:46.002019 12900 sgd_solver.cpp:138] Iteration 5780, lr = 0.0005
I0228 16:32:25.516158 12900 solver.cpp:243] Iteration 5790, loss = 1.68018
I0228 16:32:25.516324 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.03235 (* 1 = 1.03235 loss)
I0228 16:32:25.516340 12900 sgd_solver.cpp:138] Iteration 5790, lr = 0.0005
I0228 16:32:55.223367 12900 solver.cpp:243] Iteration 5800, loss = 1.74735
I0228 16:32:55.223420 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.2883 (* 1 = 2.2883 loss)
I0228 16:32:55.223431 12900 sgd_solver.cpp:138] Iteration 5800, lr = 0.0005
I0228 16:33:30.945480 12900 solver.cpp:243] Iteration 5810, loss = 1.61145
I0228 16:33:30.945646 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.59082 (* 1 = 1.59082 loss)
I0228 16:33:30.945659 12900 sgd_solver.cpp:138] Iteration 5810, lr = 0.0005
I0228 16:34:07.028631 12900 solver.cpp:243] Iteration 5820, loss = 2.06053
I0228 16:34:07.028790 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38218 (* 1 = 2.38218 loss)
I0228 16:34:07.028805 12900 sgd_solver.cpp:138] Iteration 5820, lr = 0.0005
I0228 16:34:39.261353 12900 solver.cpp:243] Iteration 5830, loss = 1.91166
I0228 16:34:39.261498 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.71528 (* 1 = 2.71528 loss)
I0228 16:34:39.261515 12900 sgd_solver.cpp:138] Iteration 5830, lr = 0.0005
I0228 16:35:22.591609 12900 solver.cpp:243] Iteration 5840, loss = 1.76998
I0228 16:35:22.591806 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.2547 (* 1 = 2.2547 loss)
I0228 16:35:22.591820 12900 sgd_solver.cpp:138] Iteration 5840, lr = 0.0005
I0228 16:35:56.505347 12900 solver.cpp:243] Iteration 5850, loss = 1.9616
I0228 16:35:56.505522 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.7706 (* 1 = 2.7706 loss)
I0228 16:35:56.505537 12900 sgd_solver.cpp:138] Iteration 5850, lr = 0.0005
I0228 16:36:27.660718 12900 solver.cpp:243] Iteration 5860, loss = 1.91583
I0228 16:36:27.660894 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.8688 (* 1 = 2.8688 loss)
I0228 16:36:27.660908 12900 sgd_solver.cpp:138] Iteration 5860, lr = 0.0005
I0228 16:37:07.558460 12900 solver.cpp:243] Iteration 5870, loss = 1.97111
I0228 16:37:07.558660 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.53359 (* 1 = 2.53359 loss)
I0228 16:37:07.558678 12900 sgd_solver.cpp:138] Iteration 5870, lr = 0.0005
I0228 16:37:46.211097 12900 solver.cpp:243] Iteration 5880, loss = 1.95132
I0228 16:37:46.211263 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.09616 (* 1 = 2.09616 loss)
I0228 16:37:46.211277 12900 sgd_solver.cpp:138] Iteration 5880, lr = 0.0005
I0228 16:38:17.464848 12900 solver.cpp:243] Iteration 5890, loss = 1.90185
I0228 16:38:17.464998 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.31947 (* 1 = 1.31947 loss)
I0228 16:38:17.465011 12900 sgd_solver.cpp:138] Iteration 5890, lr = 0.0005
I0228 16:38:51.669976 12900 solver.cpp:243] Iteration 5900, loss = 2.00176
I0228 16:38:51.670169 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.66277 (* 1 = 1.66277 loss)
I0228 16:38:51.670183 12900 sgd_solver.cpp:138] Iteration 5900, lr = 0.0005
I0228 16:39:32.450023 12900 solver.cpp:243] Iteration 5910, loss = 2.1034
I0228 16:39:32.450186 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.26099 (* 1 = 3.26099 loss)
I0228 16:39:32.450199 12900 sgd_solver.cpp:138] Iteration 5910, lr = 0.0005
I0228 16:40:22.063967 12900 solver.cpp:243] Iteration 5920, loss = 1.87579
I0228 16:40:22.064175 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.11744 (* 1 = 2.11744 loss)
I0228 16:40:22.064188 12900 sgd_solver.cpp:138] Iteration 5920, lr = 0.0005
I0228 16:40:57.374344 12900 solver.cpp:243] Iteration 5930, loss = 2.04562
I0228 16:40:57.374521 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.73739 (* 1 = 1.73739 loss)
I0228 16:40:57.374538 12900 sgd_solver.cpp:138] Iteration 5930, lr = 0.0005
I0228 16:41:28.763948 12900 solver.cpp:243] Iteration 5940, loss = 2.06675
I0228 16:41:28.764101 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.89364 (* 1 = 1.89364 loss)
I0228 16:41:28.764114 12900 sgd_solver.cpp:138] Iteration 5940, lr = 0.0005
I0228 16:41:58.444778 12900 solver.cpp:243] Iteration 5950, loss = 1.81256
I0228 16:41:58.444830 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.63987 (* 1 = 1.63987 loss)
I0228 16:41:58.444844 12900 sgd_solver.cpp:138] Iteration 5950, lr = 0.0005
I0228 16:42:30.056409 12900 solver.cpp:243] Iteration 5960, loss = 1.97474
I0228 16:42:30.056565 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78751 (* 1 = 1.78751 loss)
I0228 16:42:30.056577 12900 sgd_solver.cpp:138] Iteration 5960, lr = 0.0005
I0228 16:43:10.665381 12900 solver.cpp:243] Iteration 5970, loss = 1.65651
I0228 16:43:10.665580 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.13625 (* 1 = 3.13625 loss)
I0228 16:43:10.665596 12900 sgd_solver.cpp:138] Iteration 5970, lr = 0.0005
I0228 16:43:46.595118 12900 solver.cpp:243] Iteration 5980, loss = 2.20377
I0228 16:43:46.595309 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.04055 (* 1 = 3.04055 loss)
I0228 16:43:46.595324 12900 sgd_solver.cpp:138] Iteration 5980, lr = 0.0005
I0228 16:44:24.151423 12900 solver.cpp:243] Iteration 5990, loss = 1.62612
I0228 16:44:24.151612 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.11696 (* 1 = 2.11696 loss)
I0228 16:44:24.151625 12900 sgd_solver.cpp:138] Iteration 5990, lr = 0.0005
I0228 16:44:52.656394 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_6000.caffemodel
I0228 16:44:52.732760 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_6000.solverstate
I0228 16:44:55.375581 12900 solver.cpp:243] Iteration 6000, loss = 1.76737
I0228 16:44:55.375826 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.51281 (* 1 = 1.51281 loss)
I0228 16:44:55.375846 12900 sgd_solver.cpp:138] Iteration 6000, lr = 0.0005
I0228 16:45:24.964762 12900 solver.cpp:243] Iteration 6010, loss = 1.7901
I0228 16:45:24.964819 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.39735 (* 1 = 1.39735 loss)
I0228 16:45:24.964850 12900 sgd_solver.cpp:138] Iteration 6010, lr = 0.0005
I0228 16:46:06.469650 12900 solver.cpp:243] Iteration 6020, loss = 1.8014
I0228 16:46:06.469841 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.1517 (* 1 = 3.1517 loss)
I0228 16:46:06.469856 12900 sgd_solver.cpp:138] Iteration 6020, lr = 0.0005
I0228 16:46:44.985332 12900 solver.cpp:243] Iteration 6030, loss = 2.00469
I0228 16:46:44.985569 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.34239 (* 1 = 1.34239 loss)
I0228 16:46:44.985582 12900 sgd_solver.cpp:138] Iteration 6030, lr = 0.0005
I0228 16:47:17.117643 12900 solver.cpp:243] Iteration 6040, loss = 1.8434
I0228 16:47:17.117831 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.63654 (* 1 = 1.63654 loss)
I0228 16:47:17.117846 12900 sgd_solver.cpp:138] Iteration 6040, lr = 0.0005
I0228 16:47:53.630656 12900 solver.cpp:243] Iteration 6050, loss = 2.08754
I0228 16:47:53.630841 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.65775 (* 1 = 1.65775 loss)
I0228 16:47:53.630853 12900 sgd_solver.cpp:138] Iteration 6050, lr = 0.0005
I0228 16:48:23.957743 12900 solver.cpp:243] Iteration 6060, loss = 2.07871
I0228 16:48:23.958308 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.17026 (* 1 = 2.17026 loss)
I0228 16:48:23.958323 12900 sgd_solver.cpp:138] Iteration 6060, lr = 0.0005
I0228 16:49:02.515169 12900 solver.cpp:243] Iteration 6070, loss = 1.59964
I0228 16:49:02.515331 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.0102 (* 1 = 1.0102 loss)
I0228 16:49:02.515346 12900 sgd_solver.cpp:138] Iteration 6070, lr = 0.0005
I0228 16:49:45.837093 12900 solver.cpp:243] Iteration 6080, loss = 1.65422
I0228 16:49:45.837276 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61764 (* 1 = 1.61764 loss)
I0228 16:49:45.837293 12900 sgd_solver.cpp:138] Iteration 6080, lr = 0.0005
I0228 16:50:12.664984 12900 solver.cpp:243] Iteration 6090, loss = 1.91047
I0228 16:50:12.665038 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.5936 (* 1 = 1.5936 loss)
I0228 16:50:12.665051 12900 sgd_solver.cpp:138] Iteration 6090, lr = 0.0005
I0228 16:50:45.361232 12900 solver.cpp:243] Iteration 6100, loss = 1.90472
I0228 16:50:45.361428 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.33816 (* 1 = 1.33816 loss)
I0228 16:50:45.361440 12900 sgd_solver.cpp:138] Iteration 6100, lr = 0.0005
I0228 16:51:13.957962 12900 solver.cpp:243] Iteration 6110, loss = 2.34029
I0228 16:51:13.958016 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.31107 (* 1 = 1.31107 loss)
I0228 16:51:13.958029 12900 sgd_solver.cpp:138] Iteration 6110, lr = 0.0005
I0228 16:51:42.409224 12900 solver.cpp:243] Iteration 6120, loss = 1.80262
I0228 16:51:42.409399 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.2031 (* 1 = 2.2031 loss)
I0228 16:51:42.409413 12900 sgd_solver.cpp:138] Iteration 6120, lr = 0.0005
I0228 16:52:18.882941 12900 solver.cpp:243] Iteration 6130, loss = 1.68498
I0228 16:52:18.883114 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.48732 (* 1 = 1.48732 loss)
I0228 16:52:18.883128 12900 sgd_solver.cpp:138] Iteration 6130, lr = 0.0005
I0228 16:52:48.821652 12900 solver.cpp:243] Iteration 6140, loss = 1.58279
I0228 16:52:48.821696 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.48512 (* 1 = 1.48512 loss)
I0228 16:52:48.821707 12900 sgd_solver.cpp:138] Iteration 6140, lr = 0.0005
I0228 16:53:22.640564 12900 solver.cpp:243] Iteration 6150, loss = 1.76487
I0228 16:53:22.640779 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00299 (* 1 = 2.00299 loss)
I0228 16:53:22.640792 12900 sgd_solver.cpp:138] Iteration 6150, lr = 0.0005
I0228 16:54:05.841542 12900 solver.cpp:243] Iteration 6160, loss = 1.90393
I0228 16:54:05.841737 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.98292 (* 1 = 1.98292 loss)
I0228 16:54:05.841750 12900 sgd_solver.cpp:138] Iteration 6160, lr = 0.0005
I0228 16:54:47.327188 12900 solver.cpp:243] Iteration 6170, loss = 1.80906
I0228 16:54:47.327340 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.44537 (* 1 = 1.44537 loss)
I0228 16:54:47.327361 12900 sgd_solver.cpp:138] Iteration 6170, lr = 0.0005
I0228 16:55:20.987035 12900 solver.cpp:243] Iteration 6180, loss = 1.76982
I0228 16:55:20.987197 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.71797 (* 1 = 1.71797 loss)
I0228 16:55:20.987215 12900 sgd_solver.cpp:138] Iteration 6180, lr = 0.0005
I0228 16:55:55.501519 12900 solver.cpp:243] Iteration 6190, loss = 2.07239
I0228 16:55:55.501693 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.49144 (* 1 = 1.49144 loss)
I0228 16:55:55.501705 12900 sgd_solver.cpp:138] Iteration 6190, lr = 0.0005
I0228 16:56:30.390802 12900 solver.cpp:243] Iteration 6200, loss = 1.98322
I0228 16:56:30.391044 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9632 (* 1 = 1.9632 loss)
I0228 16:56:30.391062 12900 sgd_solver.cpp:138] Iteration 6200, lr = 0.0005
I0228 16:57:13.333690 12900 solver.cpp:243] Iteration 6210, loss = 1.62055
I0228 16:57:13.333899 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.24098 (* 1 = 1.24098 loss)
I0228 16:57:13.333912 12900 sgd_solver.cpp:138] Iteration 6210, lr = 0.0005
I0228 16:57:51.722555 12900 solver.cpp:243] Iteration 6220, loss = 2.07816
I0228 16:57:51.722709 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.81446 (* 1 = 1.81446 loss)
I0228 16:57:51.722721 12900 sgd_solver.cpp:138] Iteration 6220, lr = 0.0005
I0228 16:58:24.201745 12900 solver.cpp:243] Iteration 6230, loss = 1.8856
I0228 16:58:24.201907 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.84383 (* 1 = 2.84383 loss)
I0228 16:58:24.201920 12900 sgd_solver.cpp:138] Iteration 6230, lr = 0.0005
I0228 16:59:16.173401 12900 solver.cpp:243] Iteration 6240, loss = 1.74486
I0228 16:59:16.173579 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61318 (* 1 = 1.61318 loss)
I0228 16:59:16.173593 12900 sgd_solver.cpp:138] Iteration 6240, lr = 0.0005
I0228 16:59:58.211277 12900 solver.cpp:243] Iteration 6250, loss = 1.94235
I0228 16:59:58.211439 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.60243 (* 1 = 3.60243 loss)
I0228 16:59:58.211452 12900 sgd_solver.cpp:138] Iteration 6250, lr = 0.0005
I0228 17:00:32.843448 12900 solver.cpp:243] Iteration 6260, loss = 2.04341
I0228 17:00:32.843688 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.64175 (* 1 = 1.64175 loss)
I0228 17:00:32.843711 12900 sgd_solver.cpp:138] Iteration 6260, lr = 0.0005
I0228 17:01:19.015494 12900 solver.cpp:243] Iteration 6270, loss = 1.71738
I0228 17:01:19.015682 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75535 (* 1 = 1.75535 loss)
I0228 17:01:19.015696 12900 sgd_solver.cpp:138] Iteration 6270, lr = 0.0005
I0228 17:01:52.602798 12900 solver.cpp:243] Iteration 6280, loss = 1.909
I0228 17:01:52.602952 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.4154 (* 1 = 1.4154 loss)
I0228 17:01:52.602967 12900 sgd_solver.cpp:138] Iteration 6280, lr = 0.0005
I0228 17:02:40.143275 12900 solver.cpp:243] Iteration 6290, loss = 2.03735
I0228 17:02:40.143755 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9818 (* 1 = 1.9818 loss)
I0228 17:02:40.143787 12900 sgd_solver.cpp:138] Iteration 6290, lr = 0.0005
I0228 17:03:09.222158 12900 solver.cpp:243] Iteration 6300, loss = 1.66853
I0228 17:03:09.222236 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.52533 (* 1 = 1.52533 loss)
I0228 17:03:09.222247 12900 sgd_solver.cpp:138] Iteration 6300, lr = 0.0005
I0228 17:03:39.212766 12900 solver.cpp:243] Iteration 6310, loss = 1.96953
I0228 17:03:39.212990 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.27825 (* 1 = 2.27825 loss)
I0228 17:03:39.213008 12900 sgd_solver.cpp:138] Iteration 6310, lr = 0.0005
I0228 17:04:15.934432 12900 solver.cpp:243] Iteration 6320, loss = 1.76111
I0228 17:04:15.934612 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96367 (* 1 = 1.96367 loss)
I0228 17:04:15.934625 12900 sgd_solver.cpp:138] Iteration 6320, lr = 0.0005
I0228 17:04:44.235332 12900 solver.cpp:243] Iteration 6330, loss = 1.78197
I0228 17:04:44.235386 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.11195 (* 1 = 2.11195 loss)
I0228 17:04:44.235396 12900 sgd_solver.cpp:138] Iteration 6330, lr = 0.0005
I0228 17:05:14.924186 12900 solver.cpp:243] Iteration 6340, loss = 1.66381
I0228 17:05:14.924394 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.12137 (* 1 = 1.12137 loss)
I0228 17:05:14.924407 12900 sgd_solver.cpp:138] Iteration 6340, lr = 0.0005
I0228 17:05:43.828675 12900 solver.cpp:243] Iteration 6350, loss = 1.97182
I0228 17:05:43.828738 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.0083 (* 1 = 2.0083 loss)
I0228 17:05:43.828748 12900 sgd_solver.cpp:138] Iteration 6350, lr = 0.0005
I0228 17:06:33.019309 12900 solver.cpp:243] Iteration 6360, loss = 1.89879
I0228 17:06:33.020033 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.11935 (* 1 = 1.11935 loss)
I0228 17:06:33.020050 12900 sgd_solver.cpp:138] Iteration 6360, lr = 0.0005
I0228 17:07:02.625480 12900 solver.cpp:243] Iteration 6370, loss = 1.8227
I0228 17:07:02.625531 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.17645 (* 1 = 2.17645 loss)
I0228 17:07:02.625540 12900 sgd_solver.cpp:138] Iteration 6370, lr = 0.0005
I0228 17:07:31.460067 12900 solver.cpp:243] Iteration 6380, loss = 1.88479
I0228 17:07:31.461210 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.64384 (* 1 = 2.64384 loss)
I0228 17:07:31.461226 12900 sgd_solver.cpp:138] Iteration 6380, lr = 0.0005
I0228 17:08:00.869063 12900 solver.cpp:243] Iteration 6390, loss = 1.76503
I0228 17:08:00.869109 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.62535 (* 1 = 1.62535 loss)
I0228 17:08:00.869120 12900 sgd_solver.cpp:138] Iteration 6390, lr = 0.0005
I0228 17:08:34.086395 12900 solver.cpp:243] Iteration 6400, loss = 1.77195
I0228 17:08:34.086580 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.71506 (* 1 = 1.71506 loss)
I0228 17:08:34.086594 12900 sgd_solver.cpp:138] Iteration 6400, lr = 0.0005
I0228 17:09:05.385465 12900 solver.cpp:243] Iteration 6410, loss = 1.86134
I0228 17:09:05.385669 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.36675 (* 1 = 2.36675 loss)
I0228 17:09:05.385687 12900 sgd_solver.cpp:138] Iteration 6410, lr = 0.0005
I0228 17:09:38.821563 12900 solver.cpp:243] Iteration 6420, loss = 2.01224
I0228 17:09:38.821741 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.6787 (* 1 = 1.6787 loss)
I0228 17:09:38.821753 12900 sgd_solver.cpp:138] Iteration 6420, lr = 0.0005
I0228 17:10:05.954200 12900 solver.cpp:243] Iteration 6430, loss = 1.60148
I0228 17:10:05.954259 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61037 (* 1 = 1.61037 loss)
I0228 17:10:05.954270 12900 sgd_solver.cpp:138] Iteration 6430, lr = 0.0005
I0228 17:10:37.042011 12900 solver.cpp:243] Iteration 6440, loss = 2.08398
I0228 17:10:37.042160 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.4695 (* 1 = 3.4695 loss)
I0228 17:10:37.042174 12900 sgd_solver.cpp:138] Iteration 6440, lr = 0.0005
I0228 17:11:18.159324 12900 solver.cpp:243] Iteration 6450, loss = 1.86516
I0228 17:11:18.159538 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.18917 (* 1 = 2.18917 loss)
I0228 17:11:18.159554 12900 sgd_solver.cpp:138] Iteration 6450, lr = 0.0005
I0228 17:11:53.388622 12900 solver.cpp:243] Iteration 6460, loss = 1.69906
I0228 17:11:53.388865 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.4462 (* 1 = 1.4462 loss)
I0228 17:11:53.388880 12900 sgd_solver.cpp:138] Iteration 6460, lr = 0.0005
I0228 17:12:33.603878 12900 solver.cpp:243] Iteration 6470, loss = 1.67976
I0228 17:12:33.604076 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94537 (* 1 = 1.94537 loss)
I0228 17:12:33.604090 12900 sgd_solver.cpp:138] Iteration 6470, lr = 0.0005
I0228 17:13:31.901358 12900 solver.cpp:243] Iteration 6480, loss = 1.66014
I0228 17:13:31.901509 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.39423 (* 1 = 1.39423 loss)
I0228 17:13:31.901523 12900 sgd_solver.cpp:138] Iteration 6480, lr = 0.0005
I0228 17:14:07.176592 12900 solver.cpp:243] Iteration 6490, loss = 1.88307
I0228 17:14:07.176769 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.27708 (* 1 = 1.27708 loss)
I0228 17:14:07.176781 12900 sgd_solver.cpp:138] Iteration 6490, lr = 0.0005
I0228 17:14:37.815070 12900 solver.cpp:243] Iteration 6500, loss = 1.62855
I0228 17:14:37.815562 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.20007 (* 1 = 1.20007 loss)
I0228 17:14:37.815577 12900 sgd_solver.cpp:138] Iteration 6500, lr = 0.0005
I0228 17:15:18.083709 12900 solver.cpp:243] Iteration 6510, loss = 1.94019
I0228 17:15:18.083933 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.03955 (* 1 = 2.03955 loss)
I0228 17:15:18.083946 12900 sgd_solver.cpp:138] Iteration 6510, lr = 0.0005
I0228 17:15:55.990885 12900 solver.cpp:243] Iteration 6520, loss = 1.63517
I0228 17:15:55.991060 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.4921 (* 1 = 1.4921 loss)
I0228 17:15:55.991078 12900 sgd_solver.cpp:138] Iteration 6520, lr = 0.0005
I0228 17:16:23.562410 12900 solver.cpp:243] Iteration 6530, loss = 1.88129
I0228 17:16:23.562469 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.82141 (* 1 = 1.82141 loss)
I0228 17:16:23.562480 12900 sgd_solver.cpp:138] Iteration 6530, lr = 0.0005
I0228 17:17:09.213034 12900 solver.cpp:243] Iteration 6540, loss = 2.0957
I0228 17:17:09.213223 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.21387 (* 1 = 2.21387 loss)
I0228 17:17:09.213238 12900 sgd_solver.cpp:138] Iteration 6540, lr = 0.0005
I0228 17:17:40.814795 12900 solver.cpp:243] Iteration 6550, loss = 1.74773
I0228 17:17:40.814961 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.37284 (* 1 = 1.37284 loss)
I0228 17:17:40.814973 12900 sgd_solver.cpp:138] Iteration 6550, lr = 0.0005
I0228 17:18:11.836200 12900 solver.cpp:243] Iteration 6560, loss = 1.85427
I0228 17:18:11.836421 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.33063 (* 1 = 1.33063 loss)
I0228 17:18:11.836436 12900 sgd_solver.cpp:138] Iteration 6560, lr = 0.0005
I0228 17:18:49.590497 12900 solver.cpp:243] Iteration 6570, loss = 1.96188
I0228 17:18:49.590643 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.66072 (* 1 = 2.66072 loss)
I0228 17:18:49.590656 12900 sgd_solver.cpp:138] Iteration 6570, lr = 0.0005
I0228 17:19:19.532845 12900 solver.cpp:243] Iteration 6580, loss = 1.73359
I0228 17:19:19.532902 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.66833 (* 1 = 1.66833 loss)
I0228 17:19:19.532912 12900 sgd_solver.cpp:138] Iteration 6580, lr = 0.0005
I0228 17:19:51.216658 12900 solver.cpp:243] Iteration 6590, loss = 2.02677
I0228 17:19:51.218250 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.82418 (* 1 = 2.82418 loss)
I0228 17:19:51.218263 12900 sgd_solver.cpp:138] Iteration 6590, lr = 0.0005
I0228 17:20:32.268908 12900 solver.cpp:243] Iteration 6600, loss = 1.73249
I0228 17:20:32.269863 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.58851 (* 1 = 1.58851 loss)
I0228 17:20:32.269918 12900 sgd_solver.cpp:138] Iteration 6600, lr = 0.0005
I0228 17:21:13.080488 12900 solver.cpp:243] Iteration 6610, loss = 1.68971
I0228 17:21:13.080687 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42747 (* 1 = 1.42747 loss)
I0228 17:21:13.080713 12900 sgd_solver.cpp:138] Iteration 6610, lr = 0.0005
I0228 17:21:42.960804 12900 solver.cpp:243] Iteration 6620, loss = 1.64719
I0228 17:21:42.960852 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9804 (* 1 = 1.9804 loss)
I0228 17:21:42.960865 12900 sgd_solver.cpp:138] Iteration 6620, lr = 0.0005
I0228 17:22:16.830353 12900 solver.cpp:243] Iteration 6630, loss = 1.79025
I0228 17:22:16.830546 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.19131 (* 1 = 1.19131 loss)
I0228 17:22:16.830564 12900 sgd_solver.cpp:138] Iteration 6630, lr = 0.0005
I0228 17:22:52.350745 12900 solver.cpp:243] Iteration 6640, loss = 1.86551
I0228 17:22:52.350903 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94715 (* 1 = 1.94715 loss)
I0228 17:22:52.350919 12900 sgd_solver.cpp:138] Iteration 6640, lr = 0.0005
I0228 17:23:22.508651 12900 solver.cpp:243] Iteration 6650, loss = 1.64168
I0228 17:23:22.508846 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.54012 (* 1 = 1.54012 loss)
I0228 17:23:22.508859 12900 sgd_solver.cpp:138] Iteration 6650, lr = 0.0005
I0228 17:23:56.835358 12900 solver.cpp:243] Iteration 6660, loss = 1.88725
I0228 17:23:56.835602 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.81779 (* 1 = 1.81779 loss)
I0228 17:23:56.835624 12900 sgd_solver.cpp:138] Iteration 6660, lr = 0.0005
I0228 17:24:26.013135 12900 solver.cpp:243] Iteration 6670, loss = 2.02038
I0228 17:24:26.013186 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.79705 (* 1 = 1.79705 loss)
I0228 17:24:26.013197 12900 sgd_solver.cpp:138] Iteration 6670, lr = 0.0005
I0228 17:24:58.979665 12900 solver.cpp:243] Iteration 6680, loss = 2.07464
I0228 17:24:58.979857 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.42973 (* 1 = 2.42973 loss)
I0228 17:24:58.979871 12900 sgd_solver.cpp:138] Iteration 6680, lr = 0.0005
I0228 17:25:28.109822 12900 solver.cpp:243] Iteration 6690, loss = 2.01822
I0228 17:25:28.109886 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.67636 (* 1 = 2.67636 loss)
I0228 17:25:28.109899 12900 sgd_solver.cpp:138] Iteration 6690, lr = 0.0005
I0228 17:25:58.296891 12900 solver.cpp:243] Iteration 6700, loss = 1.76539
I0228 17:25:58.297104 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.60606 (* 1 = 1.60606 loss)
I0228 17:25:58.297122 12900 sgd_solver.cpp:138] Iteration 6700, lr = 0.0005
I0228 17:26:32.664897 12900 solver.cpp:243] Iteration 6710, loss = 1.90703
I0228 17:26:32.665050 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.21167 (* 1 = 2.21167 loss)
I0228 17:26:32.665062 12900 sgd_solver.cpp:138] Iteration 6710, lr = 0.0005
I0228 17:27:04.186326 12900 solver.cpp:243] Iteration 6720, loss = 1.86209
I0228 17:27:04.186523 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.5051 (* 1 = 1.5051 loss)
I0228 17:27:04.186540 12900 sgd_solver.cpp:138] Iteration 6720, lr = 0.0005
I0228 17:27:43.591258 12900 solver.cpp:243] Iteration 6730, loss = 1.67543
I0228 17:27:43.591408 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.33695 (* 1 = 1.33695 loss)
I0228 17:27:43.591419 12900 sgd_solver.cpp:138] Iteration 6730, lr = 0.0005
I0228 17:28:22.846109 12900 solver.cpp:243] Iteration 6740, loss = 1.79009
I0228 17:28:22.846312 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.36973 (* 1 = 1.36973 loss)
I0228 17:28:22.846325 12900 sgd_solver.cpp:138] Iteration 6740, lr = 0.0005
I0228 17:28:56.870542 12900 solver.cpp:243] Iteration 6750, loss = 1.58921
I0228 17:28:56.870746 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.54179 (* 1 = 1.54179 loss)
I0228 17:28:56.870759 12900 sgd_solver.cpp:138] Iteration 6750, lr = 0.0005
I0228 17:29:33.645987 12900 solver.cpp:243] Iteration 6760, loss = 1.74952
I0228 17:29:33.646143 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.50654 (* 1 = 1.50654 loss)
I0228 17:29:33.646155 12900 sgd_solver.cpp:138] Iteration 6760, lr = 0.0005
I0228 17:30:09.256173 12900 solver.cpp:243] Iteration 6770, loss = 1.7957
I0228 17:30:09.256440 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.81923 (* 1 = 1.81923 loss)
I0228 17:30:09.256454 12900 sgd_solver.cpp:138] Iteration 6770, lr = 0.0005
I0228 17:30:39.658644 12900 solver.cpp:243] Iteration 6780, loss = 1.72142
I0228 17:30:39.658830 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80393 (* 1 = 1.80393 loss)
I0228 17:30:39.658843 12900 sgd_solver.cpp:138] Iteration 6780, lr = 0.0005
I0228 17:31:13.504750 12900 solver.cpp:243] Iteration 6790, loss = 1.93413
I0228 17:31:13.504930 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.95315 (* 1 = 1.95315 loss)
I0228 17:31:13.504943 12900 sgd_solver.cpp:138] Iteration 6790, lr = 0.0005
I0228 17:31:50.599369 12900 solver.cpp:243] Iteration 6800, loss = 1.6834
I0228 17:31:50.599548 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.568 (* 1 = 1.568 loss)
I0228 17:31:50.599566 12900 sgd_solver.cpp:138] Iteration 6800, lr = 0.0005
I0228 17:32:27.554738 12900 solver.cpp:243] Iteration 6810, loss = 1.58918
I0228 17:32:27.554904 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.04068 (* 1 = 2.04068 loss)
I0228 17:32:27.554917 12900 sgd_solver.cpp:138] Iteration 6810, lr = 0.0005
I0228 17:32:59.111853 12900 solver.cpp:243] Iteration 6820, loss = 1.56963
I0228 17:32:59.112056 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.03926 (* 1 = 2.03926 loss)
I0228 17:32:59.112071 12900 sgd_solver.cpp:138] Iteration 6820, lr = 0.0005
I0228 17:33:34.277424 12900 solver.cpp:243] Iteration 6830, loss = 1.89164
I0228 17:33:34.277581 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9943 (* 1 = 1.9943 loss)
I0228 17:33:34.277593 12900 sgd_solver.cpp:138] Iteration 6830, lr = 0.0005
I0228 17:34:03.879873 12900 solver.cpp:243] Iteration 6840, loss = 1.64225
I0228 17:34:03.879916 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80138 (* 1 = 1.80138 loss)
I0228 17:34:03.879930 12900 sgd_solver.cpp:138] Iteration 6840, lr = 0.0005
I0228 17:34:50.167882 12900 solver.cpp:243] Iteration 6850, loss = 1.75553
I0228 17:34:50.168105 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.97517 (* 1 = 1.97517 loss)
I0228 17:34:50.168121 12900 sgd_solver.cpp:138] Iteration 6850, lr = 0.0005
I0228 17:35:27.755682 12900 solver.cpp:243] Iteration 6860, loss = 2.00099
I0228 17:35:27.755918 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.19987 (* 1 = 1.19987 loss)
I0228 17:35:27.755933 12900 sgd_solver.cpp:138] Iteration 6860, lr = 0.0005
I0228 17:35:56.892271 12900 solver.cpp:243] Iteration 6870, loss = 1.58872
I0228 17:35:56.892330 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42312 (* 1 = 1.42312 loss)
I0228 17:35:56.892341 12900 sgd_solver.cpp:138] Iteration 6870, lr = 0.0005
I0228 17:36:28.203687 12900 solver.cpp:243] Iteration 6880, loss = 1.97807
I0228 17:36:28.203927 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.87566 (* 1 = 1.87566 loss)
I0228 17:36:28.203944 12900 sgd_solver.cpp:138] Iteration 6880, lr = 0.0005
I0228 17:36:56.993824 12900 solver.cpp:243] Iteration 6890, loss = 1.74897
I0228 17:36:56.993875 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.893532 (* 1 = 0.893532 loss)
I0228 17:36:56.993887 12900 sgd_solver.cpp:138] Iteration 6890, lr = 0.0005
I0228 17:37:25.558305 12900 solver.cpp:243] Iteration 6900, loss = 1.7058
I0228 17:37:25.558503 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.19588 (* 1 = 1.19588 loss)
I0228 17:37:25.558516 12900 sgd_solver.cpp:138] Iteration 6900, lr = 0.0005
I0228 17:38:06.963243 12900 solver.cpp:243] Iteration 6910, loss = 1.66098
I0228 17:38:06.963409 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.16099 (* 1 = 1.16099 loss)
I0228 17:38:06.963421 12900 sgd_solver.cpp:138] Iteration 6910, lr = 0.0005
I0228 17:38:38.428573 12900 solver.cpp:243] Iteration 6920, loss = 1.69746
I0228 17:38:38.428699 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.39373 (* 1 = 2.39373 loss)
I0228 17:38:38.428712 12900 sgd_solver.cpp:138] Iteration 6920, lr = 0.0005
I0228 17:39:14.020288 12900 solver.cpp:243] Iteration 6930, loss = 1.66247
I0228 17:39:14.020494 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.18133 (* 1 = 1.18133 loss)
I0228 17:39:14.020507 12900 sgd_solver.cpp:138] Iteration 6930, lr = 0.0005
I0228 17:39:45.515918 12900 solver.cpp:243] Iteration 6940, loss = 1.67187
I0228 17:39:45.516108 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.30055 (* 1 = 1.30055 loss)
I0228 17:39:45.516122 12900 sgd_solver.cpp:138] Iteration 6940, lr = 0.0005
I0228 17:40:23.692435 12900 solver.cpp:243] Iteration 6950, loss = 1.83018
I0228 17:40:23.692607 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.07915 (* 1 = 1.07915 loss)
I0228 17:40:23.692621 12900 sgd_solver.cpp:138] Iteration 6950, lr = 0.0005
I0228 17:40:58.867501 12900 solver.cpp:243] Iteration 6960, loss = 2.11093
I0228 17:40:58.868119 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.15335 (* 1 = 2.15335 loss)
I0228 17:40:58.868137 12900 sgd_solver.cpp:138] Iteration 6960, lr = 0.0005
I0228 17:41:30.988459 12900 solver.cpp:243] Iteration 6970, loss = 1.70469
I0228 17:41:30.988636 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47759 (* 1 = 1.47759 loss)
I0228 17:41:30.988649 12900 sgd_solver.cpp:138] Iteration 6970, lr = 0.0005
I0228 17:42:08.978278 12900 solver.cpp:243] Iteration 6980, loss = 1.87726
I0228 17:42:08.978463 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.93068 (* 1 = 1.93068 loss)
I0228 17:42:08.978478 12900 sgd_solver.cpp:138] Iteration 6980, lr = 0.0005
I0228 17:42:48.621338 12900 solver.cpp:243] Iteration 6990, loss = 1.5866
I0228 17:42:48.621501 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.19322 (* 1 = 2.19322 loss)
I0228 17:42:48.621515 12900 sgd_solver.cpp:138] Iteration 6990, lr = 0.0005
I0228 17:43:29.290187 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_7000.caffemodel
I0228 17:43:29.362620 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_7000.solverstate
I0228 17:43:32.312160 12900 solver.cpp:243] Iteration 7000, loss = 1.58931
I0228 17:43:32.312230 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.64197 (* 1 = 1.64197 loss)
I0228 17:43:32.312243 12900 sgd_solver.cpp:138] Iteration 7000, lr = 0.0005
I0228 17:44:02.484210 12900 solver.cpp:243] Iteration 7010, loss = 1.63177
I0228 17:44:02.484443 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.98858 (* 1 = 1.98858 loss)
I0228 17:44:02.484457 12900 sgd_solver.cpp:138] Iteration 7010, lr = 0.0005
I0228 17:44:34.672477 12900 solver.cpp:243] Iteration 7020, loss = 1.59994
I0228 17:44:34.672672 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.44538 (* 1 = 1.44538 loss)
I0228 17:44:34.672684 12900 sgd_solver.cpp:138] Iteration 7020, lr = 0.0005
I0228 17:44:43.480895 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 17:45:07.649561 12900 solver.cpp:243] Iteration 7030, loss = 1.56823
I0228 17:45:07.649706 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.90763 (* 1 = 1.90763 loss)
I0228 17:45:07.649721 12900 sgd_solver.cpp:138] Iteration 7030, lr = 0.0005
I0228 17:45:47.066597 12900 solver.cpp:243] Iteration 7040, loss = 1.8351
I0228 17:45:47.066766 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.32639 (* 1 = 1.32639 loss)
I0228 17:45:47.066777 12900 sgd_solver.cpp:138] Iteration 7040, lr = 0.0005
I0228 17:46:18.314632 12900 solver.cpp:243] Iteration 7050, loss = 1.97812
I0228 17:46:18.314855 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.63241 (* 1 = 2.63241 loss)
I0228 17:46:18.314877 12900 sgd_solver.cpp:138] Iteration 7050, lr = 0.0005
I0228 17:47:08.032995 12900 solver.cpp:243] Iteration 7060, loss = 1.90487
I0228 17:47:08.033217 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.03098 (* 1 = 1.03098 loss)
I0228 17:47:08.033234 12900 sgd_solver.cpp:138] Iteration 7060, lr = 0.0005
I0228 17:47:50.831586 12900 solver.cpp:243] Iteration 7070, loss = 2.01897
I0228 17:47:50.831813 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.33045 (* 1 = 2.33045 loss)
I0228 17:47:50.831830 12900 sgd_solver.cpp:138] Iteration 7070, lr = 0.0005
I0228 17:48:21.867842 12900 solver.cpp:243] Iteration 7080, loss = 1.91922
I0228 17:48:21.868011 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.74642 (* 1 = 2.74642 loss)
I0228 17:48:21.868023 12900 sgd_solver.cpp:138] Iteration 7080, lr = 0.0005
I0228 17:48:55.653318 12900 solver.cpp:243] Iteration 7090, loss = 1.78634
I0228 17:48:55.653514 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41311 (* 1 = 2.41311 loss)
I0228 17:48:55.653527 12900 sgd_solver.cpp:138] Iteration 7090, lr = 0.0005
I0228 17:49:59.862853 12900 solver.cpp:243] Iteration 7100, loss = 1.70359
I0228 17:49:59.863011 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.27471 (* 1 = 1.27471 loss)
I0228 17:49:59.863024 12900 sgd_solver.cpp:138] Iteration 7100, lr = 0.0005
I0228 17:50:35.177049 12900 solver.cpp:243] Iteration 7110, loss = 1.62784
I0228 17:50:35.177219 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.38087 (* 1 = 1.38087 loss)
I0228 17:50:35.177233 12900 sgd_solver.cpp:138] Iteration 7110, lr = 0.0005
I0228 17:51:08.036614 12900 solver.cpp:243] Iteration 7120, loss = 1.89584
I0228 17:51:08.036818 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.62398 (* 1 = 2.62398 loss)
I0228 17:51:08.036831 12900 sgd_solver.cpp:138] Iteration 7120, lr = 0.0005
I0228 17:51:37.638659 12900 solver.cpp:243] Iteration 7130, loss = 1.64861
I0228 17:51:37.638716 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.0931 (* 1 = 2.0931 loss)
I0228 17:51:37.638726 12900 sgd_solver.cpp:138] Iteration 7130, lr = 0.0005
I0228 17:52:13.660673 12900 solver.cpp:243] Iteration 7140, loss = 1.95526
I0228 17:52:13.660821 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96822 (* 1 = 1.96822 loss)
I0228 17:52:13.660835 12900 sgd_solver.cpp:138] Iteration 7140, lr = 0.0005
I0228 17:52:44.653429 12900 solver.cpp:243] Iteration 7150, loss = 1.75042
I0228 17:52:44.653618 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.63513 (* 1 = 1.63513 loss)
I0228 17:52:44.653635 12900 sgd_solver.cpp:138] Iteration 7150, lr = 0.0005
I0228 17:53:14.488520 12900 solver.cpp:243] Iteration 7160, loss = 1.79258
I0228 17:53:14.488572 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.20926 (* 1 = 2.20926 loss)
I0228 17:53:14.488584 12900 sgd_solver.cpp:138] Iteration 7160, lr = 0.0005
I0228 17:53:48.238010 12900 solver.cpp:243] Iteration 7170, loss = 1.97551
I0228 17:53:48.238193 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.70216 (* 1 = 1.70216 loss)
I0228 17:53:48.238206 12900 sgd_solver.cpp:138] Iteration 7170, lr = 0.0005
I0228 17:54:32.442395 12900 solver.cpp:243] Iteration 7180, loss = 1.87519
I0228 17:54:32.442571 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.57432 (* 1 = 2.57432 loss)
I0228 17:54:32.442584 12900 sgd_solver.cpp:138] Iteration 7180, lr = 0.0005
I0228 17:55:04.954412 12900 solver.cpp:243] Iteration 7190, loss = 1.90933
I0228 17:55:04.954629 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.12969 (* 1 = 3.12969 loss)
I0228 17:55:04.954644 12900 sgd_solver.cpp:138] Iteration 7190, lr = 0.0005
I0228 17:55:39.534940 12900 solver.cpp:243] Iteration 7200, loss = 1.71839
I0228 17:55:39.535147 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.68142 (* 1 = 1.68142 loss)
I0228 17:55:39.535161 12900 sgd_solver.cpp:138] Iteration 7200, lr = 0.0005
I0228 17:56:18.894392 12900 solver.cpp:243] Iteration 7210, loss = 1.90488
I0228 17:56:18.894606 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.65987 (* 1 = 2.65987 loss)
I0228 17:56:18.894619 12900 sgd_solver.cpp:138] Iteration 7210, lr = 0.0005
I0228 17:56:50.468123 12900 solver.cpp:243] Iteration 7220, loss = 2.00669
I0228 17:56:50.468267 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74354 (* 1 = 1.74354 loss)
I0228 17:56:50.468281 12900 sgd_solver.cpp:138] Iteration 7220, lr = 0.0005
I0228 17:57:31.685830 12900 solver.cpp:243] Iteration 7230, loss = 1.86209
I0228 17:57:31.686053 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.31961 (* 1 = 2.31961 loss)
I0228 17:57:31.686067 12900 sgd_solver.cpp:138] Iteration 7230, lr = 0.0005
I0228 17:58:02.120805 12900 solver.cpp:243] Iteration 7240, loss = 1.73962
I0228 17:58:02.120959 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.53188 (* 1 = 1.53188 loss)
I0228 17:58:02.120971 12900 sgd_solver.cpp:138] Iteration 7240, lr = 0.0005
I0228 17:58:41.698137 12900 solver.cpp:243] Iteration 7250, loss = 1.44435
I0228 17:58:41.698331 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.34725 (* 1 = 1.34725 loss)
I0228 17:58:41.698343 12900 sgd_solver.cpp:138] Iteration 7250, lr = 0.0005
I0228 17:59:14.816807 12900 solver.cpp:243] Iteration 7260, loss = 1.78276
I0228 17:59:14.816992 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.29173 (* 1 = 1.29173 loss)
I0228 17:59:14.817004 12900 sgd_solver.cpp:138] Iteration 7260, lr = 0.0005
I0228 17:59:46.947104 12900 solver.cpp:243] Iteration 7270, loss = 1.47695
I0228 17:59:46.948014 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96957 (* 1 = 1.96957 loss)
I0228 17:59:46.948037 12900 sgd_solver.cpp:138] Iteration 7270, lr = 0.0005
I0228 18:00:15.563977 12900 solver.cpp:243] Iteration 7280, loss = 1.83159
I0228 18:00:15.564039 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.38462 (* 1 = 2.38462 loss)
I0228 18:00:15.564054 12900 sgd_solver.cpp:138] Iteration 7280, lr = 0.0005
I0228 18:00:42.304394 12900 solver.cpp:243] Iteration 7290, loss = 1.84882
I0228 18:00:42.304503 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.28869 (* 1 = 1.28869 loss)
I0228 18:00:42.304517 12900 sgd_solver.cpp:138] Iteration 7290, lr = 0.0005
I0228 18:01:10.375923 12900 solver.cpp:243] Iteration 7300, loss = 1.78798
I0228 18:01:10.375969 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.23886 (* 1 = 1.23886 loss)
I0228 18:01:10.375980 12900 sgd_solver.cpp:138] Iteration 7300, lr = 0.0005
I0228 18:01:44.490403 12900 solver.cpp:243] Iteration 7310, loss = 1.74024
I0228 18:01:44.490568 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.21393 (* 1 = 1.21393 loss)
I0228 18:01:44.490582 12900 sgd_solver.cpp:138] Iteration 7310, lr = 0.0005
I0228 18:02:12.933349 12900 solver.cpp:243] Iteration 7320, loss = 1.87965
I0228 18:02:12.933399 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.77725 (* 1 = 2.77725 loss)
I0228 18:02:12.933411 12900 sgd_solver.cpp:138] Iteration 7320, lr = 0.0005
I0228 18:02:56.036064 12900 solver.cpp:243] Iteration 7330, loss = 2.06173
I0228 18:02:56.036240 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.65376 (* 1 = 2.65376 loss)
I0228 18:02:56.036253 12900 sgd_solver.cpp:138] Iteration 7330, lr = 0.0005
I0228 18:03:34.540791 12900 solver.cpp:243] Iteration 7340, loss = 2.14429
I0228 18:03:34.540969 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.60023 (* 1 = 2.60023 loss)
I0228 18:03:34.540983 12900 sgd_solver.cpp:138] Iteration 7340, lr = 0.0005
I0228 18:04:10.657389 12900 solver.cpp:243] Iteration 7350, loss = 1.84387
I0228 18:04:10.658044 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.88193 (* 1 = 1.88193 loss)
I0228 18:04:10.658057 12900 sgd_solver.cpp:138] Iteration 7350, lr = 0.0005
I0228 18:04:42.293170 12900 solver.cpp:243] Iteration 7360, loss = 1.50348
I0228 18:04:42.293321 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80468 (* 1 = 1.80468 loss)
I0228 18:04:42.293334 12900 sgd_solver.cpp:138] Iteration 7360, lr = 0.0005
I0228 18:05:21.692870 12900 solver.cpp:243] Iteration 7370, loss = 1.54368
I0228 18:05:21.693058 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.2242 (* 1 = 1.2242 loss)
I0228 18:05:21.693069 12900 sgd_solver.cpp:138] Iteration 7370, lr = 0.0005
I0228 18:05:54.390290 12900 solver.cpp:243] Iteration 7380, loss = 2.45898
I0228 18:05:54.390473 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.71576 (* 1 = 2.71576 loss)
I0228 18:05:54.390486 12900 sgd_solver.cpp:138] Iteration 7380, lr = 0.0005
I0228 18:06:28.190335 12900 solver.cpp:243] Iteration 7390, loss = 1.79229
I0228 18:06:28.190557 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41797 (* 1 = 2.41797 loss)
I0228 18:06:28.190572 12900 sgd_solver.cpp:138] Iteration 7390, lr = 0.0005
I0228 18:07:00.357765 12900 solver.cpp:243] Iteration 7400, loss = 1.65979
I0228 18:07:00.357949 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.48471 (* 1 = 2.48471 loss)
I0228 18:07:00.357964 12900 sgd_solver.cpp:138] Iteration 7400, lr = 0.0005
I0228 18:07:32.429646 12900 solver.cpp:243] Iteration 7410, loss = 1.63171
I0228 18:07:32.429836 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00375 (* 1 = 2.00375 loss)
I0228 18:07:32.429852 12900 sgd_solver.cpp:138] Iteration 7410, lr = 0.0005
I0228 18:08:02.517194 12900 solver.cpp:243] Iteration 7420, loss = 1.86381
I0228 18:08:02.517388 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.93429 (* 1 = 1.93429 loss)
I0228 18:08:02.517401 12900 sgd_solver.cpp:138] Iteration 7420, lr = 0.0005
I0228 18:08:39.410677 12900 solver.cpp:243] Iteration 7430, loss = 1.63611
I0228 18:08:39.410876 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.703 (* 1 = 1.703 loss)
I0228 18:08:39.410889 12900 sgd_solver.cpp:138] Iteration 7430, lr = 0.0005
I0228 18:09:24.582974 12900 solver.cpp:243] Iteration 7440, loss = 1.85906
I0228 18:09:24.583145 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.33478 (* 1 = 1.33478 loss)
I0228 18:09:24.583158 12900 sgd_solver.cpp:138] Iteration 7440, lr = 0.0005
I0228 18:10:10.377737 12900 solver.cpp:243] Iteration 7450, loss = 1.77815
I0228 18:10:10.377897 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.48494 (* 1 = 1.48494 loss)
I0228 18:10:10.377910 12900 sgd_solver.cpp:138] Iteration 7450, lr = 0.0005
I0228 18:10:46.960779 12900 solver.cpp:243] Iteration 7460, loss = 2.04424
I0228 18:10:46.961026 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.03245 (* 1 = 3.03245 loss)
I0228 18:10:46.961045 12900 sgd_solver.cpp:138] Iteration 7460, lr = 0.0005
I0228 18:11:22.677487 12900 solver.cpp:243] Iteration 7470, loss = 1.70108
I0228 18:11:22.677707 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.7675 (* 1 = 1.7675 loss)
I0228 18:11:22.677722 12900 sgd_solver.cpp:138] Iteration 7470, lr = 0.0005
I0228 18:12:02.074904 12900 solver.cpp:243] Iteration 7480, loss = 1.63893
I0228 18:12:02.075090 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61963 (* 1 = 1.61963 loss)
I0228 18:12:02.075103 12900 sgd_solver.cpp:138] Iteration 7480, lr = 0.0005
I0228 18:12:39.693807 12900 solver.cpp:243] Iteration 7490, loss = 1.843
I0228 18:12:39.695361 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.39051 (* 1 = 2.39051 loss)
I0228 18:12:39.695374 12900 sgd_solver.cpp:138] Iteration 7490, lr = 0.0005
I0228 18:13:08.411165 12900 solver.cpp:243] Iteration 7500, loss = 1.78701
I0228 18:13:08.411222 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.63771 (* 1 = 1.63771 loss)
I0228 18:13:08.411233 12900 sgd_solver.cpp:138] Iteration 7500, lr = 0.0005
I0228 18:13:57.100975 12900 solver.cpp:243] Iteration 7510, loss = 1.71444
I0228 18:13:57.101151 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.08333 (* 1 = 2.08333 loss)
I0228 18:13:57.101166 12900 sgd_solver.cpp:138] Iteration 7510, lr = 0.0005
I0228 18:14:43.105859 12900 solver.cpp:243] Iteration 7520, loss = 1.75297
I0228 18:14:43.106056 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.62409 (* 1 = 1.62409 loss)
I0228 18:14:43.106070 12900 sgd_solver.cpp:138] Iteration 7520, lr = 0.0005
I0228 18:15:14.193596 12900 solver.cpp:243] Iteration 7530, loss = 1.89349
I0228 18:15:14.193785 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.71613 (* 1 = 2.71613 loss)
I0228 18:15:14.193799 12900 sgd_solver.cpp:138] Iteration 7530, lr = 0.0005
I0228 18:15:43.429453 12900 solver.cpp:243] Iteration 7540, loss = 2.04974
I0228 18:15:43.429507 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.489 (* 1 = 2.489 loss)
I0228 18:15:43.429517 12900 sgd_solver.cpp:138] Iteration 7540, lr = 0.0005
I0228 18:16:22.241499 12900 solver.cpp:243] Iteration 7550, loss = 1.62684
I0228 18:16:22.241716 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.00609 (* 1 = 1.00609 loss)
I0228 18:16:22.241731 12900 sgd_solver.cpp:138] Iteration 7550, lr = 0.0005
I0228 18:16:52.820742 12900 solver.cpp:243] Iteration 7560, loss = 1.95636
I0228 18:16:52.820869 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.29944 (* 1 = 1.29944 loss)
I0228 18:16:52.820881 12900 sgd_solver.cpp:138] Iteration 7560, lr = 0.0005
I0228 18:17:37.764992 12900 solver.cpp:243] Iteration 7570, loss = 1.80777
I0228 18:17:37.765159 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.38782 (* 1 = 1.38782 loss)
I0228 18:17:37.765173 12900 sgd_solver.cpp:138] Iteration 7570, lr = 0.0005
I0228 18:18:11.212388 12900 solver.cpp:243] Iteration 7580, loss = 1.76067
I0228 18:18:11.212548 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.45561 (* 1 = 1.45561 loss)
I0228 18:18:11.212560 12900 sgd_solver.cpp:138] Iteration 7580, lr = 0.0005
I0228 18:18:41.506579 12900 solver.cpp:243] Iteration 7590, loss = 2.02178
I0228 18:18:41.506747 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.57871 (* 1 = 3.57871 loss)
I0228 18:18:41.506762 12900 sgd_solver.cpp:138] Iteration 7590, lr = 0.0005
I0228 18:19:17.854768 12900 solver.cpp:243] Iteration 7600, loss = 1.71869
I0228 18:19:17.854923 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.488 (* 1 = 2.488 loss)
I0228 18:19:17.854936 12900 sgd_solver.cpp:138] Iteration 7600, lr = 0.0005
I0228 18:19:59.581859 12900 solver.cpp:243] Iteration 7610, loss = 1.77915
I0228 18:19:59.582020 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.35251 (* 1 = 2.35251 loss)
I0228 18:19:59.582032 12900 sgd_solver.cpp:138] Iteration 7610, lr = 0.0005
I0228 18:20:42.342444 12900 solver.cpp:243] Iteration 7620, loss = 1.65923
I0228 18:20:42.342599 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.3309 (* 1 = 1.3309 loss)
I0228 18:20:42.342612 12900 sgd_solver.cpp:138] Iteration 7620, lr = 0.0005
I0228 18:21:21.629669 12900 solver.cpp:243] Iteration 7630, loss = 1.84705
I0228 18:21:21.629869 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.43873 (* 1 = 1.43873 loss)
I0228 18:21:21.629885 12900 sgd_solver.cpp:138] Iteration 7630, lr = 0.0005
I0228 18:21:51.962013 12900 solver.cpp:243] Iteration 7640, loss = 1.55857
I0228 18:21:51.962229 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.45162 (* 1 = 1.45162 loss)
I0228 18:21:51.962241 12900 sgd_solver.cpp:138] Iteration 7640, lr = 0.0005
I0228 18:22:30.667709 12900 solver.cpp:243] Iteration 7650, loss = 1.59941
I0228 18:22:30.667904 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07742 (* 1 = 2.07742 loss)
I0228 18:22:30.667933 12900 sgd_solver.cpp:138] Iteration 7650, lr = 0.0005
I0228 18:23:13.985569 12900 solver.cpp:243] Iteration 7660, loss = 1.56208
I0228 18:23:13.985730 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61884 (* 1 = 1.61884 loss)
I0228 18:23:13.985743 12900 sgd_solver.cpp:138] Iteration 7660, lr = 0.0005
I0228 18:23:47.521101 12900 solver.cpp:243] Iteration 7670, loss = 2.05536
I0228 18:23:47.521294 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.2382 (* 1 = 1.2382 loss)
I0228 18:23:47.521308 12900 sgd_solver.cpp:138] Iteration 7670, lr = 0.0005
I0228 18:24:23.151156 12900 solver.cpp:243] Iteration 7680, loss = 1.75747
I0228 18:24:23.151331 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.28322 (* 1 = 1.28322 loss)
I0228 18:24:23.151345 12900 sgd_solver.cpp:138] Iteration 7680, lr = 0.0005
I0228 18:25:07.250277 12900 solver.cpp:243] Iteration 7690, loss = 2.01143
I0228 18:25:07.250396 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.67721 (* 1 = 1.67721 loss)
I0228 18:25:07.250425 12900 sgd_solver.cpp:138] Iteration 7690, lr = 0.0005
I0228 18:25:45.410648 12900 solver.cpp:243] Iteration 7700, loss = 1.68027
I0228 18:25:45.410890 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.20917 (* 1 = 1.20917 loss)
I0228 18:25:45.410905 12900 sgd_solver.cpp:138] Iteration 7700, lr = 0.0005
I0228 18:26:19.081543 12900 solver.cpp:243] Iteration 7710, loss = 1.77144
I0228 18:26:19.081733 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.59469 (* 1 = 1.59469 loss)
I0228 18:26:19.081748 12900 sgd_solver.cpp:138] Iteration 7710, lr = 0.0005
I0228 18:26:51.245934 12900 solver.cpp:243] Iteration 7720, loss = 1.76859
I0228 18:26:51.247175 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.83412 (* 1 = 1.83412 loss)
I0228 18:26:51.247190 12900 sgd_solver.cpp:138] Iteration 7720, lr = 0.0005
I0228 18:27:30.265502 12900 solver.cpp:243] Iteration 7730, loss = 1.65593
I0228 18:27:30.265661 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.971827 (* 1 = 0.971827 loss)
I0228 18:27:30.265684 12900 sgd_solver.cpp:138] Iteration 7730, lr = 0.0005
I0228 18:27:59.194350 12900 solver.cpp:243] Iteration 7740, loss = 1.83235
I0228 18:27:59.194397 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.52988 (* 1 = 1.52988 loss)
I0228 18:27:59.194408 12900 sgd_solver.cpp:138] Iteration 7740, lr = 0.0005
I0228 18:28:33.346516 12900 solver.cpp:243] Iteration 7750, loss = 1.76186
I0228 18:28:33.346664 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.1848 (* 1 = 1.1848 loss)
I0228 18:28:33.346678 12900 sgd_solver.cpp:138] Iteration 7750, lr = 0.0005
I0228 18:29:09.573423 12900 solver.cpp:243] Iteration 7760, loss = 2.04687
I0228 18:29:09.573616 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.85327 (* 1 = 1.85327 loss)
I0228 18:29:09.573629 12900 sgd_solver.cpp:138] Iteration 7760, lr = 0.0005
I0228 18:29:55.646875 12900 solver.cpp:243] Iteration 7770, loss = 1.72407
I0228 18:29:55.647092 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.30853 (* 1 = 1.30853 loss)
I0228 18:29:55.647106 12900 sgd_solver.cpp:138] Iteration 7770, lr = 0.0005
I0228 18:30:27.353384 12900 solver.cpp:243] Iteration 7780, loss = 1.76105
I0228 18:30:27.353572 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.7646 (* 1 = 1.7646 loss)
I0228 18:30:27.353590 12900 sgd_solver.cpp:138] Iteration 7780, lr = 0.0005
I0228 18:30:59.835413 12900 solver.cpp:243] Iteration 7790, loss = 1.73985
I0228 18:30:59.835608 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.45262 (* 1 = 1.45262 loss)
I0228 18:30:59.835625 12900 sgd_solver.cpp:138] Iteration 7790, lr = 0.0005
I0228 18:31:30.441593 12900 solver.cpp:243] Iteration 7800, loss = 1.66981
I0228 18:31:30.441753 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.66915 (* 1 = 1.66915 loss)
I0228 18:31:30.441766 12900 sgd_solver.cpp:138] Iteration 7800, lr = 0.0005
I0228 18:32:11.096938 12900 solver.cpp:243] Iteration 7810, loss = 1.86941
I0228 18:32:11.097121 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.26356 (* 1 = 3.26356 loss)
I0228 18:32:11.097134 12900 sgd_solver.cpp:138] Iteration 7810, lr = 0.0005
I0228 18:32:40.645045 12900 solver.cpp:243] Iteration 7820, loss = 1.48605
I0228 18:32:40.645099 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.44666 (* 1 = 1.44666 loss)
I0228 18:32:40.645109 12900 sgd_solver.cpp:138] Iteration 7820, lr = 0.0005
I0228 18:33:16.769739 12900 solver.cpp:243] Iteration 7830, loss = 2.18293
I0228 18:33:16.769892 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.77373 (* 1 = 2.77373 loss)
I0228 18:33:16.769910 12900 sgd_solver.cpp:138] Iteration 7830, lr = 0.0005
I0228 18:33:55.229583 12900 solver.cpp:243] Iteration 7840, loss = 1.88298
I0228 18:33:55.229739 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.7979 (* 1 = 1.7979 loss)
I0228 18:33:55.229753 12900 sgd_solver.cpp:138] Iteration 7840, lr = 0.0005
I0228 18:34:25.186856 12900 solver.cpp:243] Iteration 7850, loss = 2.04224
I0228 18:34:25.186924 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.60061 (* 1 = 1.60061 loss)
I0228 18:34:25.186935 12900 sgd_solver.cpp:138] Iteration 7850, lr = 0.0005
I0228 18:35:08.328368 12900 solver.cpp:243] Iteration 7860, loss = 1.70745
I0228 18:35:08.328681 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.99184 (* 1 = 1.99184 loss)
I0228 18:35:08.328708 12900 sgd_solver.cpp:138] Iteration 7860, lr = 0.0005
I0228 18:35:36.956650 12900 solver.cpp:243] Iteration 7870, loss = 1.6572
I0228 18:35:36.956730 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.54345 (* 1 = 1.54345 loss)
I0228 18:35:36.956743 12900 sgd_solver.cpp:138] Iteration 7870, lr = 0.0005
I0228 18:36:07.886446 12900 solver.cpp:243] Iteration 7880, loss = 1.33658
I0228 18:36:07.886610 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.12528 (* 1 = 1.12528 loss)
I0228 18:36:07.886622 12900 sgd_solver.cpp:138] Iteration 7880, lr = 0.0005
I0228 18:36:42.725442 12900 solver.cpp:243] Iteration 7890, loss = 2.14215
I0228 18:36:42.725611 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.6284 (* 1 = 1.6284 loss)
I0228 18:36:42.725625 12900 sgd_solver.cpp:138] Iteration 7890, lr = 0.0005
I0228 18:37:18.351701 12900 solver.cpp:243] Iteration 7900, loss = 1.63135
I0228 18:37:18.351882 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.27213 (* 1 = 1.27213 loss)
I0228 18:37:18.351897 12900 sgd_solver.cpp:138] Iteration 7900, lr = 0.0005
I0228 18:37:54.883353 12900 solver.cpp:243] Iteration 7910, loss = 1.89663
I0228 18:37:54.883545 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74739 (* 1 = 1.74739 loss)
I0228 18:37:54.883559 12900 sgd_solver.cpp:138] Iteration 7910, lr = 0.0005
I0228 18:38:28.847651 12900 solver.cpp:243] Iteration 7920, loss = 1.71159
I0228 18:38:28.847859 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47518 (* 1 = 1.47518 loss)
I0228 18:38:28.847882 12900 sgd_solver.cpp:138] Iteration 7920, lr = 0.0005
I0228 18:39:01.541348 12900 solver.cpp:243] Iteration 7930, loss = 1.76673
I0228 18:39:01.541514 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.35231 (* 1 = 1.35231 loss)
I0228 18:39:01.541527 12900 sgd_solver.cpp:138] Iteration 7930, lr = 0.0005
I0228 18:39:32.973491 12900 solver.cpp:243] Iteration 7940, loss = 1.64318
I0228 18:39:32.973652 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.89763 (* 1 = 1.89763 loss)
I0228 18:39:32.973665 12900 sgd_solver.cpp:138] Iteration 7940, lr = 0.0005
I0228 18:40:02.243207 12900 solver.cpp:243] Iteration 7950, loss = 1.63178
I0228 18:40:02.243261 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91946 (* 1 = 1.91946 loss)
I0228 18:40:02.243274 12900 sgd_solver.cpp:138] Iteration 7950, lr = 0.0005
I0228 18:40:42.515560 12900 solver.cpp:243] Iteration 7960, loss = 1.61834
I0228 18:40:42.515749 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.29459 (* 1 = 1.29459 loss)
I0228 18:40:42.515763 12900 sgd_solver.cpp:138] Iteration 7960, lr = 0.0005
I0228 18:41:12.376193 12900 solver.cpp:243] Iteration 7970, loss = 1.75026
I0228 18:41:12.376250 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.52613 (* 1 = 1.52613 loss)
I0228 18:41:12.376261 12900 sgd_solver.cpp:138] Iteration 7970, lr = 0.0005
I0228 18:41:41.525146 12900 solver.cpp:243] Iteration 7980, loss = 1.53896
I0228 18:41:41.525269 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.92734 (* 1 = 1.92734 loss)
I0228 18:41:41.525285 12900 sgd_solver.cpp:138] Iteration 7980, lr = 0.0005
I0228 18:42:14.861248 12900 solver.cpp:243] Iteration 7990, loss = 1.90485
I0228 18:42:14.861436 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.50945 (* 1 = 1.50945 loss)
I0228 18:42:14.861451 12900 sgd_solver.cpp:138] Iteration 7990, lr = 0.0005
I0228 18:42:41.874212 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_8000.caffemodel
I0228 18:42:41.950165 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_8000.solverstate
I0228 18:42:44.642611 12900 solver.cpp:243] Iteration 8000, loss = 1.73758
I0228 18:42:44.642652 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.43637 (* 1 = 1.43637 loss)
I0228 18:42:44.642663 12900 sgd_solver.cpp:138] Iteration 8000, lr = 0.0005
I0228 18:43:24.327626 12900 solver.cpp:243] Iteration 8010, loss = 1.57439
I0228 18:43:24.327811 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.37532 (* 1 = 1.37532 loss)
I0228 18:43:24.327826 12900 sgd_solver.cpp:138] Iteration 8010, lr = 0.0005
I0228 18:43:53.698642 12900 solver.cpp:243] Iteration 8020, loss = 1.76337
I0228 18:43:53.698688 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.14436 (* 1 = 2.14436 loss)
I0228 18:43:53.698700 12900 sgd_solver.cpp:138] Iteration 8020, lr = 0.0005
I0228 18:44:33.241878 12900 solver.cpp:243] Iteration 8030, loss = 1.8425
I0228 18:44:33.242055 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.79246 (* 1 = 1.79246 loss)
I0228 18:44:33.242069 12900 sgd_solver.cpp:138] Iteration 8030, lr = 0.0005
I0228 18:45:01.656342 12900 solver.cpp:243] Iteration 8040, loss = 1.59872
I0228 18:45:01.656412 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.49483 (* 1 = 1.49483 loss)
I0228 18:45:01.656424 12900 sgd_solver.cpp:138] Iteration 8040, lr = 0.0005
I0228 18:45:33.331934 12900 solver.cpp:243] Iteration 8050, loss = 1.53092
I0228 18:45:33.332124 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00502 (* 1 = 2.00502 loss)
I0228 18:45:33.332137 12900 sgd_solver.cpp:138] Iteration 8050, lr = 0.0005
I0228 18:46:11.382961 12900 solver.cpp:243] Iteration 8060, loss = 1.83394
I0228 18:46:11.383620 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42175 (* 1 = 1.42175 loss)
I0228 18:46:11.383648 12900 sgd_solver.cpp:138] Iteration 8060, lr = 0.0005
I0228 18:46:44.991366 12900 solver.cpp:243] Iteration 8070, loss = 1.77114
I0228 18:46:44.991541 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42382 (* 1 = 1.42382 loss)
I0228 18:46:44.991554 12900 sgd_solver.cpp:138] Iteration 8070, lr = 0.0005
I0228 18:47:16.171955 12900 solver.cpp:243] Iteration 8080, loss = 1.62314
I0228 18:47:16.172106 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.16215 (* 1 = 1.16215 loss)
I0228 18:47:16.172121 12900 sgd_solver.cpp:138] Iteration 8080, lr = 0.0005
I0228 18:47:44.661478 12900 solver.cpp:243] Iteration 8090, loss = 1.7886
I0228 18:47:44.661525 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.64814 (* 1 = 1.64814 loss)
I0228 18:47:44.661536 12900 sgd_solver.cpp:138] Iteration 8090, lr = 0.0005
I0228 18:48:31.596755 12900 solver.cpp:243] Iteration 8100, loss = 1.697
I0228 18:48:31.596949 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91344 (* 1 = 1.91344 loss)
I0228 18:48:31.596962 12900 sgd_solver.cpp:138] Iteration 8100, lr = 0.0005
I0228 18:49:03.387495 12900 solver.cpp:243] Iteration 8110, loss = 1.64191
I0228 18:49:03.387701 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.4262 (* 1 = 1.4262 loss)
I0228 18:49:03.387713 12900 sgd_solver.cpp:138] Iteration 8110, lr = 0.0005
I0228 18:49:31.915314 12900 solver.cpp:243] Iteration 8120, loss = 1.76146
I0228 18:49:31.915374 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.20992 (* 1 = 3.20992 loss)
I0228 18:49:31.915385 12900 sgd_solver.cpp:138] Iteration 8120, lr = 0.0005
I0228 18:50:04.311166 12900 solver.cpp:243] Iteration 8130, loss = 1.55896
I0228 18:50:04.311291 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.48476 (* 1 = 2.48476 loss)
I0228 18:50:04.311305 12900 sgd_solver.cpp:138] Iteration 8130, lr = 0.0005
I0228 18:50:46.360091 12900 solver.cpp:243] Iteration 8140, loss = 1.73364
I0228 18:50:46.360318 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.45176 (* 1 = 1.45176 loss)
I0228 18:50:46.360332 12900 sgd_solver.cpp:138] Iteration 8140, lr = 0.0005
I0228 18:51:25.922794 12900 solver.cpp:243] Iteration 8150, loss = 1.91252
I0228 18:51:25.923559 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.07246 (* 1 = 1.07246 loss)
I0228 18:51:25.923604 12900 sgd_solver.cpp:138] Iteration 8150, lr = 0.0005
I0228 18:52:06.714984 12900 solver.cpp:243] Iteration 8160, loss = 1.65182
I0228 18:52:06.715224 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.59346 (* 1 = 2.59346 loss)
I0228 18:52:06.715237 12900 sgd_solver.cpp:138] Iteration 8160, lr = 0.0005
I0228 18:52:46.462616 12900 solver.cpp:243] Iteration 8170, loss = 1.97941
I0228 18:52:46.462954 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.30477 (* 1 = 3.30477 loss)
I0228 18:52:46.462968 12900 sgd_solver.cpp:138] Iteration 8170, lr = 0.0005
I0228 18:53:23.932345 12900 solver.cpp:243] Iteration 8180, loss = 1.70104
I0228 18:53:23.932585 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.392 (* 1 = 1.392 loss)
I0228 18:53:23.932600 12900 sgd_solver.cpp:138] Iteration 8180, lr = 0.0005
I0228 18:53:55.252038 12900 solver.cpp:243] Iteration 8190, loss = 1.56334
I0228 18:53:55.252230 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47786 (* 1 = 1.47786 loss)
I0228 18:53:55.252260 12900 sgd_solver.cpp:138] Iteration 8190, lr = 0.0005
I0228 18:54:25.830945 12900 solver.cpp:243] Iteration 8200, loss = 1.7448
I0228 18:54:25.831118 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.38612 (* 1 = 1.38612 loss)
I0228 18:54:25.831131 12900 sgd_solver.cpp:138] Iteration 8200, lr = 0.0005
I0228 18:55:01.390935 12900 solver.cpp:243] Iteration 8210, loss = 1.68639
I0228 18:55:01.391126 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.24979 (* 1 = 2.24979 loss)
I0228 18:55:01.391141 12900 sgd_solver.cpp:138] Iteration 8210, lr = 0.0005
I0228 18:55:36.394708 12900 solver.cpp:243] Iteration 8220, loss = 1.74252
I0228 18:55:36.394899 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72082 (* 1 = 1.72082 loss)
I0228 18:55:36.394915 12900 sgd_solver.cpp:138] Iteration 8220, lr = 0.0005
I0228 18:56:11.942623 12900 solver.cpp:243] Iteration 8230, loss = 1.98615
I0228 18:56:11.942806 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.30765 (* 1 = 1.30765 loss)
I0228 18:56:11.942818 12900 sgd_solver.cpp:138] Iteration 8230, lr = 0.0005
I0228 18:56:42.947773 12900 solver.cpp:243] Iteration 8240, loss = 1.72471
I0228 18:56:42.947962 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.26345 (* 1 = 1.26345 loss)
I0228 18:56:42.947974 12900 sgd_solver.cpp:138] Iteration 8240, lr = 0.0005
I0228 18:57:35.318482 12900 solver.cpp:243] Iteration 8250, loss = 1.93533
I0228 18:57:35.318670 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.31432 (* 1 = 1.31432 loss)
I0228 18:57:35.318684 12900 sgd_solver.cpp:138] Iteration 8250, lr = 0.0005
I0228 18:58:05.468789 12900 solver.cpp:243] Iteration 8260, loss = 1.74766
I0228 18:58:05.468945 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.69444 (* 1 = 1.69444 loss)
I0228 18:58:05.468957 12900 sgd_solver.cpp:138] Iteration 8260, lr = 0.0005
I0228 18:58:37.292757 12900 solver.cpp:243] Iteration 8270, loss = 1.87746
I0228 18:58:37.292932 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.71807 (* 1 = 1.71807 loss)
I0228 18:58:37.292945 12900 sgd_solver.cpp:138] Iteration 8270, lr = 0.0005
I0228 18:59:22.055898 12900 solver.cpp:243] Iteration 8280, loss = 1.81318
I0228 18:59:22.056067 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.60995 (* 1 = 1.60995 loss)
I0228 18:59:22.056080 12900 sgd_solver.cpp:138] Iteration 8280, lr = 0.0005
I0228 19:00:02.344945 12900 solver.cpp:243] Iteration 8290, loss = 1.74747
I0228 19:00:02.345136 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9534 (* 1 = 1.9534 loss)
I0228 19:00:02.345150 12900 sgd_solver.cpp:138] Iteration 8290, lr = 0.0005
I0228 19:00:52.029084 12900 solver.cpp:243] Iteration 8300, loss = 1.60538
I0228 19:00:52.029290 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.18007 (* 1 = 1.18007 loss)
I0228 19:00:52.029304 12900 sgd_solver.cpp:138] Iteration 8300, lr = 0.0005
I0228 19:01:22.661556 12900 solver.cpp:243] Iteration 8310, loss = 1.75363
I0228 19:01:22.662740 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.07406 (* 1 = 1.07406 loss)
I0228 19:01:22.662755 12900 sgd_solver.cpp:138] Iteration 8310, lr = 0.0005
I0228 19:01:54.636589 12900 solver.cpp:243] Iteration 8320, loss = 1.81507
I0228 19:01:54.636766 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.4839 (* 1 = 2.4839 loss)
I0228 19:01:54.636780 12900 sgd_solver.cpp:138] Iteration 8320, lr = 0.0005
I0228 19:02:33.284761 12900 solver.cpp:243] Iteration 8330, loss = 1.70119
I0228 19:02:33.284950 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.08061 (* 1 = 1.08061 loss)
I0228 19:02:33.284965 12900 sgd_solver.cpp:138] Iteration 8330, lr = 0.0005
I0228 19:03:11.317735 12900 solver.cpp:243] Iteration 8340, loss = 1.6629
I0228 19:03:11.317916 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.8609 (* 1 = 1.8609 loss)
I0228 19:03:11.317930 12900 sgd_solver.cpp:138] Iteration 8340, lr = 0.0005
I0228 19:03:41.977555 12900 solver.cpp:243] Iteration 8350, loss = 1.96876
I0228 19:03:41.977722 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.64739 (* 1 = 1.64739 loss)
I0228 19:03:41.977735 12900 sgd_solver.cpp:138] Iteration 8350, lr = 0.0005
I0228 19:04:12.883734 12900 solver.cpp:243] Iteration 8360, loss = 1.67679
I0228 19:04:12.883882 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.62854 (* 1 = 1.62854 loss)
I0228 19:04:12.883899 12900 sgd_solver.cpp:138] Iteration 8360, lr = 0.0005
I0228 19:04:43.951234 12900 solver.cpp:243] Iteration 8370, loss = 1.52182
I0228 19:04:43.951376 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.868305 (* 1 = 0.868305 loss)
I0228 19:04:43.951395 12900 sgd_solver.cpp:138] Iteration 8370, lr = 0.0005
I0228 19:05:12.972767 12900 solver.cpp:243] Iteration 8380, loss = 1.67888
I0228 19:05:12.972856 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.12383 (* 1 = 2.12383 loss)
I0228 19:05:12.972868 12900 sgd_solver.cpp:138] Iteration 8380, lr = 0.0005
I0228 19:05:45.507792 12900 solver.cpp:243] Iteration 8390, loss = 1.55757
I0228 19:05:45.507959 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.29842 (* 1 = 1.29842 loss)
I0228 19:05:45.507972 12900 sgd_solver.cpp:138] Iteration 8390, lr = 0.0005
I0228 19:06:15.823846 12900 solver.cpp:243] Iteration 8400, loss = 1.50118
I0228 19:06:15.824041 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.15009 (* 1 = 1.15009 loss)
I0228 19:06:15.824054 12900 sgd_solver.cpp:138] Iteration 8400, lr = 0.0005
I0228 19:06:54.268234 12900 solver.cpp:243] Iteration 8410, loss = 1.64128
I0228 19:06:54.268419 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.8298 (* 1 = 1.8298 loss)
I0228 19:06:54.268434 12900 sgd_solver.cpp:138] Iteration 8410, lr = 0.0005
I0228 19:07:26.080438 12900 solver.cpp:243] Iteration 8420, loss = 1.74996
I0228 19:07:26.080590 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.76628 (* 1 = 1.76628 loss)
I0228 19:07:26.080605 12900 sgd_solver.cpp:138] Iteration 8420, lr = 0.0005
I0228 19:07:56.155529 12900 solver.cpp:243] Iteration 8430, loss = 1.77966
I0228 19:07:56.155696 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.43398 (* 1 = 1.43398 loss)
I0228 19:07:56.155709 12900 sgd_solver.cpp:138] Iteration 8430, lr = 0.0005
I0228 19:08:40.511734 12900 solver.cpp:243] Iteration 8440, loss = 1.6265
I0228 19:08:40.511945 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.56757 (* 1 = 1.56757 loss)
I0228 19:08:40.511965 12900 sgd_solver.cpp:138] Iteration 8440, lr = 0.0005
I0228 19:09:15.455646 12900 solver.cpp:243] Iteration 8450, loss = 1.8978
I0228 19:09:15.455850 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.58391 (* 1 = 2.58391 loss)
I0228 19:09:15.455864 12900 sgd_solver.cpp:138] Iteration 8450, lr = 0.0005
I0228 19:09:47.299769 12900 solver.cpp:243] Iteration 8460, loss = 1.62991
I0228 19:09:47.299980 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.25323 (* 1 = 1.25323 loss)
I0228 19:09:47.299993 12900 sgd_solver.cpp:138] Iteration 8460, lr = 0.0005
I0228 19:10:15.701114 12900 solver.cpp:243] Iteration 8470, loss = 1.74716
I0228 19:10:15.701172 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.29495 (* 1 = 2.29495 loss)
I0228 19:10:15.701184 12900 sgd_solver.cpp:138] Iteration 8470, lr = 0.0005
I0228 19:10:21.565475 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 19:10:44.661444 12900 solver.cpp:243] Iteration 8480, loss = 1.71417
I0228 19:10:44.661499 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91477 (* 1 = 1.91477 loss)
I0228 19:10:44.661509 12900 sgd_solver.cpp:138] Iteration 8480, lr = 0.0005
I0228 19:11:15.957530 12900 solver.cpp:243] Iteration 8490, loss = 1.68851
I0228 19:11:15.957716 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.43192 (* 1 = 1.43192 loss)
I0228 19:11:15.957728 12900 sgd_solver.cpp:138] Iteration 8490, lr = 0.0005
I0228 19:11:49.245348 12900 solver.cpp:243] Iteration 8500, loss = 1.70318
I0228 19:11:49.245522 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.55581 (* 1 = 1.55581 loss)
I0228 19:11:49.245537 12900 sgd_solver.cpp:138] Iteration 8500, lr = 0.0005
I0228 19:12:21.284462 12900 solver.cpp:243] Iteration 8510, loss = 1.74756
I0228 19:12:21.284636 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.64681 (* 1 = 1.64681 loss)
I0228 19:12:21.284648 12900 sgd_solver.cpp:138] Iteration 8510, lr = 0.0005
I0228 19:12:51.931092 12900 solver.cpp:243] Iteration 8520, loss = 1.57944
I0228 19:12:51.931262 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.17444 (* 1 = 1.17444 loss)
I0228 19:12:51.931274 12900 sgd_solver.cpp:138] Iteration 8520, lr = 0.0005
I0228 19:13:22.112594 12900 solver.cpp:243] Iteration 8530, loss = 1.77083
I0228 19:13:22.112769 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91729 (* 1 = 1.91729 loss)
I0228 19:13:22.112784 12900 sgd_solver.cpp:138] Iteration 8530, lr = 0.0005
I0228 19:13:54.541313 12900 solver.cpp:243] Iteration 8540, loss = 1.36639
I0228 19:13:54.541565 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.22534 (* 1 = 1.22534 loss)
I0228 19:13:54.541580 12900 sgd_solver.cpp:138] Iteration 8540, lr = 0.0005
I0228 19:14:35.363696 12900 solver.cpp:243] Iteration 8550, loss = 1.79625
I0228 19:14:35.363847 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.02713 (* 1 = 2.02713 loss)
I0228 19:14:35.363859 12900 sgd_solver.cpp:138] Iteration 8550, lr = 0.0005
I0228 19:15:10.952488 12900 solver.cpp:243] Iteration 8560, loss = 1.65439
I0228 19:15:10.952679 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.58763 (* 1 = 1.58763 loss)
I0228 19:15:10.952692 12900 sgd_solver.cpp:138] Iteration 8560, lr = 0.0005
I0228 19:15:40.297351 12900 solver.cpp:243] Iteration 8570, loss = 1.52747
I0228 19:15:40.297395 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.04442 (* 1 = 2.04442 loss)
I0228 19:15:40.297406 12900 sgd_solver.cpp:138] Iteration 8570, lr = 0.0005
I0228 19:16:16.906756 12900 solver.cpp:243] Iteration 8580, loss = 1.95936
I0228 19:16:16.906941 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.4914 (* 1 = 1.4914 loss)
I0228 19:16:16.906960 12900 sgd_solver.cpp:138] Iteration 8580, lr = 0.0005
I0228 19:16:55.010267 12900 solver.cpp:243] Iteration 8590, loss = 1.75477
I0228 19:16:55.010463 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.79757 (* 1 = 1.79757 loss)
I0228 19:16:55.010483 12900 sgd_solver.cpp:138] Iteration 8590, lr = 0.0005
I0228 19:17:28.827631 12900 solver.cpp:243] Iteration 8600, loss = 1.95906
I0228 19:17:28.827785 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.40971 (* 1 = 1.40971 loss)
I0228 19:17:28.827801 12900 sgd_solver.cpp:138] Iteration 8600, lr = 0.0005
I0228 19:18:07.868918 12900 solver.cpp:243] Iteration 8610, loss = 1.69401
I0228 19:18:07.869092 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.41733 (* 1 = 1.41733 loss)
I0228 19:18:07.869104 12900 sgd_solver.cpp:138] Iteration 8610, lr = 0.0005
I0228 19:18:38.215905 12900 solver.cpp:243] Iteration 8620, loss = 1.75022
I0228 19:18:38.216049 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.76523 (* 1 = 1.76523 loss)
I0228 19:18:38.216063 12900 sgd_solver.cpp:138] Iteration 8620, lr = 0.0005
I0228 19:19:21.715457 12900 solver.cpp:243] Iteration 8630, loss = 1.59711
I0228 19:19:21.715649 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.31668 (* 1 = 1.31668 loss)
I0228 19:19:21.715663 12900 sgd_solver.cpp:138] Iteration 8630, lr = 0.0005
I0228 19:19:57.486738 12900 solver.cpp:243] Iteration 8640, loss = 1.78245
I0228 19:19:57.486925 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.46178 (* 1 = 1.46178 loss)
I0228 19:19:57.486955 12900 sgd_solver.cpp:138] Iteration 8640, lr = 0.0005
I0228 19:20:36.467056 12900 solver.cpp:243] Iteration 8650, loss = 1.83379
I0228 19:20:36.467244 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.53127 (* 1 = 2.53127 loss)
I0228 19:20:36.467257 12900 sgd_solver.cpp:138] Iteration 8650, lr = 0.0005
I0228 19:21:09.896250 12900 solver.cpp:243] Iteration 8660, loss = 1.57405
I0228 19:21:09.896440 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.30869 (* 1 = 1.30869 loss)
I0228 19:21:09.896457 12900 sgd_solver.cpp:138] Iteration 8660, lr = 0.0005
I0228 19:21:42.516438 12900 solver.cpp:243] Iteration 8670, loss = 1.74337
I0228 19:21:42.516621 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9073 (* 1 = 1.9073 loss)
I0228 19:21:42.516634 12900 sgd_solver.cpp:138] Iteration 8670, lr = 0.0005
I0228 19:22:18.920531 12900 solver.cpp:243] Iteration 8680, loss = 1.64186
I0228 19:22:18.920722 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.88978 (* 1 = 1.88978 loss)
I0228 19:22:18.920740 12900 sgd_solver.cpp:138] Iteration 8680, lr = 0.0005
I0228 19:22:47.248090 12900 solver.cpp:243] Iteration 8690, loss = 1.76926
I0228 19:22:47.248147 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.21463 (* 1 = 2.21463 loss)
I0228 19:22:47.248174 12900 sgd_solver.cpp:138] Iteration 8690, lr = 0.0005
I0228 19:23:22.187121 12900 solver.cpp:243] Iteration 8700, loss = 1.77923
I0228 19:23:22.187274 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.70697 (* 1 = 1.70697 loss)
I0228 19:23:22.187289 12900 sgd_solver.cpp:138] Iteration 8700, lr = 0.0005
I0228 19:23:57.844653 12900 solver.cpp:243] Iteration 8710, loss = 1.82688
I0228 19:23:57.844918 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80115 (* 1 = 1.80115 loss)
I0228 19:23:57.844935 12900 sgd_solver.cpp:138] Iteration 8710, lr = 0.0005
I0228 19:24:30.772706 12900 solver.cpp:243] Iteration 8720, loss = 2.00722
I0228 19:24:30.772887 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96792 (* 1 = 1.96792 loss)
I0228 19:24:30.772899 12900 sgd_solver.cpp:138] Iteration 8720, lr = 0.0005
I0228 19:25:07.578361 12900 solver.cpp:243] Iteration 8730, loss = 1.74831
I0228 19:25:07.578537 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75795 (* 1 = 1.75795 loss)
I0228 19:25:07.578550 12900 sgd_solver.cpp:138] Iteration 8730, lr = 0.0005
I0228 19:25:42.322701 12900 solver.cpp:243] Iteration 8740, loss = 1.68178
I0228 19:25:42.322890 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42595 (* 1 = 1.42595 loss)
I0228 19:25:42.322906 12900 sgd_solver.cpp:138] Iteration 8740, lr = 0.0005
I0228 19:26:11.130411 12900 solver.cpp:243] Iteration 8750, loss = 1.75863
I0228 19:26:11.130499 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.5542 (* 1 = 1.5542 loss)
I0228 19:26:11.130511 12900 sgd_solver.cpp:138] Iteration 8750, lr = 0.0005
I0228 19:26:40.975314 12900 solver.cpp:243] Iteration 8760, loss = 1.84288
I0228 19:26:40.975494 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.18729 (* 1 = 1.18729 loss)
I0228 19:26:40.975508 12900 sgd_solver.cpp:138] Iteration 8760, lr = 0.0005
I0228 19:27:10.951525 12900 solver.cpp:243] Iteration 8770, loss = 2.00434
I0228 19:27:10.951572 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.35112 (* 1 = 1.35112 loss)
I0228 19:27:10.951582 12900 sgd_solver.cpp:138] Iteration 8770, lr = 0.0005
I0228 19:27:50.085196 12900 solver.cpp:243] Iteration 8780, loss = 1.56437
I0228 19:27:50.085363 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47118 (* 1 = 1.47118 loss)
I0228 19:27:50.085377 12900 sgd_solver.cpp:138] Iteration 8780, lr = 0.0005
I0228 19:28:18.433490 12900 solver.cpp:243] Iteration 8790, loss = 1.60969
I0228 19:28:18.433552 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.03977 (* 1 = 2.03977 loss)
I0228 19:28:18.433563 12900 sgd_solver.cpp:138] Iteration 8790, lr = 0.0005
I0228 19:28:50.399421 12900 solver.cpp:243] Iteration 8800, loss = 1.61879
I0228 19:28:50.399644 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.930315 (* 1 = 0.930315 loss)
I0228 19:28:50.399657 12900 sgd_solver.cpp:138] Iteration 8800, lr = 0.0005
I0228 19:29:33.504940 12900 solver.cpp:243] Iteration 8810, loss = 1.57888
I0228 19:29:33.505115 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.57361 (* 1 = 1.57361 loss)
I0228 19:29:33.505126 12900 sgd_solver.cpp:138] Iteration 8810, lr = 0.0005
I0228 19:30:02.693707 12900 solver.cpp:243] Iteration 8820, loss = 1.79864
I0228 19:30:02.693768 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.3496 (* 1 = 1.3496 loss)
I0228 19:30:02.693779 12900 sgd_solver.cpp:138] Iteration 8820, lr = 0.0005
I0228 19:30:32.455065 12900 solver.cpp:243] Iteration 8830, loss = 1.80455
I0228 19:30:32.456586 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.89744 (* 1 = 1.89744 loss)
I0228 19:30:32.456604 12900 sgd_solver.cpp:138] Iteration 8830, lr = 0.0005
I0228 19:31:00.864804 12900 solver.cpp:243] Iteration 8840, loss = 1.44506
I0228 19:31:00.864874 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.37318 (* 1 = 1.37318 loss)
I0228 19:31:00.864888 12900 sgd_solver.cpp:138] Iteration 8840, lr = 0.0005
I0228 19:31:34.159409 12900 solver.cpp:243] Iteration 8850, loss = 1.78196
I0228 19:31:34.159616 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.52333 (* 1 = 1.52333 loss)
I0228 19:31:34.159633 12900 sgd_solver.cpp:138] Iteration 8850, lr = 0.0005
I0228 19:32:04.232123 12900 solver.cpp:243] Iteration 8860, loss = 1.69505
I0228 19:32:04.232281 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.14351 (* 1 = 1.14351 loss)
I0228 19:32:04.232295 12900 sgd_solver.cpp:138] Iteration 8860, lr = 0.0005
I0228 19:32:31.182118 12900 solver.cpp:243] Iteration 8870, loss = 1.73194
I0228 19:32:31.182183 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.40811 (* 1 = 1.40811 loss)
I0228 19:32:31.182209 12900 sgd_solver.cpp:138] Iteration 8870, lr = 0.0005
I0228 19:33:42.869837 12900 solver.cpp:243] Iteration 8880, loss = 1.78074
I0228 19:33:42.869987 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.54665 (* 1 = 2.54665 loss)
I0228 19:33:42.870002 12900 sgd_solver.cpp:138] Iteration 8880, lr = 0.0005
I0228 19:34:11.680341 12900 solver.cpp:243] Iteration 8890, loss = 1.64544
I0228 19:34:11.680426 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.52132 (* 1 = 1.52132 loss)
I0228 19:34:11.680438 12900 sgd_solver.cpp:138] Iteration 8890, lr = 0.0005
I0228 19:34:44.264505 12900 solver.cpp:243] Iteration 8900, loss = 1.62547
I0228 19:34:44.264681 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.6914 (* 1 = 1.6914 loss)
I0228 19:34:44.264696 12900 sgd_solver.cpp:138] Iteration 8900, lr = 0.0005
I0228 19:35:23.085242 12900 solver.cpp:243] Iteration 8910, loss = 1.82163
I0228 19:35:23.085362 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.36458 (* 1 = 1.36458 loss)
I0228 19:35:23.085376 12900 sgd_solver.cpp:138] Iteration 8910, lr = 0.0005
I0228 19:36:02.824679 12900 solver.cpp:243] Iteration 8920, loss = 1.67178
I0228 19:36:02.824916 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.55839 (* 1 = 2.55839 loss)
I0228 19:36:02.824929 12900 sgd_solver.cpp:138] Iteration 8920, lr = 0.0005
I0228 19:36:33.791167 12900 solver.cpp:243] Iteration 8930, loss = 1.82141
I0228 19:36:33.791352 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.94814 (* 1 = 1.94814 loss)
I0228 19:36:33.791365 12900 sgd_solver.cpp:138] Iteration 8930, lr = 0.0005
I0228 19:37:26.974576 12900 solver.cpp:243] Iteration 8940, loss = 1.37142
I0228 19:37:26.975668 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.52644 (* 1 = 1.52644 loss)
I0228 19:37:26.975684 12900 sgd_solver.cpp:138] Iteration 8940, lr = 0.0005
I0228 19:38:02.670516 12900 solver.cpp:243] Iteration 8950, loss = 1.87176
I0228 19:38:02.670732 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.62963 (* 1 = 1.62963 loss)
I0228 19:38:02.670744 12900 sgd_solver.cpp:138] Iteration 8950, lr = 0.0005
I0228 19:38:50.967003 12900 solver.cpp:243] Iteration 8960, loss = 1.72452
I0228 19:38:50.967192 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.82046 (* 1 = 1.82046 loss)
I0228 19:38:50.967206 12900 sgd_solver.cpp:138] Iteration 8960, lr = 0.0005
I0228 19:39:22.611315 12900 solver.cpp:243] Iteration 8970, loss = 1.72495
I0228 19:39:22.611485 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.3321 (* 1 = 1.3321 loss)
I0228 19:39:22.611497 12900 sgd_solver.cpp:138] Iteration 8970, lr = 0.0005
I0228 19:40:02.634665 12900 solver.cpp:243] Iteration 8980, loss = 1.64281
I0228 19:40:02.634865 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.84808 (* 1 = 1.84808 loss)
I0228 19:40:02.634881 12900 sgd_solver.cpp:138] Iteration 8980, lr = 0.0005
I0228 19:40:44.958747 12900 solver.cpp:243] Iteration 8990, loss = 1.8121
I0228 19:40:44.958972 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.153 (* 1 = 2.153 loss)
I0228 19:40:44.958988 12900 sgd_solver.cpp:138] Iteration 8990, lr = 0.0005
I0228 19:41:16.843099 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_9000.caffemodel
I0228 19:41:16.918330 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_9000.solverstate
I0228 19:41:19.260752 12900 solver.cpp:243] Iteration 9000, loss = 1.71455
I0228 19:41:19.260795 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.64006 (* 1 = 1.64006 loss)
I0228 19:41:19.260805 12900 sgd_solver.cpp:138] Iteration 9000, lr = 0.0005
I0228 19:41:48.636400 12900 solver.cpp:243] Iteration 9010, loss = 1.85214
I0228 19:41:48.636607 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.97484 (* 1 = 1.97484 loss)
I0228 19:41:48.636620 12900 sgd_solver.cpp:138] Iteration 9010, lr = 0.0005
I0228 19:42:22.838182 12900 solver.cpp:243] Iteration 9020, loss = 1.49933
I0228 19:42:22.838349 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.42916 (* 1 = 1.42916 loss)
I0228 19:42:22.838362 12900 sgd_solver.cpp:138] Iteration 9020, lr = 0.0005
I0228 19:43:03.719794 12900 solver.cpp:243] Iteration 9030, loss = 2.16139
I0228 19:43:03.719964 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.81903 (* 1 = 1.81903 loss)
I0228 19:43:03.719977 12900 sgd_solver.cpp:138] Iteration 9030, lr = 0.0005
I0228 19:43:33.857638 12900 solver.cpp:243] Iteration 9040, loss = 1.91024
I0228 19:43:33.857789 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.02101 (* 1 = 3.02101 loss)
I0228 19:43:33.857803 12900 sgd_solver.cpp:138] Iteration 9040, lr = 0.0005
I0228 19:44:03.205519 12900 solver.cpp:243] Iteration 9050, loss = 1.76063
I0228 19:44:03.205564 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.59649 (* 1 = 1.59649 loss)
I0228 19:44:03.205574 12900 sgd_solver.cpp:138] Iteration 9050, lr = 0.0005
I0228 19:45:00.235880 12900 solver.cpp:243] Iteration 9060, loss = 1.7548
I0228 19:45:00.236570 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.945801 (* 1 = 0.945801 loss)
I0228 19:45:00.236584 12900 sgd_solver.cpp:138] Iteration 9060, lr = 0.0005
I0228 19:45:32.042554 12900 solver.cpp:243] Iteration 9070, loss = 1.85401
I0228 19:45:32.042776 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.8775 (* 1 = 1.8775 loss)
I0228 19:45:32.042790 12900 sgd_solver.cpp:138] Iteration 9070, lr = 0.0005
I0228 19:46:05.126852 12900 solver.cpp:243] Iteration 9080, loss = 1.83481
I0228 19:46:05.127061 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.39897 (* 1 = 3.39897 loss)
I0228 19:46:05.127076 12900 sgd_solver.cpp:138] Iteration 9080, lr = 0.0005
I0228 19:46:34.069996 12900 solver.cpp:243] Iteration 9090, loss = 1.85945
I0228 19:46:34.070039 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.44471 (* 1 = 2.44471 loss)
I0228 19:46:34.070050 12900 sgd_solver.cpp:138] Iteration 9090, lr = 0.0005
I0228 19:47:12.741617 12900 solver.cpp:243] Iteration 9100, loss = 1.96007
I0228 19:47:12.741818 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.68004 (* 1 = 1.68004 loss)
I0228 19:47:12.741832 12900 sgd_solver.cpp:138] Iteration 9100, lr = 0.0005
I0228 19:47:43.767001 12900 solver.cpp:243] Iteration 9110, loss = 1.76215
I0228 19:47:43.767177 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.21126 (* 1 = 1.21126 loss)
I0228 19:47:43.767190 12900 sgd_solver.cpp:138] Iteration 9110, lr = 0.0005
I0228 19:48:12.853391 12900 solver.cpp:243] Iteration 9120, loss = 1.57749
I0228 19:48:12.853448 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.19924 (* 1 = 2.19924 loss)
I0228 19:48:12.853459 12900 sgd_solver.cpp:138] Iteration 9120, lr = 0.0005
I0228 19:48:55.451398 12900 solver.cpp:243] Iteration 9130, loss = 1.83267
I0228 19:48:55.451588 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.40638 (* 1 = 1.40638 loss)
I0228 19:48:55.451603 12900 sgd_solver.cpp:138] Iteration 9130, lr = 0.0005
I0228 19:49:31.347782 12900 solver.cpp:243] Iteration 9140, loss = 1.48285
I0228 19:49:31.347983 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.40402 (* 1 = 1.40402 loss)
I0228 19:49:31.347996 12900 sgd_solver.cpp:138] Iteration 9140, lr = 0.0005
I0228 19:50:01.306716 12900 solver.cpp:243] Iteration 9150, loss = 1.77512
I0228 19:50:01.306764 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.56753 (* 1 = 1.56753 loss)
I0228 19:50:01.306777 12900 sgd_solver.cpp:138] Iteration 9150, lr = 0.0005
I0228 19:50:30.738039 12900 solver.cpp:243] Iteration 9160, loss = 1.79412
I0228 19:50:30.739538 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.01907 (* 1 = 2.01907 loss)
I0228 19:50:30.739552 12900 sgd_solver.cpp:138] Iteration 9160, lr = 0.0005
I0228 19:51:03.596901 12900 solver.cpp:243] Iteration 9170, loss = 1.60349
I0228 19:51:03.597084 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.43562 (* 1 = 1.43562 loss)
I0228 19:51:03.597098 12900 sgd_solver.cpp:138] Iteration 9170, lr = 0.0005
I0228 19:51:31.863978 12900 solver.cpp:243] Iteration 9180, loss = 1.72869
I0228 19:51:31.864037 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.14822 (* 1 = 3.14822 loss)
I0228 19:51:31.864048 12900 sgd_solver.cpp:138] Iteration 9180, lr = 0.0005
I0228 19:52:04.613203 12900 solver.cpp:243] Iteration 9190, loss = 1.74669
I0228 19:52:04.613389 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.53512 (* 1 = 1.53512 loss)
I0228 19:52:04.613401 12900 sgd_solver.cpp:138] Iteration 9190, lr = 0.0005
I0228 19:52:35.952499 12900 solver.cpp:243] Iteration 9200, loss = 1.55856
I0228 19:52:35.952719 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.32068 (* 1 = 1.32068 loss)
I0228 19:52:35.952733 12900 sgd_solver.cpp:138] Iteration 9200, lr = 0.0005
I0228 19:53:06.806270 12900 solver.cpp:243] Iteration 9210, loss = 1.41458
I0228 19:53:06.807446 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.40417 (* 1 = 1.40417 loss)
I0228 19:53:06.807478 12900 sgd_solver.cpp:138] Iteration 9210, lr = 0.0005
I0228 19:53:34.930315 12900 solver.cpp:243] Iteration 9220, loss = 1.66757
I0228 19:53:34.930356 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.35583 (* 1 = 1.35583 loss)
I0228 19:53:34.930364 12900 sgd_solver.cpp:138] Iteration 9220, lr = 0.0005
I0228 19:54:14.601356 12900 solver.cpp:243] Iteration 9230, loss = 2.04168
I0228 19:54:14.601500 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.96299 (* 1 = 2.96299 loss)
I0228 19:54:14.601512 12900 sgd_solver.cpp:138] Iteration 9230, lr = 0.0005
I0228 19:54:55.384810 12900 solver.cpp:243] Iteration 9240, loss = 1.70323
I0228 19:54:55.384999 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.60522 (* 1 = 1.60522 loss)
I0228 19:54:55.385012 12900 sgd_solver.cpp:138] Iteration 9240, lr = 0.0005
I0228 19:55:29.623842 12900 solver.cpp:243] Iteration 9250, loss = 1.76651
I0228 19:55:29.624070 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.14427 (* 1 = 1.14427 loss)
I0228 19:55:29.624085 12900 sgd_solver.cpp:138] Iteration 9250, lr = 0.0005
I0228 19:56:03.570044 12900 solver.cpp:243] Iteration 9260, loss = 1.61996
I0228 19:56:03.570235 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.22499 (* 1 = 1.22499 loss)
I0228 19:56:03.570248 12900 sgd_solver.cpp:138] Iteration 9260, lr = 0.0005
I0228 19:56:32.200505 12900 solver.cpp:243] Iteration 9270, loss = 1.6195
I0228 19:56:32.200557 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.31364 (* 1 = 2.31364 loss)
I0228 19:56:32.200570 12900 sgd_solver.cpp:138] Iteration 9270, lr = 0.0005
I0228 19:57:15.992192 12900 solver.cpp:243] Iteration 9280, loss = 1.69924
I0228 19:57:15.992416 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.61531 (* 1 = 1.61531 loss)
I0228 19:57:15.992434 12900 sgd_solver.cpp:138] Iteration 9280, lr = 0.0005
I0228 19:57:51.141122 12900 solver.cpp:243] Iteration 9290, loss = 1.97778
I0228 19:57:51.141283 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.41956 (* 1 = 2.41956 loss)
I0228 19:57:51.141295 12900 sgd_solver.cpp:138] Iteration 9290, lr = 0.0005
I0228 19:58:19.980782 12900 solver.cpp:243] Iteration 9300, loss = 1.57802
I0228 19:58:19.980847 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.9271 (* 1 = 1.9271 loss)
I0228 19:58:19.980860 12900 sgd_solver.cpp:138] Iteration 9300, lr = 0.0005
I0228 19:58:53.849383 12900 solver.cpp:243] Iteration 9310, loss = 2.07983
I0228 19:58:53.849601 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.27328 (* 1 = 1.27328 loss)
I0228 19:58:53.849613 12900 sgd_solver.cpp:138] Iteration 9310, lr = 0.0005
I0228 19:59:23.860090 12900 solver.cpp:243] Iteration 9320, loss = 1.92492
I0228 19:59:23.860273 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.9542 (* 1 = 2.9542 loss)
I0228 19:59:23.860287 12900 sgd_solver.cpp:138] Iteration 9320, lr = 0.0005
I0228 19:59:59.465545 12900 solver.cpp:243] Iteration 9330, loss = 1.7264
I0228 19:59:59.465705 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.13141 (* 1 = 2.13141 loss)
I0228 19:59:59.465719 12900 sgd_solver.cpp:138] Iteration 9330, lr = 0.0005
I0228 20:00:30.997407 12900 solver.cpp:243] Iteration 9340, loss = 1.65876
I0228 20:00:30.997612 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.55632 (* 1 = 1.55632 loss)
I0228 20:00:30.997625 12900 sgd_solver.cpp:138] Iteration 9340, lr = 0.0005
I0228 20:01:02.507721 12900 solver.cpp:243] Iteration 9350, loss = 1.86166
I0228 20:01:02.507913 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78051 (* 1 = 1.78051 loss)
I0228 20:01:02.507926 12900 sgd_solver.cpp:138] Iteration 9350, lr = 0.0005
I0228 20:01:39.963531 12900 solver.cpp:243] Iteration 9360, loss = 1.79746
I0228 20:01:39.963690 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.23061 (* 1 = 1.23061 loss)
I0228 20:01:39.963703 12900 sgd_solver.cpp:138] Iteration 9360, lr = 0.0005
I0228 20:02:08.479041 12900 solver.cpp:243] Iteration 9370, loss = 1.82029
I0228 20:02:08.479085 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.37017 (* 1 = 1.37017 loss)
I0228 20:02:08.479095 12900 sgd_solver.cpp:138] Iteration 9370, lr = 0.0005
I0228 20:02:42.910432 12900 solver.cpp:243] Iteration 9380, loss = 1.74758
I0228 20:02:42.910605 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.01287 (* 1 = 2.01287 loss)
I0228 20:02:42.910619 12900 sgd_solver.cpp:138] Iteration 9380, lr = 0.0005
I0228 20:03:13.125480 12900 solver.cpp:243] Iteration 9390, loss = 1.6042
I0228 20:03:13.125674 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.908688 (* 1 = 0.908688 loss)
I0228 20:03:13.125689 12900 sgd_solver.cpp:138] Iteration 9390, lr = 0.0005
I0228 20:03:48.249128 12900 solver.cpp:243] Iteration 9400, loss = 1.78754
I0228 20:03:48.249300 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.36064 (* 1 = 2.36064 loss)
I0228 20:03:48.249316 12900 sgd_solver.cpp:138] Iteration 9400, lr = 0.0005
I0228 20:04:19.004578 12900 solver.cpp:243] Iteration 9410, loss = 1.58083
I0228 20:04:19.004817 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.47124 (* 1 = 1.47124 loss)
I0228 20:04:19.004829 12900 sgd_solver.cpp:138] Iteration 9410, lr = 0.0005
I0228 20:04:50.963075 12900 solver.cpp:243] Iteration 9420, loss = 1.65671
I0228 20:04:50.963243 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.10944 (* 1 = 1.10944 loss)
I0228 20:04:50.963256 12900 sgd_solver.cpp:138] Iteration 9420, lr = 0.0005
I0228 20:05:28.776053 12900 solver.cpp:243] Iteration 9430, loss = 1.59506
I0228 20:05:28.777930 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.63337 (* 1 = 1.63337 loss)
I0228 20:05:28.777946 12900 sgd_solver.cpp:138] Iteration 9430, lr = 0.0005
I0228 20:05:59.634280 12900 solver.cpp:243] Iteration 9440, loss = 1.9442
I0228 20:05:59.634485 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.68173 (* 1 = 1.68173 loss)
I0228 20:05:59.634500 12900 sgd_solver.cpp:138] Iteration 9440, lr = 0.0005
I0228 20:06:29.937602 12900 solver.cpp:243] Iteration 9450, loss = 1.82476
I0228 20:06:29.937772 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.07553 (* 1 = 2.07553 loss)
I0228 20:06:29.937784 12900 sgd_solver.cpp:138] Iteration 9450, lr = 0.0005
I0228 20:07:04.736021 12900 solver.cpp:243] Iteration 9460, loss = 1.97357
I0228 20:07:04.736251 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.29251 (* 1 = 2.29251 loss)
I0228 20:07:04.736265 12900 sgd_solver.cpp:138] Iteration 9460, lr = 0.0005
I0228 20:07:38.149157 12900 solver.cpp:243] Iteration 9470, loss = 1.77549
I0228 20:07:38.149346 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.69777 (* 1 = 1.69777 loss)
I0228 20:07:38.149359 12900 sgd_solver.cpp:138] Iteration 9470, lr = 0.0005
I0228 20:08:09.316805 12900 solver.cpp:243] Iteration 9480, loss = 1.83691
I0228 20:08:09.316969 12900 solver.cpp:259]     Train net output #0: mbox_loss = 3.33179 (* 1 = 3.33179 loss)
I0228 20:08:09.316983 12900 sgd_solver.cpp:138] Iteration 9480, lr = 0.0005
I0228 20:08:39.529693 12900 solver.cpp:243] Iteration 9490, loss = 1.75375
I0228 20:08:39.529927 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.91031 (* 1 = 1.91031 loss)
I0228 20:08:39.529991 12900 sgd_solver.cpp:138] Iteration 9490, lr = 0.0005
I0228 20:09:09.788053 12900 solver.cpp:243] Iteration 9500, loss = 1.79724
I0228 20:09:09.788206 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.74623 (* 1 = 1.74623 loss)
I0228 20:09:09.788219 12900 sgd_solver.cpp:138] Iteration 9500, lr = 0.0005
I0228 20:09:41.608399 12900 solver.cpp:243] Iteration 9510, loss = 1.62505
I0228 20:09:41.608603 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.55327 (* 1 = 1.55327 loss)
I0228 20:09:41.608616 12900 sgd_solver.cpp:138] Iteration 9510, lr = 0.0005
I0228 20:10:17.767985 12900 solver.cpp:243] Iteration 9520, loss = 1.74406
I0228 20:10:17.768160 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.60644 (* 1 = 1.60644 loss)
I0228 20:10:17.768174 12900 sgd_solver.cpp:138] Iteration 9520, lr = 0.0005
I0228 20:10:46.794061 12900 solver.cpp:243] Iteration 9530, loss = 1.75356
I0228 20:10:46.794102 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.81588 (* 1 = 1.81588 loss)
I0228 20:10:46.794112 12900 sgd_solver.cpp:138] Iteration 9530, lr = 0.0005
I0228 20:11:26.978425 12900 solver.cpp:243] Iteration 9540, loss = 1.60933
I0228 20:11:26.978657 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.70109 (* 1 = 1.70109 loss)
I0228 20:11:26.978680 12900 sgd_solver.cpp:138] Iteration 9540, lr = 0.0005
I0228 20:11:57.467893 12900 solver.cpp:243] Iteration 9550, loss = 1.69967
I0228 20:11:57.468045 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78558 (* 1 = 1.78558 loss)
I0228 20:11:57.468057 12900 sgd_solver.cpp:138] Iteration 9550, lr = 0.0005
I0228 20:12:38.376324 12900 solver.cpp:243] Iteration 9560, loss = 1.90413
I0228 20:12:38.376508 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.52486 (* 1 = 2.52486 loss)
I0228 20:12:38.376523 12900 sgd_solver.cpp:138] Iteration 9560, lr = 0.0005
I0228 20:13:07.407310 12900 solver.cpp:243] Iteration 9570, loss = 1.68186
I0228 20:13:07.407366 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.964568 (* 1 = 0.964568 loss)
I0228 20:13:07.407377 12900 sgd_solver.cpp:138] Iteration 9570, lr = 0.0005
I0228 20:13:43.420815 12900 solver.cpp:243] Iteration 9580, loss = 2.01396
I0228 20:13:43.420984 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.80697 (* 1 = 1.80697 loss)
I0228 20:13:43.420997 12900 sgd_solver.cpp:138] Iteration 9580, lr = 0.0005
I0228 20:14:15.657439 12900 solver.cpp:243] Iteration 9590, loss = 2.19741
I0228 20:14:15.657663 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.76181 (* 1 = 1.76181 loss)
I0228 20:14:15.657675 12900 sgd_solver.cpp:138] Iteration 9590, lr = 0.0005
I0228 20:14:55.374873 12900 solver.cpp:243] Iteration 9600, loss = 1.52796
I0228 20:14:55.375056 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.63526 (* 1 = 2.63526 loss)
I0228 20:14:55.375069 12900 sgd_solver.cpp:138] Iteration 9600, lr = 0.0005
I0228 20:15:32.099792 12900 solver.cpp:243] Iteration 9610, loss = 1.7541
I0228 20:15:32.101577 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.58265 (* 1 = 2.58265 loss)
I0228 20:15:32.101593 12900 sgd_solver.cpp:138] Iteration 9610, lr = 0.0005
I0228 20:16:10.217998 12900 solver.cpp:243] Iteration 9620, loss = 2.02566
I0228 20:16:10.219743 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.61017 (* 1 = 2.61017 loss)
I0228 20:16:10.219758 12900 sgd_solver.cpp:138] Iteration 9620, lr = 0.0005
I0228 20:16:41.523844 12900 solver.cpp:243] Iteration 9630, loss = 1.74651
I0228 20:16:41.524049 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.49379 (* 1 = 1.49379 loss)
I0228 20:16:41.524060 12900 sgd_solver.cpp:138] Iteration 9630, lr = 0.0005
I0228 20:17:16.848785 12900 solver.cpp:243] Iteration 9640, loss = 1.64135
I0228 20:17:16.848989 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.12139 (* 1 = 1.12139 loss)
I0228 20:17:16.849002 12900 sgd_solver.cpp:138] Iteration 9640, lr = 0.0005
I0228 20:17:46.498145 12900 solver.cpp:243] Iteration 9650, loss = 1.89005
I0228 20:17:46.498188 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.59951 (* 1 = 1.59951 loss)
I0228 20:17:46.498199 12900 sgd_solver.cpp:138] Iteration 9650, lr = 0.0005
I0228 20:18:26.435214 12900 solver.cpp:243] Iteration 9660, loss = 1.82078
I0228 20:18:26.435406 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.3304 (* 1 = 2.3304 loss)
I0228 20:18:26.435425 12900 sgd_solver.cpp:138] Iteration 9660, lr = 0.0005
I0228 20:18:58.090034 12900 solver.cpp:243] Iteration 9670, loss = 1.51607
I0228 20:18:58.090212 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78651 (* 1 = 1.78651 loss)
I0228 20:18:58.090225 12900 sgd_solver.cpp:138] Iteration 9670, lr = 0.0005
I0228 20:19:40.364444 12900 solver.cpp:243] Iteration 9680, loss = 1.4746
I0228 20:19:40.364598 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.04402 (* 1 = 2.04402 loss)
I0228 20:19:40.364611 12900 sgd_solver.cpp:138] Iteration 9680, lr = 0.0005
I0228 20:20:22.155743 12900 solver.cpp:243] Iteration 9690, loss = 1.77298
I0228 20:20:22.155936 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.78727 (* 1 = 1.78727 loss)
I0228 20:20:22.155948 12900 sgd_solver.cpp:138] Iteration 9690, lr = 0.0005
I0228 20:20:59.434196 12900 solver.cpp:243] Iteration 9700, loss = 1.47807
I0228 20:20:59.434404 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.06047 (* 1 = 1.06047 loss)
I0228 20:20:59.434417 12900 sgd_solver.cpp:138] Iteration 9700, lr = 0.0005
I0228 20:21:41.603662 12900 solver.cpp:243] Iteration 9710, loss = 2.05976
I0228 20:21:41.603838 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.05321 (* 1 = 2.05321 loss)
I0228 20:21:41.603852 12900 sgd_solver.cpp:138] Iteration 9710, lr = 0.0005
I0228 20:22:13.777653 12900 solver.cpp:243] Iteration 9720, loss = 1.86071
I0228 20:22:13.777880 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.00462 (* 1 = 2.00462 loss)
I0228 20:22:13.777894 12900 sgd_solver.cpp:138] Iteration 9720, lr = 0.0005
I0228 20:22:42.427502 12900 solver.cpp:243] Iteration 9730, loss = 1.7899
I0228 20:22:42.427583 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.58674 (* 1 = 1.58674 loss)
I0228 20:22:42.427595 12900 sgd_solver.cpp:138] Iteration 9730, lr = 0.0005
I0228 20:23:27.187163 12900 solver.cpp:243] Iteration 9740, loss = 1.87445
I0228 20:23:27.187377 12900 solver.cpp:259]     Train net output #0: mbox_loss = 0.989813 (* 1 = 0.989813 loss)
I0228 20:23:27.187394 12900 sgd_solver.cpp:138] Iteration 9740, lr = 0.0005
I0228 20:24:02.853575 12900 solver.cpp:243] Iteration 9750, loss = 1.76433
I0228 20:24:02.853729 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75716 (* 1 = 1.75716 loss)
I0228 20:24:02.853740 12900 sgd_solver.cpp:138] Iteration 9750, lr = 0.0005
I0228 20:24:32.747181 12900 solver.cpp:243] Iteration 9760, loss = 2.07831
I0228 20:24:32.747218 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.50298 (* 1 = 1.50298 loss)
I0228 20:24:32.747229 12900 sgd_solver.cpp:138] Iteration 9760, lr = 0.0005
I0228 20:25:05.313436 12900 solver.cpp:243] Iteration 9770, loss = 1.87638
I0228 20:25:05.313622 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.65451 (* 1 = 2.65451 loss)
I0228 20:25:05.313637 12900 sgd_solver.cpp:138] Iteration 9770, lr = 0.0005
I0228 20:25:42.448521 12900 solver.cpp:243] Iteration 9780, loss = 1.49314
I0228 20:25:42.448683 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.10629 (* 1 = 1.10629 loss)
I0228 20:25:42.448694 12900 sgd_solver.cpp:138] Iteration 9780, lr = 0.0005
I0228 20:26:11.700989 12900 solver.cpp:243] Iteration 9790, loss = 2.00936
I0228 20:26:11.701046 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.49673 (* 1 = 2.49673 loss)
I0228 20:26:11.701056 12900 sgd_solver.cpp:138] Iteration 9790, lr = 0.0005
I0228 20:26:48.644924 12900 solver.cpp:243] Iteration 9800, loss = 1.67225
I0228 20:26:48.645114 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.86047 (* 1 = 1.86047 loss)
I0228 20:26:48.645128 12900 sgd_solver.cpp:138] Iteration 9800, lr = 0.0005
I0228 20:27:18.516392 12900 solver.cpp:243] Iteration 9810, loss = 1.96491
I0228 20:27:18.516433 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.29421 (* 1 = 1.29421 loss)
I0228 20:27:18.516443 12900 sgd_solver.cpp:138] Iteration 9810, lr = 0.0005
I0228 20:27:49.399188 12900 solver.cpp:243] Iteration 9820, loss = 1.6227
I0228 20:27:49.399399 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.75453 (* 1 = 2.75453 loss)
I0228 20:27:49.399413 12900 sgd_solver.cpp:138] Iteration 9820, lr = 0.0005
I0228 20:28:19.083614 12900 solver.cpp:243] Iteration 9830, loss = 1.6862
I0228 20:28:19.083678 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.3347 (* 1 = 2.3347 loss)
I0228 20:28:19.083690 12900 sgd_solver.cpp:138] Iteration 9830, lr = 0.0005
I0228 20:28:47.329175 12900 solver.cpp:243] Iteration 9840, loss = 1.88871
I0228 20:28:47.329370 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.29119 (* 1 = 1.29119 loss)
I0228 20:28:47.329385 12900 sgd_solver.cpp:138] Iteration 9840, lr = 0.0005
I0228 20:29:19.507272 12900 solver.cpp:243] Iteration 9850, loss = 1.6378
I0228 20:29:19.507436 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.48216 (* 1 = 1.48216 loss)
I0228 20:29:19.507452 12900 sgd_solver.cpp:138] Iteration 9850, lr = 0.0005
I0228 20:30:00.939944 12900 solver.cpp:243] Iteration 9860, loss = 1.72707
I0228 20:30:00.940124 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75538 (* 1 = 1.75538 loss)
I0228 20:30:00.940140 12900 sgd_solver.cpp:138] Iteration 9860, lr = 0.0005
I0228 20:30:40.874253 12900 solver.cpp:243] Iteration 9870, loss = 1.59744
I0228 20:30:40.874431 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.84782 (* 1 = 1.84782 loss)
I0228 20:30:40.874444 12900 sgd_solver.cpp:138] Iteration 9870, lr = 0.0005
I0228 20:31:20.418452 12900 solver.cpp:243] Iteration 9880, loss = 1.66769
I0228 20:31:20.418627 12900 solver.cpp:259]     Train net output #0: mbox_loss = 2.27482 (* 1 = 2.27482 loss)
I0228 20:31:20.418642 12900 sgd_solver.cpp:138] Iteration 9880, lr = 0.0005
I0228 20:31:49.763783 12900 solver.cpp:243] Iteration 9890, loss = 1.46145
I0228 20:31:49.763844 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.72839 (* 1 = 1.72839 loss)
I0228 20:31:49.763854 12900 sgd_solver.cpp:138] Iteration 9890, lr = 0.0005
I0228 20:32:32.224714 12900 solver.cpp:243] Iteration 9900, loss = 1.60151
I0228 20:32:32.224867 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.1485 (* 1 = 1.1485 loss)
I0228 20:32:32.224881 12900 sgd_solver.cpp:138] Iteration 9900, lr = 0.0005
I0228 20:33:02.018362 12900 solver.cpp:243] Iteration 9910, loss = 1.74467
I0228 20:33:02.018406 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.44877 (* 1 = 1.44877 loss)
I0228 20:33:02.018416 12900 sgd_solver.cpp:138] Iteration 9910, lr = 0.0005
I0228 20:33:32.795223 12900 solver.cpp:243] Iteration 9920, loss = 1.51746
I0228 20:33:32.795409 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.14008 (* 1 = 1.14008 loss)
I0228 20:33:32.795423 12900 sgd_solver.cpp:138] Iteration 9920, lr = 0.0005
I0228 20:34:14.380017 12900 solver.cpp:243] Iteration 9930, loss = 1.68305
I0228 20:34:14.380218 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.75772 (* 1 = 1.75772 loss)
I0228 20:34:14.380241 12900 sgd_solver.cpp:138] Iteration 9930, lr = 0.0005
I0228 20:34:57.467099 12900 solver.cpp:243] Iteration 9940, loss = 1.78274
I0228 20:34:57.467250 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.34734 (* 1 = 1.34734 loss)
I0228 20:34:57.467263 12900 sgd_solver.cpp:138] Iteration 9940, lr = 0.0005
I0228 20:35:32.567111 12900 solver.cpp:243] Iteration 9950, loss = 1.71486
I0228 20:35:32.567328 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.87199 (* 1 = 1.87199 loss)
I0228 20:35:32.567342 12900 sgd_solver.cpp:138] Iteration 9950, lr = 0.0005
I0228 20:36:11.411070 12900 solver.cpp:243] Iteration 9960, loss = 2.24222
I0228 20:36:11.411244 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.96678 (* 1 = 1.96678 loss)
I0228 20:36:11.411257 12900 sgd_solver.cpp:138] Iteration 9960, lr = 0.0005
I0228 20:36:44.410424 12900 solver.cpp:243] Iteration 9970, loss = 1.40097
I0228 20:36:44.410629 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.21223 (* 1 = 1.21223 loss)
I0228 20:36:44.410643 12900 sgd_solver.cpp:138] Iteration 9970, lr = 0.0005
I0228 20:37:01.681743 12900 blocking_queue.cpp:50] Data layer prefetch queue empty
I0228 20:37:26.067297 12900 solver.cpp:243] Iteration 9980, loss = 1.71089
I0228 20:37:26.067432 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.41137 (* 1 = 1.41137 loss)
I0228 20:37:26.067450 12900 sgd_solver.cpp:138] Iteration 9980, lr = 0.0005
I0228 20:38:00.505753 12900 solver.cpp:243] Iteration 9990, loss = 1.71827
I0228 20:38:00.505910 12900 solver.cpp:259]     Train net output #0: mbox_loss = 1.60741 (* 1 = 1.60741 loss)
I0228 20:38:00.505924 12900 sgd_solver.cpp:138] Iteration 9990, lr = 0.0005
I0228 20:38:47.084530 12900 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_10000.caffemodel
I0228 20:38:47.153031 12900 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_10000.solverstate
I0228 20:38:47.194299 12900 solver.cpp:433] Iteration 10000, Testing net (#0)
I0228 20:38:47.200587 12900 net.cpp:693] Ignoring source layer mbox_loss
F0228 20:38:47.207754 12900 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
    @     0x7fe9c60b95cd  google::LogMessage::Fail()
    @     0x7fe9c60bb433  google::LogMessage::SendToLog()
    @     0x7fe9c60b915b  google::LogMessage::Flush()
    @     0x7fe9c60bbe1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fe9c67a4300  caffe::SyncedMemory::to_gpu()
    @     0x7fe9c67a32c9  caffe::SyncedMemory::mutable_gpu_data()
    @     0x7fe9c69cb422  caffe::Blob<>::mutable_gpu_data()
    @     0x7fe9c6891b68  caffe::BaseConvolutionLayer<>::forward_gpu_gemm()
    @     0x7fe9c69f03f6  caffe::ConvolutionLayer<>::Forward_gpu()
    @     0x7fe9c678ba12  caffe::Net<>::ForwardFromTo()
    @     0x7fe9c678bb37  caffe::Net<>::Forward()
    @     0x7fe9c67719ca  caffe::Solver<>::TestDetection()
    @     0x7fe9c6773099  caffe::Solver<>::TestAll()
    @     0x7fe9c677319c  caffe::Solver<>::Step()
    @     0x7fe9c6773d1e  caffe::Solver<>::Solve()
    @           0x40b9c4  train()
    @           0x407590  main
    @     0x7fe9c5029830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
./train.sh: line 10: 12900 Aborted                 (core dumped) ../../../build/tools/caffe train -solver="solver_train.prototxt" -weights="../mobilenet_iter_73000.caffemodel" -gpu 1
